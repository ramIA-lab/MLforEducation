[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "",
    "text": "La filosofía de la minería de datos trata de la conversión de datos en conocimiento para la toma de decisiones, y como tal constituye la fase central del proceso de extracción de conocimiento a partir de bases de datos. La minería de datos es un punto de encuentro de diferentes disciplinas:\nJuntas permiten afrontar muchos problemas actuales en cuanto al tratamiento de la información.\nLa asignatura introduce las técnicas más usuales para la resolución de tres tipos de problemas fundamentales: el análisis de datos binarios (transacciones), el análisis de datos científicos (por ejemplo, de genómica) y el análisis de datos de empresas; los cuales configuran buena parte de los problemas actuales que trata la minería de datos.\nComo objetivo paralelo hay utilizar la R, un potente en torno a programación libre.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "",
    "text": "En este ejemplo se entrena un árbol de regresión para predecir el precio unitario de la vivienda en Madrid. Para ello se utilizan los datos de viviendas a la venta en Madrid publicados en Idealista durante el año 2018. Estos datos están incluidos en el paquete idealista18. Las variables que contienen nuestra base de datos son las siguientes:\n\n“ASSETID” : Identificador único del activo\n“PERIOD” : Fecha AAAAMM, indica el trimestre en el que se extrajo el anuncio, utilizamos AAAA03 para el 1.er trimestre, AAAA06 para el 2.º, AAAA09 para el 3.er y AAAA12 para el 4.º\n“PRICE” : Precio de venta del anuncio en idealista expresado en euros\n“UNITPRICE” : Precio en euros por metro cuadrado\n“CONSTRUCTEDAREA” : Superficie construida de la casa en metros cuadrados\n“ROOMNUMBER” : Número de habitaciones\n“BATHNUMBER” : Número de baños\n“HASTERRACE” : Variable ficticia para terraza (toma 1 si hay una terraza, 0 en caso contrario)\n“HASLIFT” : Variable ficticia para ascensor (toma 1 si hay ascensor en el edificio, 0 en caso contrario)\n“HASAIRCONDITIONING” : Variable ficticia para Aire Acondicionado (toma 1 si hay una Aire Acondicionado, 0 en caso contrario)\n“AMENITYID” : Indica las comodidades incluidas (1 - sin muebles, sin comodidades de cocina, 2 - comodidades de cocina, sin muebles, 3 - comodidades de cocina, muebles)\n“HASPARKINGSPACE” : Variable ficticia para estacionamiento (toma 1 si el estacionamiento está incluido en el anuncio, 0 en caso contrario)\n“ISPARKINGSPACEINCLUDEDINPRICE” : Variable ficticia para estacionamiento (toma 1 si el estacionamiento está incluido en el anuncio, 0 en caso contrario)\n“PARKINGSPACEPRICE” : Precio de plaza de parking en euros\n“HASNORTHORIENTATION” : Variable ficticia para orientación (toma 1 si la orientación es Norte en el anuncio, 0 en caso contrario) - Nota importante: las características de orientación no son características ortogonales, una casa orientada al norte también puede estar orientada al este\n“HASSOUTHORIENTATION” : Variable ficticia para orientación (toma 1 si la orientación es Sur en el anuncio, 0 en caso contrario) - Nota importante: las características de orientación no son características ortogonales, una casa orientada al norte también puede estar orientada al este\n“HASEASTORIENTATION” : Variable ficticia para orientación (toma 1 si la orientación es Este en el anuncio, 0 en caso contrario) - Nota importante: las características de orientación no son características ortogonales, una casa orientada al norte también puede estar orientada al este\n“HASWESTORIENTATION” : Variable ficticia para orientación (toma 1 si la orientación es Oeste en el anuncio, 0 en caso contrario) - Nota importante: las características de orientación no son características ortogonales, una casa orientada al norte también puede estar orientada al este\n“HASBOXROOM” : Variable ficticia para boxroom (toma 1 si boxroom está incluido en el anuncio, 0 en caso contrario)\n“HASWARDROBE” : Variable ficticia para vestuario (toma 1 si el vestuario está incluido en el anuncio, 0 en caso contrario)\n“HASSWIMMINGPOOL” : Variable ficticia para piscina (toma 1 si la piscina está incluida en el anuncio, 0 en caso contrario)\n“HASDOORMAN” : Variable ficticia para portero (toma 1 si hay un portero en el edificio, 0 en caso contrario)\n“HASGARDEN” : Variable ficticia para jardín (toma 1 si hay un jardín en el edificio, 0 en caso contrario)\n“ISDUPLEX” : Variable ficticia para dúplex (toma 1 si es un dúplex, 0 en caso contrario)\n“ISSTUDIO” : Variable ficticia para piso de soltero (estudio en español) (toma 1 si es un piso para una sola persona, 0 en caso contrario)\n“ISINTOPFLOOR” : Variable ficticia que indica si el apartamento está ubicado en el piso superior (toma 1 en el piso superior, 0 en caso contrario)\n“CONSTRUCTIONYEAR” : Año de construcción (fuente: anunciante)\n“FLOORCLEAN” : Indica el número de piso del apartamento comenzando desde el valor 0 para la planta baja (fuente: anunciante)\n“FLATLOCATIONID” : Indica el tipo de vistas que tiene el piso (1 - exterior, 2 - interior)\n“CADCONSTRUCTIONYEAR” : Año de construcción según fuente catastral (fuente: catastro), tenga en cuenta que esta cifra puede diferir de la proporcionada por el anunciante\n“CADMAXBUILDINGFLOOR” : Superficie máxima del edificio (fuente: catastro)\n“CADDWELLINGCOUNT” : Recuento de viviendas en el edificio (fuente: catastro)\n“CADASTRALQUALITYID” : Calidad catastral (fuente: catastro)\n“BUILTTYPEID_1” : Valor ficticio para estado del piso: 1 obra nueva 0 en caso contrario (fuente: anunciante)\n“BUILTTYPEID_2” : Valor ficticio para condición plana: 1 segundero a restaurar 0 en caso contrario (fuente: anunciante)\n“BUILTTYPEID_3” : Valor ficticio para estado plano: 1 de segunda mano en buen estado 0 en caso contrario (fuente: anunciante)\n“DISTANCE_TO_CITY_CENTER” : Distancia al centro de la ciudad en km\n“DISTANCE_TO_METRO” : Distancia istancia a una parada de metro en km.\n“DISTANCE_TO_DIAGONAL” : Distancia a la Avenida Diagonal en km; Diagonal es una calle principal que corta la ciudad en diagonal a la cuadrícula de calles.\n“LONGITUDE” : Longitud del activo\n“LATITUDE” : Latitud del activo\n“geometry” : Geometría de características simples en latitud y longitud.\n\nFuente: Idealista\n\nlibrary(\"idealista18\")\nBCN &lt;- get(data(\"Barcelona_Sale\"))\n\n\n# Filtramos la epoca a Navidad\nBCN &lt;- BCN[which(BCN$PERIOD == \"201812\"), ]\n\npisos_sf_BCN &lt;- st_as_sf(BCN, coords = c(\"LONGITUDE\", \"LATITUDE\"), crs = 4326)\n\n# Leer shapefile de secciones censales\nsecciones &lt;- st_read(\"C:/Users/sergi/Downloads/Shapefile/seccionado_2024/SECC_CE_20240101.shp\")\n\n# Transformar pisos al sistema de referencia de las secciones censales\npisos_sf_BCN &lt;- st_transform(pisos_sf_BCN, crs = st_crs(secciones))\n\n# Hacer el match entre pisos y secciones censales\npisos_con_seccion &lt;- st_join(pisos_sf_BCN, secciones, join = st_within)\n\n# Convertir a dataframe para exportar\nBCN &lt;- as.data.frame(pisos_con_seccion)\n\nrm(Barcelona_Sale, Barcelona_Polygons, Barcelona_POIS, pisos_con_seccion, pisos_sf_BCN, secciones); gc()\n\n\nrentaMedia &lt;- read.csv(\"https://raw.githubusercontent.com/miguel-angel-monjas/spain-datasets/refs/heads/master/data/Renta%20media%20en%20Espa%C3%B1a.csv\")\n# NOs quedamos con los datos que nos interesa de Barcelona\nrentaMedia &lt;- rentaMedia[which(rentaMedia$Provincia == \"Barcelona\" & rentaMedia$Tipo.de.elemento == \"sección\"), ]\nrentaMedia$Código.de.territorio &lt;- paste0(\"0\", rentaMedia$Código.de.territorio)\n\n\ncols &lt;- c(\"Renta.media.por.persona\", \"Renta.media.por.hogar\")\n\nm &lt;- match(BCN$CUSEC, rentaMedia$Código.de.territorio)\nBCN[, cols] &lt;- rentaMedia[m, cols]\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#análisi-descriptivo-de-los-datos",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#análisi-descriptivo-de-los-datos",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "2.1 Análisi descriptivo de los datos",
    "text": "2.1 Análisi descriptivo de los datos\n\n## Descriptiva de los datos\nlibrary(DataExplorer)\nlibrary(lubridate)\nlibrary(dplyr)\n\n## Data Manipulation\nlibrary(reshape2)\n\n## Plotting\nlibrary(ggplot2)\n\n## Descripción completa\nDataExplorer::introduce(BCN)\n\n   rows columns discrete_columns continuous_columns all_missing_columns\n1 23334      36               24                 12                   0\n  total_missing_values complete_rows total_observations memory_usage\n1                    0         23334             840024      6078888\n\n## Descripción de la bbdd\nplot_intro(BCN)\n\n\n\n\n\n\n\n## Descripción de los missings\nplot_missing(BCN)\n\n\n\n\n\n\n\n## Descripción de las varaibles categoricas\nplot_bar(BCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Descripción variables numéricas\nplot_histogram(BCN)\n\n\n\n\n\n\n\nplot_density(BCN)\n\n\n\n\n\n\n\nplot_qq(BCN)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplot_correlation(BCN)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#creación-del-árbol",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#creación-del-árbol",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "4.1 Creación del árbol",
    "text": "4.1 Creación del árbol\n\nRPython\n\n\n\nlibrary(rpart)\nlibrary(rpart.plot)\n\nset.seed(1994)\n\narbol &lt;- rpart(RENTA ~ ., data = rtrain)\nsummary(arbol)\n\nCall:\nrpart(formula = RENTA ~ ., data = rtrain)\n  n= 18669 \n\n          CP nsplit rel error    xerror        xstd\n1 0.38211183      0 1.0000000 1.0000000 0.008293935\n2 0.06753946      1 0.6178882 0.6178882 0.007426365\n3 0.04447571      2 0.5503487 0.5503487 0.007149373\n4 0.02214609      4 0.4613973 0.4643338 0.006727872\n5 0.01884253      5 0.4392512 0.4425548 0.006607381\n6 0.01186835      6 0.4204087 0.4267711 0.006516230\n7 0.01162364      8 0.3966720 0.4034014 0.006375036\n8 0.01015539     10 0.3734247 0.3792977 0.006221129\n9 0.01000000     12 0.3531139 0.3676740 0.006143722\n\nVariable importance\n                   CDIS DISTANCE_TO_CITY_CENTER    DISTANCE_TO_DIAGONAL \n                     40                      24                      17 \n    CADCONSTRUCTIONYEAR         CONSTRUCTEDAREA               UNITPRICE \n                      8                       3                       3 \n      DISTANCE_TO_METRO              BATHNUMBER              ROOMNUMBER \n                      2                       1                       1 \n\nNode number 1: 18669 observations,    complexity param=0.3821118\n  predicted class=Media  expected loss=0.4377846  P(node) =1\n    class counts:  1941  6232 10496\n   probabilities: 0.104 0.334 0.562 \n  left son=2 (4541 obs) right son=3 (14128 obs)\n  Primary splits:\n      CDIS                    splits as  LRRRRLRRRR, improve=2615.4350, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 1.697581   to the right, improve=1710.4180, (0 missing)\n      HASLIFT                 splits as  LR, improve= 961.7684, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 1.146692   to the left,  improve= 885.2803, (0 missing)\n      CADCONSTRUCTIONYEAR     &lt; 1900.5     to the left,  improve= 800.8061, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_CITY_CENTER &lt; 1.146692   to the left,  agree=0.853, adj=0.396, (0 split)\n      CADCONSTRUCTIONYEAR     &lt; 1900.5     to the left,  agree=0.823, adj=0.273, (0 split)\n      DISTANCE_TO_DIAGONAL    &lt; 4.28574    to the right, agree=0.775, adj=0.076, (0 split)\n      CONSTRUCTEDAREA         &lt; 46.5       to the left,  agree=0.769, adj=0.052, (0 split)\n      ROOMNUMBER              &lt; 11         to the right, agree=0.757, adj=0.001, (0 split)\n\nNode number 2: 4541 observations,    complexity param=0.02214609\n  predicted class=Baja   expected loss=0.156133  P(node) =0.2432375\n    class counts:     0  3832   709\n   probabilities: 0.000 0.844 0.156 \n  left son=4 (4294 obs) right son=5 (247 obs)\n  Primary splits:\n      DISTANCE_TO_CITY_CENTER &lt; 0.4629643  to the right, improve=263.54560, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 1.293729   to the right, improve= 85.60347, (0 missing)\n      CDIS                    splits as  L----R----, improve= 66.85504, (0 missing)\n      HASLIFT                 splits as  LR, improve= 65.14028, (0 missing)\n      CADCONSTRUCTIONYEAR     &lt; 1950.5     to the left,  improve= 50.10187, (0 missing)\n\nNode number 3: 14128 observations,    complexity param=0.06753946\n  predicted class=Media  expected loss=0.3072622  P(node) =0.7567625\n    class counts:  1941  2400  9787\n   probabilities: 0.137 0.170 0.693 \n  left son=6 (1990 obs) right son=7 (12138 obs)\n  Primary splits:\n      CDIS                 splits as  -RRRL-RRRL, improve=903.3696, (0 missing)\n      DISTANCE_TO_DIAGONAL &lt; 2.370657   to the right, improve=788.5626, (0 missing)\n      CONSTRUCTEDAREA      &lt; 137.5      to the right, improve=434.3222, (0 missing)\n      UNITPRICE            &lt; 2898.227   to the left,  improve=369.9583, (0 missing)\n      BATHNUMBER           &lt; 2.5        to the right, improve=353.8536, (0 missing)\n  Surrogate splits:\n      CONSTRUCTEDAREA   &lt; 223.5      to the right, agree=0.866, adj=0.052, (0 split)\n      BATHNUMBER        &lt; 3.5        to the right, agree=0.864, adj=0.038, (0 split)\n      DISTANCE_TO_METRO &lt; 1.634495   to the right, agree=0.860, adj=0.006, (0 split)\n      ROOMNUMBER        &lt; 6.5        to the right, agree=0.859, adj=0.003, (0 split)\n      UNITPRICE         &lt; 6992.805   to the right, agree=0.859, adj=0.001, (0 split)\n\nNode number 4: 4294 observations,    complexity param=0.01015539\n  predicted class=Baja   expected loss=0.1152771  P(node) =0.230007\n    class counts:     0  3799   495\n   probabilities: 0.000 0.885 0.115 \n  left son=8 (3278 obs) right son=9 (1016 obs)\n  Primary splits:\n      DISTANCE_TO_CITY_CENTER &lt; 3.316192   to the left,  improve=107.18450, (0 missing)\n      CDIS                    splits as  L----R----, improve=107.18450, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 2.818623   to the left,  improve= 91.99937, (0 missing)\n      CADCONSTRUCTIONYEAR     &lt; 1950.5     to the left,  improve= 66.10102, (0 missing)\n      HASLIFT                 splits as  LR, improve= 49.70642, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_DIAGONAL &lt; 2.826385   to the left,  agree=0.989, adj=0.955, (0 split)\n      CADCONSTRUCTIONYEAR  &lt; 1950.5     to the left,  agree=0.886, adj=0.517, (0 split)\n      UNITPRICE            &lt; 2840.561   to the right, agree=0.876, adj=0.475, (0 split)\n      CADDWELLINGCOUNT     &lt; 30.5       to the left,  agree=0.789, adj=0.106, (0 split)\n      CADMAXBUILDINGFLOOR  &lt; 7.5        to the left,  agree=0.776, adj=0.053, (0 split)\n\nNode number 5: 247 observations\n  predicted class=Media  expected loss=0.1336032  P(node) =0.01323049\n    class counts:     0    33   214\n   probabilities: 0.000 0.134 0.866 \n\nNode number 6: 1990 observations,    complexity param=0.01162364\n  predicted class=Alta   expected loss=0.3613065  P(node) =0.1065938\n    class counts:  1271     0   719\n   probabilities: 0.639 0.000 0.361 \n  left son=12 (1077 obs) right son=13 (913 obs)\n  Primary splits:\n      CONSTRUCTEDAREA      &lt; 119.5      to the right, improve=121.31850, (0 missing)\n      BATHNUMBER           &lt; 2.5        to the right, improve= 87.03903, (0 missing)\n      DISTANCE_TO_DIAGONAL &lt; 0.5534786  to the left,  improve= 85.36516, (0 missing)\n      CDIS                 splits as  ----R----L, improve= 68.18003, (0 missing)\n      UNITPRICE            &lt; 5287.749   to the right, improve= 60.24694, (0 missing)\n  Surrogate splits:\n      ROOMNUMBER                    &lt; 3.5        to the right, agree=0.790, adj=0.542, (0 split)\n      BATHNUMBER                    &lt; 1.5        to the right, agree=0.747, adj=0.448, (0 split)\n      HASTERRACE                    splits as  RL, agree=0.647, adj=0.230, (0 split)\n      HASPARKINGSPACE               splits as  RL, agree=0.641, adj=0.217, (0 split)\n      ISPARKINGSPACEINCLUDEDINPRICE splits as  RL, agree=0.641, adj=0.217, (0 split)\n\nNode number 7: 12138 observations,    complexity param=0.04447571\n  predicted class=Media  expected loss=0.2529247  P(node) =0.6501687\n    class counts:   670  2400  9068\n   probabilities: 0.055 0.198 0.747 \n  left son=14 (2820 obs) right son=15 (9318 obs)\n  Primary splits:\n      DISTANCE_TO_DIAGONAL    &lt; 2.370657   to the right, improve=832.9688, (0 missing)\n      CDIS                    splits as  -RRL--RLL-, improve=615.9082, (0 missing)\n      UNITPRICE               &lt; 2898.227   to the left,  improve=380.3717, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 3.940257   to the right, improve=338.4368, (0 missing)\n      CONSTRUCTEDAREA         &lt; 80.5       to the left,  improve=178.0100, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_CITY_CENTER &lt; 4.058752   to the right, agree=0.897, adj=0.558, (0 split)\n      CDIS                    splits as  -RRL--LRR-, agree=0.816, adj=0.206, (0 split)\n      UNITPRICE               &lt; 2753.972   to the left,  agree=0.811, adj=0.184, (0 split)\n      DISTANCE_TO_METRO       &lt; 0.7218963  to the right, agree=0.780, adj=0.051, (0 split)\n      CADMAXBUILDINGFLOOR     &lt; 26.5       to the right, agree=0.769, adj=0.005, (0 split)\n\nNode number 8: 3278 observations\n  predicted class=Baja   expected loss=0.05308115  P(node) =0.1755852\n    class counts:     0  3104   174\n   probabilities: 0.000 0.947 0.053 \n\nNode number 9: 1016 observations,    complexity param=0.01015539\n  predicted class=Baja   expected loss=0.3159449  P(node) =0.05442177\n    class counts:     0   695   321\n   probabilities: 0.000 0.684 0.316 \n  left son=18 (712 obs) right son=19 (304 obs)\n  Primary splits:\n      DISTANCE_TO_DIAGONAL    &lt; 3.420441   to the right, improve=181.26100, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 4.8151     to the right, improve=162.58570, (0 missing)\n      UNITPRICE               &lt; 2586.19    to the left,  improve= 62.53053, (0 missing)\n      HASLIFT                 splits as  LR, improve= 54.20484, (0 missing)\n      CONSTRUCTEDAREA         &lt; 74.5       to the left,  improve= 31.09944, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_CITY_CENTER &lt; 5.091757   to the right, agree=0.958, adj=0.859, (0 split)\n      UNITPRICE               &lt; 3251.667   to the left,  agree=0.775, adj=0.247, (0 split)\n      CADCONSTRUCTIONYEAR     &lt; 1954.5     to the right, agree=0.708, adj=0.023, (0 split)\n      BUILTTYPEID_1           splits as  LR, agree=0.707, adj=0.020, (0 split)\n      DISTANCE_TO_METRO       &lt; 0.02808259 to the right, agree=0.707, adj=0.020, (0 split)\n\nNode number 12: 1077 observations\n  predicted class=Alta   expected loss=0.2005571  P(node) =0.05768922\n    class counts:   861     0   216\n   probabilities: 0.799 0.000 0.201 \n\nNode number 13: 913 observations,    complexity param=0.01162364\n  predicted class=Media  expected loss=0.449069  P(node) =0.0489046\n    class counts:   410     0   503\n   probabilities: 0.449 0.000 0.551 \n  left son=26 (495 obs) right son=27 (418 obs)\n  Primary splits:\n      CDIS                    splits as  ----R----L, improve=47.94928, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 0.5540544  to the left,  improve=44.18423, (0 missing)\n      UNITPRICE               &lt; 5289.352   to the right, improve=37.28880, (0 missing)\n      DISTANCE_TO_METRO       &lt; 0.2951583  to the right, improve=24.68798, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 2.14678    to the left,  improve=21.64891, (0 missing)\n  Surrogate splits:\n      CADDWELLINGCOUNT        &lt; 30.5       to the left,  agree=0.729, adj=0.409, (0 split)\n      DISTANCE_TO_DIAGONAL    &lt; 1.062684   to the right, agree=0.705, adj=0.356, (0 split)\n      UNITPRICE               &lt; 4821.591   to the right, agree=0.677, adj=0.294, (0 split)\n      CADMAXBUILDINGFLOOR     &lt; 8.5        to the left,  agree=0.662, adj=0.261, (0 split)\n      DISTANCE_TO_CITY_CENTER &lt; 3.575557   to the left,  agree=0.623, adj=0.177, (0 split)\n\nNode number 14: 2820 observations,    complexity param=0.04447571\n  predicted class=Baja   expected loss=0.4553191  P(node) =0.1510525\n    class counts:    95  1536  1189\n   probabilities: 0.034 0.545 0.422 \n  left son=28 (2010 obs) right son=29 (810 obs)\n  Primary splits:\n      CDIS                    splits as  -RRL--RLL-, improve=202.04190, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 2.380396   to the left,  improve=170.89780, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 3.446593   to the left,  improve=103.80040, (0 missing)\n      CADCONSTRUCTIONYEAR     &lt; 1971.5     to the left,  improve= 77.57975, (0 missing)\n      CONSTRUCTEDAREA         &lt; 86.5       to the left,  improve= 62.41583, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_CITY_CENTER &lt; 5.730574   to the left,  agree=0.819, adj=0.370, (0 split)\n      DISTANCE_TO_DIAGONAL    &lt; 3.716013   to the left,  agree=0.759, adj=0.160, (0 split)\n      CONSTRUCTEDAREA         &lt; 130.5      to the left,  agree=0.716, adj=0.012, (0 split)\n      BATHNUMBER              &lt; 2.5        to the left,  agree=0.715, adj=0.006, (0 split)\n      DISTANCE_TO_METRO       &lt; 0.01826087 to the right, agree=0.714, adj=0.005, (0 split)\n\nNode number 15: 9318 observations,    complexity param=0.01186835\n  predicted class=Media  expected loss=0.1544323  P(node) =0.4991162\n    class counts:   575   864  7879\n   probabilities: 0.062 0.093 0.846 \n  left son=30 (523 obs) right son=31 (8795 obs)\n  Primary splits:\n      DISTANCE_TO_CITY_CENTER &lt; 0.871618   to the left,  improve=157.24670, (0 missing)\n      CDIS                    splits as  -RRL--RLL-, improve=145.36290, (0 missing)\n      CADDWELLINGCOUNT        &lt; 167.5      to the right, improve= 73.55115, (0 missing)\n      CONSTRUCTEDAREA         &lt; 135.5      to the right, improve= 56.59289, (0 missing)\n      DISTANCE_TO_DIAGONAL    &lt; 1.820647   to the right, improve= 55.50302, (0 missing)\n  Surrogate splits:\n      BATHNUMBER &lt; 0.5        to the left,  agree=0.944, adj=0.002, (0 split)\n\nNode number 18: 712 observations\n  predicted class=Baja   expected loss=0.1207865  P(node) =0.03813809\n    class counts:     0   626    86\n   probabilities: 0.000 0.879 0.121 \n\nNode number 19: 304 observations\n  predicted class=Media  expected loss=0.2269737  P(node) =0.01628368\n    class counts:     0    69   235\n   probabilities: 0.000 0.227 0.773 \n\nNode number 26: 495 observations\n  predicted class=Alta   expected loss=0.4020202  P(node) =0.02651454\n    class counts:   296     0   199\n   probabilities: 0.598 0.000 0.402 \n\nNode number 27: 418 observations\n  predicted class=Media  expected loss=0.2727273  P(node) =0.02239006\n    class counts:   114     0   304\n   probabilities: 0.273 0.000 0.727 \n\nNode number 28: 2010 observations,    complexity param=0.01884253\n  predicted class=Baja   expected loss=0.3278607  P(node) =0.1076651\n    class counts:    35  1351   624\n   probabilities: 0.017 0.672 0.310 \n  left son=56 (1748 obs) right son=57 (262 obs)\n  Primary splits:\n      DISTANCE_TO_DIAGONAL    &lt; 3.446593   to the left,  improve=135.93570, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 2.380396   to the left,  improve=112.73140, (0 missing)\n      DISTANCE_TO_METRO       &lt; 0.3243732  to the left,  improve= 83.82446, (0 missing)\n      CADCONSTRUCTIONYEAR     &lt; 1967.5     to the left,  improve= 70.86276, (0 missing)\n      CADMAXBUILDINGFLOOR     &lt; 7.5        to the left,  improve= 37.15447, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_CITY_CENTER &lt; 5.208402   to the left,  agree=0.949, adj=0.611, (0 split)\n      DISTANCE_TO_METRO       &lt; 0.7342067  to the left,  agree=0.904, adj=0.267, (0 split)\n      PARKINGSPACEPRICE       &lt; 28451      to the left,  agree=0.872, adj=0.015, (0 split)\n      CADMAXBUILDINGFLOOR     &lt; 1.5        to the right, agree=0.872, adj=0.015, (0 split)\n\nNode number 29: 810 observations\n  predicted class=Media  expected loss=0.3024691  P(node) =0.04338743\n    class counts:    60   185   565\n   probabilities: 0.074 0.228 0.698 \n\nNode number 30: 523 observations,    complexity param=0.01186835\n  predicted class=Media  expected loss=0.4760994  P(node) =0.02801436\n    class counts:   249     0   274\n   probabilities: 0.476 0.000 0.524 \n  left son=60 (284 obs) right son=61 (239 obs)\n  Primary splits:\n      DISTANCE_TO_DIAGONAL    &lt; 0.990107   to the left,  improve=165.999900, (0 missing)\n      DISTANCE_TO_METRO       &lt; 0.1705538  to the right, improve= 38.560880, (0 missing)\n      DISTANCE_TO_CITY_CENTER &lt; 0.44858    to the right, improve= 36.859370, (0 missing)\n      UNITPRICE               &lt; 4976.906   to the right, improve= 12.669910, (0 missing)\n      CONSTRUCTEDAREA         &lt; 124.5      to the right, improve=  9.569507, (0 missing)\n  Surrogate splits:\n      DISTANCE_TO_METRO       &lt; 0.1699124  to the right, agree=0.744, adj=0.439, (0 split)\n      DISTANCE_TO_CITY_CENTER &lt; 0.4805939  to the right, agree=0.728, adj=0.406, (0 split)\n      UNITPRICE               &lt; 4976.906   to the right, agree=0.642, adj=0.218, (0 split)\n      CADCONSTRUCTIONYEAR     &lt; 1941.5     to the left,  agree=0.587, adj=0.096, (0 split)\n      CADDWELLINGCOUNT        &lt; 24.5       to the left,  agree=0.583, adj=0.088, (0 split)\n\nNode number 31: 8795 observations\n  predicted class=Media  expected loss=0.1353042  P(node) =0.4711018\n    class counts:   326   864  7605\n   probabilities: 0.037 0.098 0.865 \n\nNode number 56: 1748 observations\n  predicted class=Baja   expected loss=0.2580092  P(node) =0.09363115\n    class counts:    35  1297   416\n   probabilities: 0.020 0.742 0.238 \n\nNode number 57: 262 observations\n  predicted class=Media  expected loss=0.2061069  P(node) =0.01403396\n    class counts:     0    54   208\n   probabilities: 0.000 0.206 0.794 \n\nNode number 60: 284 observations\n  predicted class=Alta   expected loss=0.1584507  P(node) =0.01521238\n    class counts:   239     0    45\n   probabilities: 0.842 0.000 0.158 \n\nNode number 61: 239 observations\n  predicted class=Media  expected loss=0.041841  P(node) =0.01280197\n    class counts:    10     0   229\n   probabilities: 0.042 0.000 0.958 \n\n\n\nrpart.plot(arbol)\n\n\n\n\n\n\n\n\n\n\n\n# Decision Tree Classification\nfrom sklearn.tree import DecisionTreeClassifier\n\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 1994)\nclf = classifier.fit(pyX_train, pyy_train)\n\n\nfrom sklearn import tree\n\ntree.plot_tree(clf)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#creamos-las-predicciones",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#creamos-las-predicciones",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "4.2 Creamos las predicciones",
    "text": "4.2 Creamos las predicciones\n\nRPython\n\n\nAplicamos el modelo a nuestros valores de test.\n\npredict(arbol, rtest[1:10, ])\n\n   Alta      Baja      Media\n1     0 0.9469189 0.05308115\n2     0 0.9469189 0.05308115\n3     0 0.9469189 0.05308115\n4     0 0.9469189 0.05308115\n5     0 0.9469189 0.05308115\n6     0 0.1336032 0.86639676\n7     0 0.9469189 0.05308115\n8     0 0.9469189 0.05308115\n9     0 0.9469189 0.05308115\n10    0 0.1336032 0.86639676\n\n\n\npredicciones &lt;- predict(arbol, rtrain, type = \"class\")\ncaret::confusionMatrix(predicciones, as.factor(rtrain$RENTA))\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Alta Baja Media\n     Alta  1396    0   460\n     Baja    35 5027   676\n     Media  510 1205  9360\n\nOverall Statistics\n                                          \n               Accuracy : 0.8454          \n                 95% CI : (0.8401, 0.8506)\n    No Information Rate : 0.5622          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7207          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n\nStatistics by Class:\n\n                     Class: Alta Class: Baja Class: Media\nSensitivity              0.71922      0.8066       0.8918\nSpecificity              0.97250      0.9428       0.7902\nPos Pred Value           0.75216      0.8761       0.8451\nNeg Pred Value           0.96758      0.9068       0.8504\nPrevalence               0.10397      0.3338       0.5622\nDetection Rate           0.07478      0.2693       0.5014\nDetection Prevalence     0.09942      0.3074       0.5932\nBalanced Accuracy        0.84586      0.8747       0.8410\n\npredicciones &lt;- predict(arbol, rtest, type = \"class\")\ncaret::confusionMatrix(predicciones, as.factor(rtest$RENTA))\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Alta Baja Media\n     Alta   311    1   148\n     Baja     5 1250   171\n     Media  151  266  2362\n\nOverall Statistics\n                                          \n               Accuracy : 0.8409          \n                 95% CI : (0.8301, 0.8513)\n    No Information Rate : 0.5747          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7099          \n                                          \n Mcnemar's Test P-Value : 3.415e-05       \n\nStatistics by Class:\n\n                     Class: Alta Class: Baja Class: Media\nSensitivity              0.66595      0.8240       0.8810\nSpecificity              0.96451      0.9441       0.7898\nPos Pred Value           0.67609      0.8766       0.8499\nNeg Pred Value           0.96290      0.9176       0.8309\nPrevalence               0.10011      0.3252       0.5747\nDetection Rate           0.06667      0.2680       0.5063\nDetection Prevalence     0.09861      0.3057       0.5957\nBalanced Accuracy        0.81523      0.8840       0.8354\n\n\n\nCM &lt;- caret::confusionMatrix(predicciones, as.factor(rtest$RENTA)); CM &lt;- data.frame(CM$table)\n\ngrafico &lt;- ggplot(CM, aes(Prediction,Reference, fill= Freq)) +\n        geom_tile() + geom_text(aes(label=Freq)) +\n        scale_fill_gradient(low=\"white\", high=\"#009194\") +\n        labs(x = \"Reference\",y = \"Prediction\")\n\nplot(grafico)\n\n\n\n\n\n\n\n\n\n\n\nimport pandas as pd\n\n# Prediction\ny_pred = classifier.predict(pyX_test)\n\nresults = pd.DataFrame({\n    'Real': pyy_test,  # Valores reales\n    'Predicho': y_pred  # Valores predichos\n})\n\n# Muestra los primeros 5 registros\nprint(results.head())  \n\n       Real  Predicho\n2399      2         2\n18420     0         0\n22515     2         2\n20265     1         1\n10432     1         1\n\n\n\nfrom sklearn.metrics import classification_report\n\nprint(f'Classification Report: \\n{classification_report(pyy_test, y_pred)}')\n\nClassification Report: \n              precision    recall  f1-score   support\n\n           0       0.85      0.82      0.84       488\n           1       0.92      0.91      0.91      1522\n           2       0.92      0.93      0.92      2657\n\n    accuracy                           0.91      4667\n   macro avg       0.89      0.89      0.89      4667\nweighted avg       0.91      0.91      0.91      4667\n\n\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\n# Confusion matrix\ncf_matrix = confusion_matrix(pyy_test, y_pred)\nsns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#modelo-de-classificación-con-cross-evaluación",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#modelo-de-classificación-con-cross-evaluación",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "4.3 Modelo de classificación con cross-evaluación",
    "text": "4.3 Modelo de classificación con cross-evaluación\n\nRPython\n\n\n\n## Generamos los parámetros de control\ntrControl &lt;- trainControl(method = \"cv\", number = 10, classProbs = TRUE,\n  summaryFunction = multiClassSummary)\n## En este caso, se realiza una cros-validación de 10 etapas\n\n# se fija una semilla aleatoria\nset.seed(1994)\n\n# se entrena el modelo\nmodel &lt;- train(RENTA ~ .,  # . equivale a incluir todas las variables\n               data = rtrain,\n               method = \"rpart\",\n               metric = \"Accuracy\",\n               trControl = trControl)\n\n# Obtenemos los valores del árbol óptimo\nmodel$finalModel\n\nn= 18669 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n 1) root 18669 8173 Media (0.10396915 0.33381542 0.56221544)  \n   2) DISTANCE_TO_DIAGONAL&gt;=1.697581 9078 3793 Baja (0.02599692 0.58217669 0.39182639)  \n     4) DISTANCE_TO_CITY_CENTER&lt; 1.182486 2168  144 Baja (0.00000000 0.93357934 0.06642066) *\n     5) DISTANCE_TO_CITY_CENTER&gt;=1.182486 6910 3497 Media (0.03415340 0.47192475 0.49392185)  \n      10) DISTANCE_TO_DIAGONAL&gt;=2.350599 4436 1689 Baja (0.02705140 0.61925158 0.35369702) *\n      11) DISTANCE_TO_DIAGONAL&lt; 2.350599 2474  630 Media (0.04688763 0.20776071 0.74535166) *\n   3) DISTANCE_TO_DIAGONAL&lt; 1.697581 9591 2652 Media (0.17777083 0.09873840 0.72349077) *\n\n# Generamos el gráfico del árbol\nrpart.plot(model$finalModel)\n\n\n\n\n\n\n\n\n\nlibrary(reshape2)\n\n# A continuación generamos un gráfico que nos permite ver la variabilidad de los estadísticos\n# calculados\nggplot(melt(model$resample[,c(2:5, 7:9, 12:13)]), aes(x = variable, y = value, fill=variable)) +\n  geom_boxplot(show.legend=FALSE) +\n  xlab(NULL) + ylab(NULL)\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Modelo de árbol de decisión\nmodel = DecisionTreeClassifier(random_state=1994)\n\nfrom sklearn.model_selection import cross_val_score\n\n# Realizar validación cruzada con 5 folds\nscores = cross_val_score(model, pyX_train, pyy_train, cv=10, scoring = 'accuracy')  # Métrica: accuracy\n\n# Mostrar resultados\nprint(f\"Accuracy por fold: {scores}\")\n\nAccuracy por fold: [0.90626674 0.90680236 0.8993037  0.90305303 0.91215854 0.90787359\n 0.89769684 0.90836013 0.914791   0.91425509]\n\nprint(f\"Accuracy promedio: {scores.mean():.4f}\")\n\nAccuracy promedio: 0.9071"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#realizando-hiperparámetro-tunning",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#realizando-hiperparámetro-tunning",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "4.4 Realizando hiperparámetro tunning",
    "text": "4.4 Realizando hiperparámetro tunning\n\nRPython\n\n\n\n# Detectamos cuales son los parámetros del modelo que podemos realizar hiperparámeter tunning\nmodelLookup(\"rpart\")\n\n  model parameter                label forReg forClass probModel\n1 rpart        cp Complexity Parameter   TRUE     TRUE      TRUE\n\n\n\n# Se especifica un rango de valores típicos para el hiperparámetro\ntuneGrid &lt;- expand.grid(cp = seq(0.01,0.05,0.01))\n\n\n# se entrena el modelo\nset.seed(1994)\n\nmodel &lt;- train(RENTA ~ .,\n               data = rtrain,\n               method = \"rpart\",\n               metric = \"Accuracy\",\n               trControl = trControl,\n               tuneGrid = tuneGrid)\n\n# Obtenemos la información del mejor modelo\nmodel$bestTune\n\n    cp\n1 0.01\n\n# Gráfico del árbol obtenido\nrpart.plot(model$finalModel)\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Definir rejilla de hiperparámetros\nparam_grid = {\n    'max_depth': [None, 5, 10],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4]\n}\n\n# Declaramos el modelo\nmodel = DecisionTreeClassifier(random_state=1994)\n\n# Configurar GridSearch con validación cruzada\ngrid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=10, scoring='accuracy', n_jobs=-1)\n\n# Ajustar modelo\ngrid_search.fit(pyX_train, pyy_train)\n\nGridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1994),\n             n_jobs=-1,\n             param_grid={'max_depth': [None, 5, 10],\n                         'min_samples_leaf': [1, 2, 4],\n                         'min_samples_split': [2, 5, 10]},\n             scoring='accuracy')In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  GridSearchCV?Documentation for GridSearchCViFittedGridSearchCV(cv=10, estimator=DecisionTreeClassifier(random_state=1994),\n             n_jobs=-1,\n             param_grid={'max_depth': [None, 5, 10],\n                         'min_samples_leaf': [1, 2, 4],\n                         'min_samples_split': [2, 5, 10]},\n             scoring='accuracy') best_estimator_: DecisionTreeClassifierDecisionTreeClassifier(random_state=1994)  DecisionTreeClassifier?Documentation for DecisionTreeClassifierDecisionTreeClassifier(random_state=1994) \n\n# Mostrar mejores parámetros\nprint(f\"Mejores parámetros: {grid_search.best_params_}\")\n\nMejores parámetros: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n\nprint(f\"Mejor accuracy: {grid_search.best_score_:.4f}\")\n\nMejor accuracy: 0.9071\n\n\n\nfrom sklearn import tree\ntree.plot_tree(grid_search.best_estimator_)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#como-realizar-poda-de-nuestro-árbol",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#como-realizar-poda-de-nuestro-árbol",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "4.5 Como realizar poda de nuestro árbol",
    "text": "4.5 Como realizar poda de nuestro árbol\n\nRPython\n\n\n\n# Con el objetivo de aumentar la generalidad del árbol y facilitar su interpretación, \n# se procede a reducir su tamaño podándolo. Para ello se establece el criterio de \n# que un nodo terminal tiene que tener, como mínimo, 50 observaciones.\nset.seed(1994)\nprunedtree &lt;- rpart(RENTA ~ ., data = rtrain,\n                    cp= 0.01, control = rpart.control(minbucket = 50))\n\nrpart.plot(prunedtree)\n\n\n\n\n\n\n\n\n\n\nEn Python, la poda de un árbol de decisión se puede realizar ajustando los hiperparámetros del árbol durante su creación. Estos hiperparámetros controlan el crecimiento del árbol y, por lo tanto, actúan como técnicas de poda preventiva o postpoda.\nscikit-learn no implementa poda dinámica directa (como ocurre en algunos otros frameworks), pero puedes limitar el tamaño del árbol y evitar sobreajuste mediante los siguientes métodos.\n\n4.5.1 Poda Preventiva (Pre-pruning)\nPoda preventiva consiste en detener el crecimiento del árbol antes de que se haga demasiado grande. Esto se logra ajustando hiperparámetros como:\n\nmax_depth: Profundidad máxima del árbol\nmin_samples_split: Número mínimo de muestras necesarias para dividir un nodo.\nmin_samples_leaf: Número mínimo de muestras necesarias en una hoja.\nmax_leaf_nodes: Número máximo de nodos hoja en el árbol.\n\n\n# Crear un árbol con poda preventiva\nmodel = DecisionTreeClassifier(\n    max_depth=3,              # Limitar la profundidad\n    min_samples_split=10,     # Mínimo 10 muestras para dividir un nodo\n    min_samples_leaf=5,       # Mínimo 5 muestras por hoja\n    random_state=42\n)\n\n# Entrenar el modelo\nmodel.fit(pyX_train, pyy_train)\n\nDecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10,\n                       random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(max_depth=3, min_samples_leaf=5, min_samples_split=10,\n                       random_state=42) \n\n# Evaluar\nprint(f\"Accuracy en entrenamiento: {model.score(pyX_train, pyy_train):.4f}\")\n\nAccuracy en entrenamiento: 0.7919\n\nprint(f\"Accuracy en prueba: {model.score(pyX_test, pyy_test):.4f}\")\n\nAccuracy en prueba: 0.7932\n\n\n# Graficamos el árbol podado\ntree.plot_tree(model)\n\n\n\n\n\n\n\n\n\n\n4.5.2 Poda Posterior (Post-Pruning) con ccp_alpha\nSe puedes realizar poda posterior usando cost complexity pruning. Esto implica ajustar el parámetro ccp_alpha (el parámetro de complejidad de coste).\nEl árbol generará múltiples subárboles podados para diferentes valores de ccp_alpha, y tú puedes elegir el más adecuado evaluando su desempeño.\n\nimport matplotlib.pyplot as plt\n\n# Crear un árbol sin poda\nmodel = DecisionTreeClassifier(random_state=1994)\nmodel.fit(pyX_train, pyy_train)\n\nDecisionTreeClassifier(random_state=1994)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(random_state=1994) \n\n# Obtener valores de ccp_alpha\npath = model.cost_complexity_pruning_path(pyX_train, pyy_train)\nccp_alphas = path.ccp_alphas\nimpurities = path.impurities\n\n# Entrenar árboles para cada valor de ccp_alpha\nmodels = []\nfor ccp_alpha in ccp_alphas:\n    clf = DecisionTreeClassifier(random_state=42, ccp_alpha=ccp_alpha)\n    clf.fit(pyX_train, pyy_train)\n    models.append(clf)\n\nDecisionTreeClassifier(ccp_alpha=0.12113075107966081, random_state=42)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  DecisionTreeClassifier?Documentation for DecisionTreeClassifieriFittedDecisionTreeClassifier(ccp_alpha=0.12113075107966081, random_state=42) \n\n# Evaluar desempeño\ntrain_scores = [clf.score(pyX_train, pyy_train) for clf in models]\ntest_scores = [clf.score(pyX_test, pyy_test) for clf in models]\n\n# Graficar resultados\nplt.figure(figsize=(8, 6))\nplt.plot(ccp_alphas, train_scores, marker='o', label=\"Train Accuracy\", drawstyle=\"steps-post\")\nplt.plot(ccp_alphas, test_scores, marker='o', label=\"Test Accuracy\", drawstyle=\"steps-post\")\nplt.xlabel(\"ccp_alpha\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracy vs ccp_alpha\")\nplt.legend()\nplt.grid()\nplt.show()"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#aplicación-del-modelo",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#aplicación-del-modelo",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "5.1 Aplicación del modelo",
    "text": "5.1 Aplicación del modelo\n\nRPython\n\n\n\n# Random Forest \nlibrary(randomForest)\n## devtools::install_github('araastat/reprtree') # Se instala 1 vez para poder printar graficos\nlibrary(reprtree)\n\nset.seed(1994)\narbol_rf &lt;- randomForest(as.factor(RENTA) ~ .,  data = rtrain, ntree = 25)\n\n\n# se observa el árbol número 20\ntree20 &lt;- getTree(arbol_rf, 20, labelVar = TRUE)\nhead(tree20)\n\n  left daughter right daughter               split var split point status\n1             2              3         CONSTRUCTEDAREA  74.5000000      1\n2             4              5       DISTANCE_TO_METRO   0.7023313      1\n3             6              7              BATHNUMBER   2.5000000      1\n4             8              9             HASWARDROBE   1.5000000      1\n5            10             11       DISTANCE_TO_METRO   1.6344953      1\n6            12             13 DISTANCE_TO_CITY_CENTER   1.1452018      1\n  prediction\n1       &lt;NA&gt;\n2       &lt;NA&gt;\n3       &lt;NA&gt;\n4       &lt;NA&gt;\n5       &lt;NA&gt;\n6       &lt;NA&gt;\n\n## Sin embargo, el método por el que se representa gráficamente no es muy claro y\n## puede llevar a confusión o dificultar la interpretación del árbol. \n## Si se desea estudiar el árbol, hasta un cierto nivel, se puede incluir el argumento depth.\n## El árbol, ahora con una profundidad de 5 ramas.\nplot.getTree(arbol_rf, k = 20, depth = 5)\n\n\n\n\n\n\n\n\n\nlibrary(vip)\nvip(arbol_rf)\n\n\n\n\n\n\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\n\nclf = RandomForestClassifier()\nclf.fit(pyX_train, pyy_train)\n\nRandomForestClassifier()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestClassifier?Documentation for RandomForestClassifieriFittedRandomForestClassifier() \n\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nresults = pd.DataFrame(clf.feature_importances_, index=pyBCN.columns[:-1]).sort_values(by=0, ascending=False)\n\n# Crear gráfico de barras horizontales\nplt.figure(figsize=(10, 8))\nplt.barh(results.index, results[0], color='skyblue')\n\n# Añadir etiquetas y título\nplt.xlabel('Importancia')\nplt.ylabel('Características')\nplt.title('Importancia de las Características')\nplt.grid(axis='x', linestyle='--', alpha=0.7)\nplt.show()"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#hiperparameter-tunning-de-random-forest",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#hiperparameter-tunning-de-random-forest",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "5.2 Hiperparameter tunning de Random Forest",
    "text": "5.2 Hiperparameter tunning de Random Forest\n\nRPython\n\n\n\n# Identificamos los parámetros que podemos tunnerar\nmodelLookup(\"rf\")\n\n  model parameter                         label forReg forClass probModel\n1    rf      mtry #Randomly Selected Predictors   TRUE     TRUE      TRUE\n\n\n\n# Se especifica un rango de valores posibles de mtry\ntuneGrid &lt;- expand.grid(mtry = c(1, 2, 5, 10))\ntuneGrid\n\n  mtry\n1    1\n2    2\n3    5\n4   10\n\n\n\n# se fija la semilla aleatoria\nset.seed(1994)\n\n# se entrena el modelo\nmodel &lt;- train(RENTA ~ ., data = rtrain, \n               ntree = 20,\n               method = \"rf\", metric = \"Accuracy\",\n               tuneGrid = tuneGrid,\n               trControl = trainControl(classProbs = TRUE))\n\n# Visualizamos los hiperparámetros obtenidos \nmodel$results\n\n  mtry  Accuracy     Kappa  AccuracySD     KappaSD\n1    1 0.7114013 0.4050249 0.021913133 0.053223045\n2    2 0.8424843 0.7083545 0.005692328 0.011410794\n3    5 0.9015691 0.8223990 0.003130659 0.006087154\n4   10 0.9143875 0.8460688 0.002978894 0.005415628\n\n\n\n\n\n5.2.1 Ajuste de hiperparámetros con GridSearchCV\nEl GridSearchCV realiza una búsqueda exhaustiva sobre un conjunto de parámetros especificados. Probará todas las combinaciones posibles de hiperparámetros.\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n\n# Definir los parámetros para la búsqueda\nparam_dist = {\n    'n_estimators': [150, 200],        # Número de árboles en el bosque\n    'max_depth': [None, 10, 20],            # Profundidad máxima del árbol\n    'min_samples_split': [2, 5, 10],            # Número mínimo de muestras para dividir un nodo\n    'min_samples_leaf': [1, 2, 4],               # Número mínimo de muestras en una hoja\n    'max_features': ['auto'],      # Número de características a considerar para dividir un nodo\n    'bootstrap': [True]                      # Si usar bootstrap para los árboles\n}\n\n# Crear el modelo RandomForest\nrf = RandomForestClassifier(random_state = 1994)\n\n# Usar GridSearchCV para encontrar el mejor conjunto de parámetros\ngrid_search = GridSearchCV(estimator = rf, param_grid = param_grid, cv = 10, n_jobs = -1, verbose = 0)\n\n# Ajustar el modelo con los datos de entrenamiento\ngrid_search.fit(pyX_train, pyy_train)\n\n# Mostrar los mejores parámetros encontrados\nprint(\"Mejores parámetros encontrados:\", grid_search.best_params_)\n\ntree.plot_tree(grid_search.best_estimator_)\n\n\n\n5.2.2 Ajuste de Hiperparámetros con RandomizedSearchCV\nRandomizedSearchCV es una técnica más eficiente que GridSearchCV, ya que no prueba todas las combinaciones posibles, sino un número limitado de combinaciones aleatorias dentro de un rango definido. Esto es útil si el espacio de búsqueda es grande y quieres evitar un tiempo de cómputo muy largo.\n\n# Definir los parámetros para la búsqueda aleatoria\nparam_dist = {\n    'n_estimators': [150, 200],        # Número de árboles en el bosque\n    'max_depth': [None, 10, 20],            # Profundidad máxima del árbol\n    'min_samples_split': [2, 5, 10],            # Número mínimo de muestras para dividir un nodo\n    'min_samples_leaf': [1, 2, 4],               # Número mínimo de muestras en una hoja\n    'max_features': ['auto'],      # Número de características a considerar para dividir un nodo\n    'bootstrap': [True]                      # Si usar bootstrap para los árboles\n}\n\n# Usar RandomizedSearchCV para búsqueda aleatoria\nrandom_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist, \n                                   n_iter=50, cv=10, n_jobs=-1, random_state=1994)\n\n# Ajustar el modelo con los datos de entrenamiento\nrandom_search.fit(X_train, y_train)\n\n# Mostrar los mejores parámetros encontrados\nprint(\"Mejores parámetros encontrados:\", random_search.best_params_)\n\ntree.plot_tree(random_search.best_estimator_)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#predicciones-del-algoritmo",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#predicciones-del-algoritmo",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "5.3 Predicciones del algoritmo",
    "text": "5.3 Predicciones del algoritmo\n\nRPython\n\n\n\nprediccion &lt;- predict(arbol_rf, rtrain, type = \"class\")\ncaret::confusionMatrix(prediccion, as.factor(rtrain$RENTA))\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  Alta  Baja Media\n     Alta   1931     0     3\n     Baja      0  6211     7\n     Media    10    21 10486\n\nOverall Statistics\n                                         \n               Accuracy : 0.9978         \n                 95% CI : (0.997, 0.9984)\n    No Information Rate : 0.5622         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.9961         \n                                         \n Mcnemar's Test P-Value : NA             \n\nStatistics by Class:\n\n                     Class: Alta Class: Baja Class: Media\nSensitivity               0.9948      0.9966       0.9990\nSpecificity               0.9998      0.9994       0.9962\nPos Pred Value            0.9984      0.9989       0.9971\nNeg Pred Value            0.9994      0.9983       0.9988\nPrevalence                0.1040      0.3338       0.5622\nDetection Rate            0.1034      0.3327       0.5617\nDetection Prevalence      0.1036      0.3331       0.5633\nBalanced Accuracy         0.9973      0.9980       0.9976\n\n# Realizamos las predicciones de este ultimo arbol para la predicción de test\n## Si no decimos nada en type (type = prob), nos devolvera la probabilidad de \n## pertenecer a cada clase. \nprediccion &lt;- predict(arbol_rf, rtest, type = \"class\")\n## Para ver la performance, realizaremos la matriz de confusión \ncaret::confusionMatrix(prediccion, as.factor(rtest$RENTA))\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Alta Baja Media\n     Alta   344    1    52\n     Baja     1 1382    76\n     Media  122  134  2553\n\nOverall Statistics\n                                        \n               Accuracy : 0.9173        \n                 95% CI : (0.909, 0.925)\n    No Information Rate : 0.5747        \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16     \n                                        \n                  Kappa : 0.8478        \n                                        \n Mcnemar's Test P-Value : 1.382e-09     \n\nStatistics by Class:\n\n                     Class: Alta Class: Baja Class: Media\nSensitivity              0.73662      0.9110       0.9523\nSpecificity              0.98737      0.9755       0.8710\nPos Pred Value           0.86650      0.9472       0.9089\nNeg Pred Value           0.97118      0.9579       0.9310\nPrevalence               0.10011      0.3252       0.5747\nDetection Rate           0.07374      0.2962       0.5473\nDetection Prevalence     0.08510      0.3128       0.6021\nBalanced Accuracy        0.86200      0.9433       0.9116\n\n\n\nCM &lt;- caret::confusionMatrix(prediccion, as.factor(rtest$RENTA)); CM &lt;- data.frame(CM$table)\n\ngrafico &lt;- ggplot(CM, aes(Prediction,Reference, fill= Freq)) +\n        geom_tile() + geom_text(aes(label=Freq)) +\n        scale_fill_gradient(low=\"white\", high=\"#009194\") +\n        labs(x = \"Reference\",y = \"Prediction\")\n\nplot(grafico)\n\n\n\n\n\n\n\n\n\n\n\npreds = clf.predict(pyX_test)\nprint(f'Classification Report: \\n{classification_report(pyy_test, preds)}')\n\nClassification Report: \n              precision    recall  f1-score   support\n\n           0       0.90      0.77      0.83       488\n           1       0.95      0.90      0.93      1522\n           2       0.91      0.96      0.93      2657\n\n    accuracy                           0.92      4667\n   macro avg       0.92      0.88      0.90      4667\nweighted avg       0.92      0.92      0.92      4667\n\n\n\n# Confusion matrix\ncf_matrix = confusion_matrix(pyy_test, preds)\nsns.heatmap(cf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#aplicamos-el-algoritmo-con-cross-validation-e-hiperparameter-tunning",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#aplicamos-el-algoritmo-con-cross-validation-e-hiperparameter-tunning",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "6.1 Aplicamos el algoritmo con cross-validation e hiperparameter tunning",
    "text": "6.1 Aplicamos el algoritmo con cross-validation e hiperparameter tunning\n\nRPython\n\n\nPara aplicar los modelos de XGBoost es necesario pasar los datos categoricos en dummies. Una variable dummy (también conocida como cualitativa o binaria) es aquella que toma el valor 1 o 0 para indicar la presencia o ausencia de una cierta característica o condición.\n\n\nSi quisieramos hacerlo en cross validación hariamos lo siguiente:"
  },
  {
    "objectID": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#predicciones",
    "href": "material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.html#predicciones",
    "title": "Árboles de Decisión, Random Forest y XGBoost",
    "section": "6.2 Predicciones",
    "text": "6.2 Predicciones\n\nRPython"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos",
    "href": "index.html#introducción-a-la-mineria-de-datos",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "1 Introducción a la mineria de datos",
    "text": "1 Introducción a la mineria de datos\nLa minería de datos es el proceso de extraer patrones, tendencias y conocimientos útiles a partir de grandes volúmenes de datos. Combina estadística, aprendizaje automático y bases de datos para ayudar a resolver problemas en diversas áreas, como negocios, ciencia y tecnología.\nTeoria\nLaboratorio - Software Carpentry\nLaboratorio - Descriptive Analysis\nLaboratorio - Advanced Preprocessing"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-1",
    "href": "index.html#introducción-a-la-mineria-de-datos-1",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "2 [Introducción a la mineria de datos] ()",
    "text": "2 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-2",
    "href": "index.html#introducción-a-la-mineria-de-datos-2",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "3 [Introducción a la mineria de datos] ()",
    "text": "3 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-3",
    "href": "index.html#introducción-a-la-mineria-de-datos-3",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "4 [Introducción a la mineria de datos] ()",
    "text": "4 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-4",
    "href": "index.html#introducción-a-la-mineria-de-datos-4",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "5 [Introducción a la mineria de datos] ()",
    "text": "5 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-5",
    "href": "index.html#introducción-a-la-mineria-de-datos-5",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "6 [Introducción a la mineria de datos] ()",
    "text": "6 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-6",
    "href": "index.html#introducción-a-la-mineria-de-datos-6",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "7 [Introducción a la mineria de datos] ()",
    "text": "7 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-7",
    "href": "index.html#introducción-a-la-mineria-de-datos-7",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "8 [Introducción a la mineria de datos] ()",
    "text": "8 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-8",
    "href": "index.html#introducción-a-la-mineria-de-datos-8",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "9 [Introducción a la mineria de datos] ()",
    "text": "9 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-9",
    "href": "index.html#introducción-a-la-mineria-de-datos-9",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "10 [Introducción a la mineria de datos] ()",
    "text": "10 [Introducción a la mineria de datos] ()"
  },
  {
    "objectID": "index.html#introducción-a-la-mineria-de-datos-material",
    "href": "index.html#introducción-a-la-mineria-de-datos-material",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "11 [Introducción a la mineria de datos] (material/)",
    "text": "11 [Introducción a la mineria de datos] (material/)"
  },
  {
    "objectID": "index.html#árboles-de-decisión-y-métodos-de-ensamblado",
    "href": "index.html#árboles-de-decisión-y-métodos-de-ensamblado",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "12 Árboles de decisión y métodos de ensamblado",
    "text": "12 Árboles de decisión y métodos de ensamblado\npráctica"
  },
  {
    "objectID": "index.html#clustering",
    "href": "index.html#clustering",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "2 Clustering",
    "text": "2 Clustering\nEl clustering agrupa datos similares en clústeres basados en características compartidas. Es útil para descubrir patrones ocultos y segmentar conjuntos de datos, comúnmente aplicado en marketing, biología y análisis de redes.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#visualización-de-datos",
    "href": "index.html#visualización-de-datos",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "3 Visualización de datos",
    "text": "3 Visualización de datos\nLa visualización de datos convierte información compleja en gráficos y representaciones visuales claras, facilitando la interpretación y comunicación de resultados. Herramientas como gráficos de dispersión, histogramas y mapas de calor son fundamentales.\n\n3.1 Analisis de componentes principales (ACP)\nEl ACP reduce la dimensionalidad de los datos al identificar las combinaciones lineales más relevantes de las variables originales, conservando la mayor parte de la variación. Se usa para simplificar datos y facilitar su interpretación.\nTeoria\nLaboratorio\n\n\n3.2 Analisis de correspondiencias múltiples (ACM)\nEl ACM analiza tablas de datos categóricos para identificar relaciones entre categorías, visualizando patrones en mapas bidimensionales que facilitan la interpretación.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#reglas-de-asociación",
    "href": "index.html#reglas-de-asociación",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "4 Reglas de asociación",
    "text": "4 Reglas de asociación\nEste método identifica relaciones significativas entre variables en grandes bases de datos. Es clave en aplicaciones como los sistemas de recomendación y análisis de cestas de mercado.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#reglas-de-clasificación",
    "href": "index.html#reglas-de-clasificación",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "5 Reglas de clasificación",
    "text": "5 Reglas de clasificación\nLos modelos de clasificación asignan datos a categorías predefinidas basándose en patrones aprendidos. Es ampliamente usado en diagnóstico médico, detección de fraudes y análisis de texto.\n\n5.1 Lineal Discriminant Analysis (LDA) y Quadratic Discriminant Analysis (QDA)\nAmbos métodos buscan separar categorías utilizando fronteras de decisión basadas en estadísticas. LDA asume varianzas iguales entre clases, mientras que QDA permite varianzas diferentes.\nTeoria\nLaboratorio\n\n\n5.2 Naives Bayes\nUn clasificador basado en probabilidad que asume independencia entre las características. Es eficiente y se aplica en problemas como clasificación de texto y detección de spam.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#métodos-particionales",
    "href": "index.html#métodos-particionales",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "6 Métodos particionales",
    "text": "6 Métodos particionales\nDividen datos en subconjuntos o particiones, a menudo mediante árboles de decisión y técnicas relacionadas.\n\n6.1 Decisions Tree\nModelo gráfico que toma decisiones en base a condiciones secuenciales. Es intuitivo y útil en clasificación y regresión.\n\n\n6.2 Random Forest\nCombina múltiples árboles de decisión para mejorar precisión y reducir sobreajuste. Es robusto y adecuado para tareas de clasificación y regresión.\n\n\n6.3 Bagging & Boosting\nMétodos de ensamblado que mejoran el rendimiento combinando múltiples modelos. Bagging reduce la variabilidad, mientras que Boosting optimiza errores iterativamente.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#métodos-flexibles-de-discriminación",
    "href": "index.html#métodos-flexibles-de-discriminación",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "7 Métodos flexibles de discriminación",
    "text": "7 Métodos flexibles de discriminación\n\n7.1 Support Vectors Machines (SVM)\nSeparan clases usando hiperplanos óptimos en un espacio de alta dimensionalidad. Son efectivas en problemas no lineales y clasificación compleja.\nTeoria\nLaboratorio"
  },
  {
    "objectID": "index.html#deep-learning",
    "href": "index.html#deep-learning",
    "title": "Métodos Estadísticos para la mineria de datos",
    "section": "8 Deep Learning",
    "text": "8 Deep Learning\nEl aprendizaje profundo utiliza redes neuronales para modelar datos complejos. Es ampliamente aplicado en reconocimiento de imágenes, procesamiento de lenguaje natural y más.\n\n8.1 Redes neuronales: Discriminación pel perceptrón multicapa\nLas redes multicapa, basadas en múltiples capas de neuronas interconectadas, resuelven problemas no lineales con alta precisión.\n\n\n8.2 Redes neuronales convolucionales\nEspecializadas en procesar datos con estructura espacial, como imágenes. Extraen automáticamente características relevantes para tareas como clasificación de imágenes y visión por computadora.\nTeoria\nDatos de deportes\nDetección de imagenes deportivas\nDreamBooth (parte 1)\nImportante: Para poder hacer uso de este script es necesario que tengas:\n\nEntre 2 y 3 fotos de cuerpo entero\nEntre 3 y 5 fotos de medio cuerpo\nEntorno a 10 fotos de cara\n\nDreamBooth (parte 2)\nDreamBooth (completo)"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html",
    "href": "material/ANN/02_DreamBooth_parte2.html",
    "title": "DREAMBOOTH 🤖",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nDreambooth es un modelo de generación de aprendizaje profundo, y que fue desarrollado en 2022 por un grupo de investigadores de Google Research y la Universidad de Boston. La misión de esta tecnología es la de poder entrenar a modelos de inteligencia artificial para personalizarlo según tus necesidades.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#como-funciona",
    "href": "material/ANN/02_DreamBooth_parte2.html#como-funciona",
    "title": "DREAMBOOTH 🤖",
    "section": "¿Como funciona? 🔩",
    "text": "¿Como funciona? 🔩\nEl funcionamiento de esta técnica funciona en tres pasos.\n\nEn primer lugar, necesitas un modelo de difusión preentrenado, que es uno de esos sistemas de inteligencia artificial que pueden crear imágenes a partir de texto. Por ejemplo, se puede usar:\n\n\nStable Diffusion\nDALL-E\nMidjourney\n\nsiempre y cuando funcionen con el proceso de ruido y denoising.\nLo que hace esta técnica es crear una imagen completamente ruidosa, y luego ir quitando ese ruido reconstruyendo en el proceso una imagen totalmente original que se parezca a lo que le has pedido por texto. Pues es en este punto en el que Dreambooth ayudará con un modelo entrenado para que puedas obtener imágenes de sujetos concretos.\n\nel segundo paso, en el que necesitas un conjunto de imágenes del sujeto con el que quieres personalizar la IA. Puede ser un estilo, una cara, o lo que sea. Se recomienda tener un set de unas 8 o 10 imágenes como mínimo para poder entrenar el modelo.\n\nEntonces, lo que hace Dreambooth es utilizar este set de imágenes para entrenar al modelo de difusión, entrenar a la IA para que sepa reconocer lo que hay en ellas. Puede reconocer tu cara para luego poder dibujarla desde cero, así como un estilo o una posición.\n\nUna vez has usado Dreambooth para entrenar a la IA, este sistema usará las imágenes del sujeto como punto de partida para el proceso de crear la imagen aleatoria, permitiendo que la IA tenga más información sobre cómo es el sujeto que quieres dibujar, y que así pueda hacer imágenes que se parezcan a él.\n\n\n\n\nImagen"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#instalació-de-paquets",
    "href": "material/ANN/02_DreamBooth_parte2.html#instalació-de-paquets",
    "title": "DREAMBOOTH 🤖",
    "section": "Instalació de paquets",
    "text": "Instalació de paquets\n\nInstal·leu el paquet de Python Py-Dreambooth tal com es mostra a continuació.\n\n\n!pip install -q py_dreambooth"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#importa-mòduls",
    "href": "material/ANN/02_DreamBooth_parte2.html#importa-mòduls",
    "title": "DREAMBOOTH 🤖",
    "section": "Importa mòduls",
    "text": "Importa mòduls\n\nHi ha diversos tipus de classes de model, però estaràs utilitzant el model més bàsic, el model Stable Diffusion Dreambooth SDDreamboothModel, però no t’has de preocupar per això ara mateix. 🤷‍♂️\n\n\nfrom py_dreambooth.dataset import LocalDataset\nfrom py_dreambooth.model import SdDreamboothModel\nfrom py_dreambooth.predictor import LocalPredictor\nfrom py_dreambooth.trainer import LocalTrainer\nfrom py_dreambooth.utils.image_helpers import display_images\nfrom py_dreambooth.utils.prompt_helpers import make_prompt\n\nMontem la relació entre el google drive i el quadern de jupyter\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#preparem-les-dades",
    "href": "material/ANN/02_DreamBooth_parte2.html#preparem-les-dades",
    "title": "DREAMBOOTH 🤖",
    "section": "Preparem les dades 📸",
    "text": "Preparem les dades 📸\n\nDATA_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/data\"  # el directori amb fotos per a que el model s'entreni\nOUTPUT_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/models\"  # El directori on s'ubicaran els fitxers de model entrenats\n\ndataset = LocalDataset(DATA_DIR)\n\n\nMolt important! En el DATA_DIR definit anteriorment, posar les imatges (jpg o png) del subjecte que es vol entrenar.\nPer a aquesta tasca, necessitareu entre 10 i 20 solos, selfies d’alta qualitat preses amb diferents fons, il·luminació i expressions facials. Crec que es pot trobar un gran exemple al repositori de GitHub de Joe Penna.\n\n\n\n\nSamples\n\n\n\nUtilitzeu el mètode de processament d’imatges següent per retallar les imatges en un quadrat centrat a la cara. Si el subjecte que el model està tractant d’aprendre no és una persona (per exemple, un gos), estableix l’argument detect_face argumentant com a False.\n\n\ndataset = dataset.preprocess_images(detect_face=True)\n\nA total of 8 images were found.\n\n\n 38%|███▊      | 3/8 [00:00&lt;00:00,  6.17it/s]\n\n\nNo faces detected in the image '443008034_395930086752782_7217331932050061307_n.jpg'.\nNo faces detected in the image '440173417_1436258973657135_9081022692963550822_n.jpg'.\n\n\n 75%|███████▌  | 6/8 [00:00&lt;00:00,  6.41it/s]\n\n\nNo faces detected in the image '429164819_452647503759342_2302826312178258320_n.jpg'.\n\n\n100%|██████████| 8/8 [00:01&lt;00:00,  5.50it/s]\n\n\nA total of 5 images were preprocessed and stored in the path '/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc'."
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#carregar-el-model",
    "href": "material/ANN/02_DreamBooth_parte2.html#carregar-el-model",
    "title": "DREAMBOOTH 🤖",
    "section": "Carregar el model 🤖",
    "text": "Carregar el model 🤖\n\nSi reinicieu el nucli del bloc de notes i voleu tornar a carregar els models que ja heu entrenat, podeu fer-ho de la següent manera.\n\n\npredictor = LocalPredictor(model, OUTPUT_DIR)"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#crea-imatges-com-vulgueu",
    "href": "material/ANN/02_DreamBooth_parte2.html#crea-imatges-com-vulgueu",
    "title": "DREAMBOOTH 🤖",
    "section": "Crea imatges com vulgueu! 💃",
    "text": "Crea imatges com vulgueu! 💃\n\nUtilitzeu les indicacions per crear qualsevol imatge que vulgueu. El text de l’indicatiu ha de contenir el nom de l’assumpte i el nom de la classe definits anteriorment.\nTens problemes per arribar amb un bon prompte? No et preocupis. Podeu utilitzar la funció make_prompt per a generar una sol·licitud comissariada a l’atzar. Mira això. 🙆‍♀️\nLa creació de grans imatges pren paciència. Juga amb les indicacions, però si la qualitat de la pròpia generació és problemàtica, és possible que hagis de tornar a entrenar amb millors dades i paràmetres d’entrenament més adequats.\n\n\n%%time\nprompt = f\"A photo of {SUBJECT_NAME} {CLASS_NAME} with Simpsons\"\n# prompt = next(make_prompt(SUBJECT_NAME, CLASS_NAME))\n\nprint(f\"The prompt is as follows:\\n{prompt}\")\n\nimages = predictor.predict(\n    prompt,\n    height = 768,\n    width = 512,\n    num_images_per_prompt = 5,\n)\n\ndisplay_images(images, fig_size = 10)\n\nThe prompt is as follows:\nA photo of mire person with Simpsons\n\n\n\n\n\n\n\n\n\n\n\n\nCPU times: user 45.9 s, sys: 3.72 s, total: 49.6 s\nWall time: 50.3 s"
  },
  {
    "objectID": "material/ANN/02_DreamBooth_parte2.html#bibliografia",
    "href": "material/ANN/02_DreamBooth_parte2.html#bibliografia",
    "title": "DREAMBOOTH 🤖",
    "section": "Bibliografia 💃",
    "text": "Bibliografia 💃\n\nStable Diffusion\nDreamBooth\nPy-Dreambooth"
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html",
    "href": "material/ANN/01_DreamBooth_parte1.html",
    "title": "DREAMBOOTH 🤖",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nDreambooth es un modelo de generación de aprendizaje profundo, y que fue desarrollado en 2022 por un grupo de investigadores de Google Research y la Universidad de Boston. La misión de esta tecnología es la de poder entrenar a modelos de inteligencia artificial para personalizarlo según tus necesidades.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#como-funciona",
    "href": "material/ANN/01_DreamBooth_parte1.html#como-funciona",
    "title": "DREAMBOOTH 🤖",
    "section": "¿Como funciona? 🔩",
    "text": "¿Como funciona? 🔩\nEl funcionamiento de esta técnica funciona en tres pasos.\n\nEn primer lugar, necesitas un modelo de difusión preentrenado, que es uno de esos sistemas de inteligencia artificial que pueden crear imágenes a partir de texto. Por ejemplo, se puede usar:\n\n\nStable Diffusion\nDALL-E\nMidjourney\n\nsiempre y cuando funcionen con el proceso de ruido y denoising.\nLo que hace esta técnica es crear una imagen completamente ruidosa, y luego ir quitando ese ruido reconstruyendo en el proceso una imagen totalmente original que se parezca a lo que le has pedido por texto. Pues es en este punto en el que Dreambooth ayudará con un modelo entrenado para que puedas obtener imágenes de sujetos concretos.\n\nel segundo paso, en el que necesitas un conjunto de imágenes del sujeto con el que quieres personalizar la IA. Puede ser un estilo, una cara, o lo que sea. Se recomienda tener un set de unas 8 o 10 imágenes como mínimo para poder entrenar el modelo.\n\nEntonces, lo que hace Dreambooth es utilizar este set de imágenes para entrenar al modelo de difusión, entrenar a la IA para que sepa reconocer lo que hay en ellas. Puede reconocer tu cara para luego poder dibujarla desde cero, así como un estilo o una posición.\n\nUna vez has usado Dreambooth para entrenar a la IA, este sistema usará las imágenes del sujeto como punto de partida para el proceso de crear la imagen aleatoria, permitiendo que la IA tenga más información sobre cómo es el sujeto que quieres dibujar, y que así pueda hacer imágenes que se parezcan a él.\n\n\n\n\nImagen"
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#instalació-de-paquets",
    "href": "material/ANN/01_DreamBooth_parte1.html#instalació-de-paquets",
    "title": "DREAMBOOTH 🤖",
    "section": "Instalació de paquets",
    "text": "Instalació de paquets\n\nInstal·leu el paquet de Python Py-Dreambooth tal com es mostra a continuació.\n\n\n!pip install -q py_dreambooth"
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#importa-mòduls",
    "href": "material/ANN/01_DreamBooth_parte1.html#importa-mòduls",
    "title": "DREAMBOOTH 🤖",
    "section": "Importa mòduls",
    "text": "Importa mòduls\n\nHi ha diversos tipus de classes de model, però estaràs utilitzant el model més bàsic, el model Stable Diffusion Dreambooth SDDreamboothModel, però no t’has de preocupar per això ara mateix. 🤷‍♂️\n\n\nfrom py_dreambooth.dataset import LocalDataset\nfrom py_dreambooth.model import SdDreamboothModel\nfrom py_dreambooth.predictor import LocalPredictor\nfrom py_dreambooth.trainer import LocalTrainer\nfrom py_dreambooth.utils.image_helpers import display_images\nfrom py_dreambooth.utils.prompt_helpers import make_prompt\n\nMontem la relació entre el google drive i el quadern de jupyter\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#preparem-les-dades",
    "href": "material/ANN/01_DreamBooth_parte1.html#preparem-les-dades",
    "title": "DREAMBOOTH 🤖",
    "section": "Preparem les dades 📸",
    "text": "Preparem les dades 📸\n\nDATA_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/data\"  # el directori amb fotos per a que el model s'entreni\nOUTPUT_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/models\"  # El directori on s'ubicaran els fitxers de model entrenats\n\ndataset = LocalDataset(DATA_DIR)\n\n\nMolt important! En el DATA_DIR definit anteriorment, posar les imatges (jpg o png) del subjecte que es vol entrenar.\nPer a aquesta tasca, necessitareu entre 10 i 20 solos, selfies d’alta qualitat preses amb diferents fons, il·luminació i expressions facials. Crec que es pot trobar un gran exemple al repositori de GitHub de Joe Penna.\n\n\n\n\nSamples\n\n\n\nUtilitzeu el mètode de processament d’imatges següent per retallar les imatges en un quadrat centrat a la cara. Si el subjecte que el model està tractant d’aprendre no és una persona (per exemple, un gos), estableix l’argument detect_face argumentant com a False.\n\n\ndataset = dataset.preprocess_images(detect_face=True)\n\nA total of 8 images were found.\n\n\n 38%|███▊      | 3/8 [00:00&lt;00:00,  6.17it/s]\n\n\nNo faces detected in the image '443008034_395930086752782_7217331932050061307_n.jpg'.\nNo faces detected in the image '440173417_1436258973657135_9081022692963550822_n.jpg'.\n\n\n 75%|███████▌  | 6/8 [00:00&lt;00:00,  6.41it/s]\n\n\nNo faces detected in the image '429164819_452647503759342_2302826312178258320_n.jpg'.\n\n\n100%|██████████| 8/8 [00:01&lt;00:00,  5.50it/s]\n\n\nA total of 5 images were preprocessed and stored in the path '/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc'."
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#entrena-el-model",
    "href": "material/ANN/01_DreamBooth_parte1.html#entrena-el-model",
    "title": "DREAMBOOTH 🤖",
    "section": "Entrena el model 🤖",
    "text": "Entrena el model 🤖\n\nAra és el moment d’entrenar el model! Digues al model el nom del subjecte al qual vols entrenar (p. ex., Joe) i la classe a la qual pertany.\nEn definir un model, un dels arguments importants és quantes iteracions entrenar, o max.train.steps. S’accepta generalment que 800 a 1200 passos són apropiats per a una persona, i 200 a 400 passos són apropiats per a un animal no humà. El valor per defecte és 100 vegades el nombre de fotos que teniu. No cal que us preocupeu per això ara mateix ,🤷‍♂️, però si no us agraden els resultats de la imatge generada a continuació, aquest és el primer paràmetre a ajustar.\n\n\nSUBJECT_NAME = \"mire\"  # The name of the subject you want to learn\nCLASS_NAME = \"person\"  # The class to which the subject you want to learn belongs\n\nmodel = SdDreamboothModel(\n    subject_name = SUBJECT_NAME,\n    class_name = CLASS_NAME,\n    max_train_steps=400,\n)\n\ntrainer = LocalTrainer(output_dir = OUTPUT_DIR)\n\n\nEl temps d’entrenament del model pot ser tan curt com unes poques desenes de minuts o com diverses hores.\n\n\n%%time\npredictor = trainer.fit(model, dataset)\n\nThe model training has begun.\n'max_train_steps' is set to 400.\n\n\n╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮\n│ /usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py:1335 in time            │\n│                                                                                                  │\n│   1332 │   │   else:                                                                             │\n│   1333 │   │   │   st = clock2()                                                                 │\n│   1334 │   │   │   try:                                                                          │\n│ ❱ 1335 │   │   │   │   exec(code, glob, local_ns)                                                │\n│   1336 │   │   │   │   out=None                                                                  │\n│   1337 │   │   │   │   # multi-line %%time case                                                  │\n│   1338 │   │   │   │   if expr_val is not None:                                                  │\n│ in &lt;module&gt;:1                                                                                    │\n│                                                                                                  │\n│ /usr/local/lib/python3.10/dist-packages/py_dreambooth/trainer.py:124 in fit                      │\n│                                                                                                  │\n│   121 │   │   │   f\"The model training has begun.\\n'max_train_steps' is set to {max_train_step   │\n│   122 │   │   │   self.logger,                                                                   │\n│   123 │   │   )                                                                                  │\n│ ❱ 124 │   │   _ = subprocess.run(shlex.split(command), check=True)                               │\n│   125 │   │   log_or_print(\"The model training has ended.\", self.logger)                         │\n│   126 │   │                                                                                      │\n│   127 │   │   predictor = LocalPredictor(model, self.output_dir, self.logger)                    │\n│                                                                                                  │\n│ /usr/lib/python3.10/subprocess.py:526 in run                                                     │\n│                                                                                                  │\n│    523 │   │   │   raise                                                                         │\n│    524 │   │   retcode = process.poll()                                                          │\n│    525 │   │   if check and retcode:                                                             │\n│ ❱  526 │   │   │   raise CalledProcessError(retcode, process.args,                               │\n│    527 │   │   │   │   │   │   │   │   │    output=stdout, stderr=stderr)                        │\n│    528 │   return CompletedProcess(process.args, retcode, stdout, stderr)                        │\n│    529                                                                                           │\n╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\nCalledProcessError: Command '['accelerate', 'launch', \n'/usr/local/lib/python3.10/dist-packages/py_dreambooth/scripts/train/train_sd_dreambooth.py', \n'--pretrained_model_name_or_path', 'stabilityai/stable-diffusion-2-1-base', '--instance_data_dir', \n'/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc', '--instance_prompt', 'a photo of mire person', \n'--num_class_images', '200', '--output_dir', '/content/drive/MyDrive/ANN/DREAMBOOTH/models', '--resolution', '768',\n'--train_batch_size', '1', '--learning_rate', '2e-06', '--lr_scheduler', 'constant', '--lr_warmup_steps', '0', \n'--validation_prompt', 'a photo of mire person with Eiffel Tower in the background', '--compress_output', 'False', \n'--with_prior_preservation', 'True', '--prior_loss_weight', '1.0', '--class_prompt', 'a photo of person', \n'--train_text_encoder', 'True', '--max_train_steps', '400', '--gradient_accumulation_steps', '1', \n'--gradient_checkpointing', 'True', '--use_8bit_adam', 'True', '--enable_xformers_memory_efficient_attention', \n'True', '--mixed_precision', 'fp16', '--set_grads_to_none', 'True', '--report_to', 'tensorboard']' returned \nnon-zero exit status 1."
  },
  {
    "objectID": "material/ANN/01_DreamBooth_parte1.html#bibliografia",
    "href": "material/ANN/01_DreamBooth_parte1.html#bibliografia",
    "title": "DREAMBOOTH 🤖",
    "section": "Bibliografia 💃",
    "text": "Bibliografia 💃\n\nStable Diffusion\nDreamBooth\nPy-Dreambooth"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html",
    "title": "Convolutional Neural Networks",
    "section": "",
    "text": "import numpy as np\nimport os\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n\n!pip install keras\n\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\nRequirement already satisfied: typing-extensions&gt;=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree-&gt;keras) (4.12.2)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\n\n\n\nimport keras\nfrom keras.utils import to_categorical\nfrom keras import Input, Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\nfrom keras.layers import Conv2D, MaxPooling2D\n\nVamos a emparejar el notebook de python con el google drive\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n\nLa red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a 784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n\n\nimagen\n\n\n\n\n\ndirname = os.path.join(os.getcwd(), 'drive/MyDrive/DOCENCIA/ANN/sports')\nimgpath = dirname + os.sep\n\n\nimages = []\ndirectories = []\ndircount = []\nprevRoot=''\ncant=0\n\nprint(\"leyendo imagenes de \",imgpath)\n\nfor root, dirnames, filenames in os.walk(imgpath):\n    for filename in filenames:\n        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n            cant=cant+1\n            filepath = os.path.join(root, filename)\n            image = plt.imread(filepath)\n            images.append(image)\n            b = \"Leyendo...\" + str(cant)\n            print (b, end=\"\\r\")\n            if prevRoot !=root:\n                print(root, cant)\n                prevRoot=root\n                directories.append(root)\n                dircount.append(cant)\n                cant=0\ndircount.append(cant)\n\ndircount = dircount[1:]\ndircount[0]=dircount[0]+1\nprint('Directorios leidos:',len(directories))\nprint(\"Imagenes en cada directorio\", dircount)\nprint('suma Total de imagenes en subdirs:',sum(dircount))\n\nleyendo imagenes de  /content/drive/MyDrive/DOCENCIA/ANN/sports/\n/content/drive/MyDrive/DOCENCIA/ANN/sports/ciclismo 1\n/content/drive/MyDrive/DOCENCIA/ANN/sports/f1 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/futbol 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/basket 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/tenis 1000\nDirectorios leidos: 5\nImagenes en cada directorio [1001, 1000, 1000, 1000, 999]\nsuma Total de imagenes en subdirs: 5000\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#imagenes-y-píxeles",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#imagenes-y-píxeles",
    "title": "Convolutional Neural Networks",
    "section": "",
    "text": "La red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a 784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n\n\nimagen\n\n\n\n\n\ndirname = os.path.join(os.getcwd(), 'drive/MyDrive/DOCENCIA/ANN/sports')\nimgpath = dirname + os.sep\n\n\nimages = []\ndirectories = []\ndircount = []\nprevRoot=''\ncant=0\n\nprint(\"leyendo imagenes de \",imgpath)\n\nfor root, dirnames, filenames in os.walk(imgpath):\n    for filename in filenames:\n        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n            cant=cant+1\n            filepath = os.path.join(root, filename)\n            image = plt.imread(filepath)\n            images.append(image)\n            b = \"Leyendo...\" + str(cant)\n            print (b, end=\"\\r\")\n            if prevRoot !=root:\n                print(root, cant)\n                prevRoot=root\n                directories.append(root)\n                dircount.append(cant)\n                cant=0\ndircount.append(cant)\n\ndircount = dircount[1:]\ndircount[0]=dircount[0]+1\nprint('Directorios leidos:',len(directories))\nprint(\"Imagenes en cada directorio\", dircount)\nprint('suma Total de imagenes en subdirs:',sum(dircount))\n\nleyendo imagenes de  /content/drive/MyDrive/DOCENCIA/ANN/sports/\n/content/drive/MyDrive/DOCENCIA/ANN/sports/ciclismo 1\n/content/drive/MyDrive/DOCENCIA/ANN/sports/f1 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/futbol 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/basket 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/tenis 1000\nDirectorios leidos: 5\nImagenes en cada directorio [1001, 1000, 1000, 1000, 999]\nsuma Total de imagenes en subdirs: 5000"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#hacemos-el-one-hot-encoding-para-la-red",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#hacemos-el-one-hot-encoding-para-la-red",
    "title": "Convolutional Neural Networks",
    "section": "Hacemos el One-hot Encoding para la red",
    "text": "Hacemos el One-hot Encoding para la red\n\n# Change the labels from categorical to one-hot encoding\ntrain_Y_one_hot = to_categorical(train_Y)\ntest_Y_one_hot = to_categorical(test_Y)\n\n# Display the change for category label using one-hot encoding\nprint('Original label:', train_Y[0])\nprint('After conversion to one-hot:', train_Y_one_hot[0])\n\nOriginal label: 1\nAfter conversion to one-hot: [0. 1. 0. 0. 0.]"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#conjunto-de-kernels",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#conjunto-de-kernels",
    "title": "Convolutional Neural Networks",
    "section": "Conjunto de Kernels",
    "text": "Conjunto de Kernels\nCuando generamos nuestra matriz agregada, en realidad, no aplicaremos 1 sólo kernel, si no que tendremos muchos kernel (en su conjunto se llama filtros). Por ejemplo en esta primer convolución podríamos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como feature mapping), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra PRIMER CAPA OCULTA de neuronas.\n\n\nA medida que vamos desplazando el kernel y vamos obteniendo una nueva imagen filtrada por el kernel. En esta primer convolución y siguiendo con el ejemplo anterior, es como si obtuviéramos 32 imágenes filtradas nuevas. Estas imágenes nuevas lo que están “dibujando” son ciertas características de la imagen original. Esto ayudará en el futuro a poder distinguir un objeto de otro.\n\n\n\nimagen"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#max-pooling",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#max-pooling",
    "title": "Convolutional Neural Networks",
    "section": "Max-Pooling",
    "text": "Max-Pooling\nVamos a intentar explicarlo con un ejemplo: supongamos que haremos Max-pooling de tamaño 2×2. Esto quiere decir que recorreremos cada una de nuestras 32 imágenes de características obtenidas anteriormente de 28x28px de izquierda-derecha, arriba-abajo PERO en vez de tomar de a 1 pixel, tomaremos de “2×2” (2 de alto por 2 de ancho = 4 pixeles) e iremos preservando el valor “más alto” de entre esos 4 pixeles (por eso lo de “Max”). En este caso, usando 2×2, la imagen resultante es reducida “a la mitad”y quedará de 14×14 pixeles. Luego de este proceso de subsamplig nos quedarán 32 imágenes de 14×14, pasando de haber tenido 25.088 neuronas a 6.272, son bastantes menos y -en teoría- siguen almacenando la información más importante para detectar características deseadas.\n\n\n\nImagen\n\n\nMuy bien, pues esa ha sido una primer convolución: consiste de una entrada, un conjunto de filtros, generamos un mapa de características y hacemos un subsampling. Con lo cual, en el ejemplo de imágenes de 1 sólo color tendremos:\n\n\n\nImagen\n\n\nLa primer convolución es capaz de detectar características primitivas como lineas ó curvas. A medida que hagamos más capas con las convoluciones, los mapas de características serán capaces de reconocer formas más complejas, y el conjunto total de capas de convoluciones podrá ver.\nPues ahora deberemos hacer una Segunda convolución que será:\n\n\n\nImagen\n\n\nLa 3er convolución comenzará en tamaño 7×7 pixels y luego del max-pooling quedará en 3×3 con lo cual podríamos hacer sólo 1 convolución más. En este ejemplo empezamos con una imagen de 28x28px e hicimos 3 convoluciones. Si la imagen inicial hubiese sido mayor (de 224x224px) aún hubiéramos podido seguir haciendo convoluciones.\nLlegamos a la última convolución y nos queda el desenlace…\nPara terminar, tomaremos la última capa oculta a la que hicimos subsampling, que se dice que es tridimensional por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la aplanamos, esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas tradicionales, de las que ya conocíamos. Por ejemplo, podríamos aplanar (y conectar) a una nueva capa oculta de 100 neuronas feedforward.\n\n\n\nImagen\n\n\nEntonces, a esta nueva capa oculta tradicional, le aplicamos una función llamada Softmax que conecta contra la capa de salida final que tendrá la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, serán 2 neuronas. Si es el dataset Mnist numérico serán 10 neuronas de salida. Si clasificamos coches, aviones ó barcos serán 3, etc.\nLas salidas al momento del entrenamiento tendrán el formato conocido como one-hot-encoding en el que para perros y gatos sera: [1,0] y [0,1], para coches, aviones ó barcos será [1,0,0]; [0,1,0];[0,0,1].\nY la función de Softmax se encarga de pasar a probabilidad (entre 0 y 1) a las neuronas de salida. Por ejemplo una salida [0,2 0,8] nos indica 20% probabilidades de que sea perro y 80% de que sea gato."
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#backpropagation",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#backpropagation",
    "title": "Convolutional Neural Networks",
    "section": "Backpropagation",
    "text": "Backpropagation\nEl proceso es similar al de las redes tradicionales en las que tenemos una entrada y una salida esperada (por eso aprendizaje supervisado) y mediante el backpropagation mejoramos el valor de los pesos de las interconexiones entre capas de neuronas y a medida que iteramos esos pesos se ajustan hasta ser óptimos.\nEn el caso de la CNN, deberemos ajustar el valor de los pesos de los distintos kernels. Esto es una gran ventaja al momento del aprendizaje pues como vimos cada kernel es de un tamaño reducido, en nuestro ejemplo en la primer convolución es de tamaño de 3×3, eso son sólo 9 parámetros que debemos ajustar en 32 filtros dan un total de 288 parámetros. En comparación con los pesos entre dos capas de neuronas “tradicionales”: una de 748 y otra de 6272 en donde están TODAS interconectarlas con TODAS y eso equivaldría a tener que entrenar y ajustar más de 4,5 millones de pesos (repito: sólo para 1 capa)."
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#arquitectura-básica",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#arquitectura-básica",
    "title": "Convolutional Neural Networks",
    "section": "Arquitectura básica",
    "text": "Arquitectura básica\nResumiendo: podemos decir que los elementos que usamos para crear CNNs son:\n\nEntrada: Serán los pixeles de la imagen. Serán alto, ancho y profundidad será 1 sólo color o 3 para Red,Green,Blue.\nCapa De Convolución: procesará la salida de neuronas que están conectadas en “regiones locales” de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una pequeña región a la que están conectados en el volumen de entrada. Aquí usaremos por ejemplo 32 filtros o la cantidad que decidamos y ese será el volumen de salida.\n“CAPA RELU” aplicará la función de activación en los elementos de la matriz.\nPOOL ó SUBSAMPLING: Hará una reducción en las dimensiones alto y ancho, pero se mantiene la profundidad.\nCAPA “TRADICIONAL” red de neuronas feedforward que conectará con la última capa de subsampling y finalizará con la cantidad de neuronas que queremos clasificar."
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#declaración-de-parámetros",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#declaración-de-parámetros",
    "title": "Convolutional Neural Networks",
    "section": "Declaración de parámetros",
    "text": "Declaración de parámetros\n\n#declaramos variables con los parámetros de configuración de la red\nINIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\nepochs = 10 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\nbatch_size = 64 # cantidad de imágenes que se toman a la vez en memoria"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#construcción-del-modelo",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#construcción-del-modelo",
    "title": "Convolutional Neural Networks",
    "section": "Construcción del modelo",
    "text": "Construcción del modelo\n\nsport_model = Sequential()\nsport_model.add(Input(shape = (21, 28, 3)))\nsport_model.add(Conv2D(32, kernel_size = (3, 3), activation = 'linear', padding = 'same'))\nsport_model.add(LeakyReLU(negative_slope = 0.1))\nsport_model.add(MaxPooling2D((2, 2), padding = 'same'))\nsport_model.add(Dropout(0.5))\nsport_model.add(Flatten())\nsport_model.add(Dense(32, activation = 'linear'))\nsport_model.add(LeakyReLU(negative_slope = 0.1))\nsport_model.add(Dropout(0.5))\nsport_model.add(Dense(nClasses, activation = 'softmax'))\n\n\nsport_model.summary()\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_1 (Conv2D)                    │ (None, 21, 28, 32)          │             896 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (LeakyReLU)            │ (None, 21, 28, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (MaxPooling2D)       │ (None, 11, 14, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (Dropout)                  │ (None, 11, 14, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (Flatten)                  │ (None, 4928)                │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (Dense)                      │ (None, 32)                  │         157,728 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (LeakyReLU)            │ (None, 32)                  │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (Dropout)                  │ (None, 32)                  │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (Dense)                      │ (None, 5)                   │             165 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 158,789 (620.27 KB)\n\n\n\n Trainable params: 158,789 (620.27 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nfrom keras.utils import plot_model\n\nplot_model(sport_model, to_file='modelo_red_neuronal.png', show_shapes = True, show_layer_names = True)\n\n# Mostrar la imagen generada\nimg = plt.imread('modelo_red_neuronal.png')\nplt.imshow(img)\nplt.axis('off')  # Opcional: desactivar los ejes\nplt.show()\n\n\n\n\n\n\n\n\n\n# from tensorflow.keras.optimizers import Adagrad\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n# Define un programador de tasa de aprendizaje\nlr_schedule = ExponentialDecay(\n    initial_learning_rate = INIT_LR,  # Tasa de aprendizaje inicial\n    decay_steps = 100,                # Número de pasos para aplicar el decaimiento\n    decay_rate = INIT_LR / 100,       # Factor de decaimiento (0.96 es un ejemplo)\n    staircase = False                 # `False` para un decaimiento continuo\n)\n\n\n# Compilamos el modelo\nsport_model.compile(loss = \"categorical_crossentropy\",\n                    optimizer = Adam(learning_rate = lr_schedule),\n                    metrics = ['accuracy'])"
  },
  {
    "objectID": "material/ANN/Ejercicio_CNN_Deportes.html#tensorflow",
    "href": "material/ANN/Ejercicio_CNN_Deportes.html#tensorflow",
    "title": "Convolutional Neural Networks",
    "section": "TENSORFLOW",
    "text": "TENSORFLOW\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import TensorBoard\n\n# Definir el callback de TensorBoard\ntensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n\n\n# Compilar el modelo\nsport_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Entrenar el modelo con el callback\nsport_train = sport_model.fit(train_X, train_label, epochs = 10,\n                              callbacks = [tensorboard_callback],\n                              validation_data = (valid_X, valid_label))\n\nEpoch 1/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 24ms/step - accuracy: 0.9707 - loss: 0.0519 - val_accuracy: 0.9900 - val_loss: 0.0153\nEpoch 2/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 35ms/step - accuracy: 0.9760 - loss: 0.0437 - val_accuracy: 0.9875 - val_loss: 0.0167\nEpoch 3/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 31ms/step - accuracy: 0.9758 - loss: 0.0464 - val_accuracy: 0.9912 - val_loss: 0.0142\nEpoch 4/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9744 - loss: 0.0399 - val_accuracy: 0.9900 - val_loss: 0.0144\nEpoch 5/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - accuracy: 0.9780 - loss: 0.0379 - val_accuracy: 0.9912 - val_loss: 0.0127\nEpoch 6/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9818 - loss: 0.0367 - val_accuracy: 0.9937 - val_loss: 0.0125\nEpoch 7/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9846 - loss: 0.0299 - val_accuracy: 0.9950 - val_loss: 0.0110\nEpoch 8/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 31ms/step - accuracy: 0.9848 - loss: 0.0332 - val_accuracy: 0.9912 - val_loss: 0.0138\nEpoch 9/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9890 - loss: 0.0269 - val_accuracy: 0.9925 - val_loss: 0.0112\nEpoch 10/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - accuracy: 0.9879 - loss: 0.0291 - val_accuracy: 0.9937 - val_loss: 0.0117\n\n\n\n# Crear un callback de TensorBoard\nimport datetime\nlog_dir = \"/content/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n\n# Iniciar TensorBoard en Colab\n%load_ext tensorboard\n%tensorboard --logdir /content/logs/fit\n\nThe tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n\n\nReusing TensorBoard on port 6006 (pid 19935), started 0:01:09 ago. (Use '!kill 19935' to kill it.)"
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html",
    "title": "DREAMBOOTH 🤖",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nDreambooth es un modelo de generación de aprendizaje profundo, y que fue desarrollado en 2022 por un grupo de investigadores de Google Research y la Universidad de Boston. La misión de esta tecnología es la de poder entrenar a modelos de inteligencia artificial para personalizarlo según tus necesidades.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#como-funciona",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#como-funciona",
    "title": "DREAMBOOTH 🤖",
    "section": "¿Como funciona? 🔩",
    "text": "¿Como funciona? 🔩\nEl funcionamiento de esta técnica funciona en tres pasos.\n\nEn primer lugar, necesitas un modelo de difusión preentrenado, que es uno de esos sistemas de inteligencia artificial que pueden crear imágenes a partir de texto. Por ejemplo, se puede usar:\n\n\nStable Diffusion\nDALL-E\nMidjourney\n\nsiempre y cuando funcionen con el proceso de ruido y denoising.\nLo que hace esta técnica es crear una imagen completamente ruidosa, y luego ir quitando ese ruido reconstruyendo en el proceso una imagen totalmente original que se parezca a lo que le has pedido por texto. Pues es en este punto en el que Dreambooth ayudará con un modelo entrenado para que puedas obtener imágenes de sujetos concretos.\n\nel segundo paso, en el que necesitas un conjunto de imágenes del sujeto con el que quieres personalizar la IA. Puede ser un estilo, una cara, o lo que sea. Se recomienda tener un set de unas 8 o 10 imágenes como mínimo para poder entrenar el modelo.\n\nEntonces, lo que hace Dreambooth es utilizar este set de imágenes para entrenar al modelo de difusión, entrenar a la IA para que sepa reconocer lo que hay en ellas. Puede reconocer tu cara para luego poder dibujarla desde cero, así como un estilo o una posición.\n\nUna vez has usado Dreambooth para entrenar a la IA, este sistema usará las imágenes del sujeto como punto de partida para el proceso de crear la imagen aleatoria, permitiendo que la IA tenga más información sobre cómo es el sujeto que quieres dibujar, y que así pueda hacer imágenes que se parezcan a él.\n\n\n\n\nImagen"
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#instalació-de-paquets",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#instalació-de-paquets",
    "title": "DREAMBOOTH 🤖",
    "section": "Instalació de paquets",
    "text": "Instalació de paquets\n\nInstal·leu el paquet de Python Py-Dreambooth tal com es mostra a continuació.\n\n\n!pip install -q py_dreambooth"
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#importa-mòduls",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#importa-mòduls",
    "title": "DREAMBOOTH 🤖",
    "section": "Importa mòduls",
    "text": "Importa mòduls\n\nHi ha diversos tipus de classes de model, però estaràs utilitzant el model més bàsic, el model Stable Diffusion Dreambooth SDDreamboothModel, però no t’has de preocupar per això ara mateix. 🤷‍♂️\n\n\nfrom py_dreambooth.dataset import LocalDataset\nfrom py_dreambooth.model import SdDreamboothModel\nfrom py_dreambooth.predictor import LocalPredictor\nfrom py_dreambooth.trainer import LocalTrainer\nfrom py_dreambooth.utils.image_helpers import display_images\nfrom py_dreambooth.utils.prompt_helpers import make_prompt\n\nMontem la relació entre el google drive i el quadern de jupyter\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#preparem-les-dades",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#preparem-les-dades",
    "title": "DREAMBOOTH 🤖",
    "section": "Preparem les dades 📸",
    "text": "Preparem les dades 📸\n\nDATA_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/data\"  # el directori amb fotos per a que el model s'entreni\nOUTPUT_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/models\"  # El directori on s'ubicaran els fitxers de model entrenats\n\ndataset = LocalDataset(DATA_DIR)\n\n\nMolt important! En el DATA_DIR definit anteriorment, posar les imatges (jpg o png) del subjecte que es vol entrenar.\nPer a aquesta tasca, necessitareu entre 10 i 20 solos, selfies d’alta qualitat preses amb diferents fons, il·luminació i expressions facials. Crec que es pot trobar un gran exemple al repositori de GitHub de Joe Penna.\n\n\n\n\nSamples\n\n\n\nUtilitzeu el mètode de processament d’imatges següent per retallar les imatges en un quadrat centrat a la cara. Si el subjecte que el model està tractant d’aprendre no és una persona (per exemple, un gos), estableix l’argument detect_face argumentant com a False.\n\n\ndataset = dataset.preprocess_images(detect_face=True)\n\nA total of 8 images were found.\n\n\n 38%|███▊      | 3/8 [00:00&lt;00:00,  6.17it/s]\n\n\nNo faces detected in the image '443008034_395930086752782_7217331932050061307_n.jpg'.\nNo faces detected in the image '440173417_1436258973657135_9081022692963550822_n.jpg'.\n\n\n 75%|███████▌  | 6/8 [00:00&lt;00:00,  6.41it/s]\n\n\nNo faces detected in the image '429164819_452647503759342_2302826312178258320_n.jpg'.\n\n\n100%|██████████| 8/8 [00:01&lt;00:00,  5.50it/s]\n\n\nA total of 5 images were preprocessed and stored in the path '/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc'."
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#entrena-el-model",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#entrena-el-model",
    "title": "DREAMBOOTH 🤖",
    "section": "Entrena el model 🤖",
    "text": "Entrena el model 🤖\n\nAra és el moment d’entrenar el model! Digues al model el nom del subjecte al qual vols entrenar (p. ex., Joe) i la classe a la qual pertany.\nEn definir un model, un dels arguments importants és quantes iteracions entrenar, o max.train.steps. S’accepta generalment que 800 a 1200 passos són apropiats per a una persona, i 200 a 400 passos són apropiats per a un animal no humà. El valor per defecte és 100 vegades el nombre de fotos que teniu. No cal que us preocupeu per això ara mateix ,🤷‍♂️, però si no us agraden els resultats de la imatge generada a continuació, aquest és el primer paràmetre a ajustar.\n\n\nSUBJECT_NAME = \"mire\"  # The name of the subject you want to learn\nCLASS_NAME = \"person\"  # The class to which the subject you want to learn belongs\n\nmodel = SdDreamboothModel(\n    subject_name = SUBJECT_NAME,\n    class_name = CLASS_NAME,\n    max_train_steps=400,\n)\n\ntrainer = LocalTrainer(output_dir = OUTPUT_DIR)\n\n\nEl temps d’entrenament del model pot ser tan curt com unes poques desenes de minuts o com diverses hores.\n\n\n%%time\npredictor = trainer.fit(model, dataset)\n\nThe model training has begun.\n'max_train_steps' is set to 400.\n\n\n╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮\n│ /usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py:1335 in time            │\n│                                                                                                  │\n│   1332 │   │   else:                                                                             │\n│   1333 │   │   │   st = clock2()                                                                 │\n│   1334 │   │   │   try:                                                                          │\n│ ❱ 1335 │   │   │   │   exec(code, glob, local_ns)                                                │\n│   1336 │   │   │   │   out=None                                                                  │\n│   1337 │   │   │   │   # multi-line %%time case                                                  │\n│   1338 │   │   │   │   if expr_val is not None:                                                  │\n│ in &lt;module&gt;:1                                                                                    │\n│                                                                                                  │\n│ /usr/local/lib/python3.10/dist-packages/py_dreambooth/trainer.py:124 in fit                      │\n│                                                                                                  │\n│   121 │   │   │   f\"The model training has begun.\\n'max_train_steps' is set to {max_train_step   │\n│   122 │   │   │   self.logger,                                                                   │\n│   123 │   │   )                                                                                  │\n│ ❱ 124 │   │   _ = subprocess.run(shlex.split(command), check=True)                               │\n│   125 │   │   log_or_print(\"The model training has ended.\", self.logger)                         │\n│   126 │   │                                                                                      │\n│   127 │   │   predictor = LocalPredictor(model, self.output_dir, self.logger)                    │\n│                                                                                                  │\n│ /usr/lib/python3.10/subprocess.py:526 in run                                                     │\n│                                                                                                  │\n│    523 │   │   │   raise                                                                         │\n│    524 │   │   retcode = process.poll()                                                          │\n│    525 │   │   if check and retcode:                                                             │\n│ ❱  526 │   │   │   raise CalledProcessError(retcode, process.args,                               │\n│    527 │   │   │   │   │   │   │   │   │    output=stdout, stderr=stderr)                        │\n│    528 │   return CompletedProcess(process.args, retcode, stdout, stderr)                        │\n│    529                                                                                           │\n╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\nCalledProcessError: Command '['accelerate', 'launch', \n'/usr/local/lib/python3.10/dist-packages/py_dreambooth/scripts/train/train_sd_dreambooth.py', \n'--pretrained_model_name_or_path', 'stabilityai/stable-diffusion-2-1-base', '--instance_data_dir', \n'/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc', '--instance_prompt', 'a photo of mire person', \n'--num_class_images', '200', '--output_dir', '/content/drive/MyDrive/ANN/DREAMBOOTH/models', '--resolution', '768',\n'--train_batch_size', '1', '--learning_rate', '2e-06', '--lr_scheduler', 'constant', '--lr_warmup_steps', '0', \n'--validation_prompt', 'a photo of mire person with Eiffel Tower in the background', '--compress_output', 'False', \n'--with_prior_preservation', 'True', '--prior_loss_weight', '1.0', '--class_prompt', 'a photo of person', \n'--train_text_encoder', 'True', '--max_train_steps', '400', '--gradient_accumulation_steps', '1', \n'--gradient_checkpointing', 'True', '--use_8bit_adam', 'True', '--enable_xformers_memory_efficient_attention', \n'True', '--mixed_precision', 'fp16', '--set_grads_to_none', 'True', '--report_to', 'tensorboard']' returned \nnon-zero exit status 1."
  },
  {
    "objectID": "docs/material/ANN/01_DreamBooth_parte1.html#bibliografia",
    "href": "docs/material/ANN/01_DreamBooth_parte1.html#bibliografia",
    "title": "DREAMBOOTH 🤖",
    "section": "Bibliografia 💃",
    "text": "Bibliografia 💃\n\nStable Diffusion\nDreamBooth\nPy-Dreambooth"
  },
  {
    "objectID": "material/ANN/Script_dreambooth.html",
    "href": "material/ANN/Script_dreambooth.html",
    "title": "Machine Learning para Data Scientist",
    "section": "",
    "text": "Instalamos las dependencias. Es posible que nos pida reiniciar el el propio colab! Saldrá un botón de reiniciar. Una vez hecho, volveis a cargar la linia y funcionará!\n\n!pip install py-dreambooth\n\nRequirement already satisfied: py-dreambooth in /usr/local/lib/python3.10/dist-packages (0.2.8)\nRequirement already satisfied: accelerate&gt;=0.23.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (1.1.1)\nRequirement already satisfied: autocrop&gt;=1.3.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (1.3.0)\nRequirement already satisfied: awscli&gt;=1.29.41 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (1.36.20)\nRequirement already satisfied: bitsandbytes&gt;=0.41.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.45.0)\nRequirement already satisfied: diffusers&gt;=0.24.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.31.0)\nRequirement already satisfied: matplotlib&gt;=3.7.2 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (3.8.0)\nRequirement already satisfied: peft&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.13.2)\nRequirement already satisfied: pillow&gt;=9.4.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (11.0.0)\nRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (2.0.1)\nRequirement already satisfied: torchvision&gt;=0.15.2 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.15.2)\nRequirement already satisfied: sagemaker&gt;=2.183.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (2.237.0)\nRequirement already satisfied: tensorboard&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (2.17.1)\nRequirement already satisfied: tqdm&gt;=4.65.0 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (4.66.6)\nRequirement already satisfied: transformers&gt;=4.33.2 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (4.46.3)\nRequirement already satisfied: wandb&gt;=0.15.11 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.18.7)\nRequirement already satisfied: xformers&gt;=0.0.20 in /usr/local/lib/python3.10/dist-packages (from py-dreambooth) (0.0.22)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (3.16.1)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (1.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (3.1.4)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.7.99)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.7.99)\nRequirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.7.101)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.10.3.66)\nRequirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (10.9.0.58)\nRequirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (10.2.10.91)\nRequirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.4.0.1)\nRequirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.7.4.91)\nRequirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (2.14.3)\nRequirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (11.7.91)\nRequirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1-&gt;py-dreambooth) (2.0.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch==2.0.1-&gt;py-dreambooth) (75.1.0)\nRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66-&gt;torch==2.0.1-&gt;py-dreambooth) (0.45.1)\nRequirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch==2.0.1-&gt;py-dreambooth) (3.30.5)\nRequirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0-&gt;torch==2.0.1-&gt;py-dreambooth) (18.1.8)\nRequirement already satisfied: huggingface-hub&gt;=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (0.26.3)\nRequirement already satisfied: numpy&lt;3.0.0,&gt;=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (1.26.4)\nRequirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (5.9.5)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (6.0.2)\nRequirement already satisfied: safetensors&gt;=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate&gt;=0.23.0-&gt;py-dreambooth) (0.4.5)\nRequirement already satisfied: opencv-python-headless&lt;5,&gt;=3 in /usr/local/lib/python3.10/dist-packages (from autocrop&gt;=1.3.0-&gt;py-dreambooth) (4.10.0.84)\nRequirement already satisfied: botocore==1.35.79 in /usr/local/lib/python3.10/dist-packages (from awscli&gt;=1.29.41-&gt;py-dreambooth) (1.35.79)\nRequirement already satisfied: docutils&lt;0.17,&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from awscli&gt;=1.29.41-&gt;py-dreambooth) (0.16)\nRequirement already satisfied: s3transfer&lt;0.11.0,&gt;=0.10.0 in /usr/local/lib/python3.10/dist-packages (from awscli&gt;=1.29.41-&gt;py-dreambooth) (0.10.4)\nRequirement already satisfied: colorama&lt;0.4.7,&gt;=0.2.5 in /usr/local/lib/python3.10/dist-packages (from awscli&gt;=1.29.41-&gt;py-dreambooth) (0.4.6)\nRequirement already satisfied: rsa&lt;4.8,&gt;=3.1.2 in /usr/local/lib/python3.10/dist-packages (from awscli&gt;=1.29.41-&gt;py-dreambooth) (4.7.2)\nRequirement already satisfied: jmespath&lt;2.0.0,&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79-&gt;awscli&gt;=1.29.41-&gt;py-dreambooth) (1.0.1)\nRequirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79-&gt;awscli&gt;=1.29.41-&gt;py-dreambooth) (2.8.2)\nRequirement already satisfied: urllib3!=2.2.0,&lt;3,&gt;=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.35.79-&gt;awscli&gt;=1.29.41-&gt;py-dreambooth) (2.2.3)\nRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers&gt;=0.24.0-&gt;py-dreambooth) (6.11.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers&gt;=0.24.0-&gt;py-dreambooth) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers&gt;=0.24.0-&gt;py-dreambooth) (2.32.3)\nRequirement already satisfied: contourpy&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib&gt;=3.7.2-&gt;py-dreambooth) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib&gt;=3.7.2-&gt;py-dreambooth) (0.12.1)\nRequirement already satisfied: fonttools&gt;=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib&gt;=3.7.2-&gt;py-dreambooth) (4.55.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib&gt;=3.7.2-&gt;py-dreambooth) (1.4.7)\nRequirement already satisfied: pyparsing&gt;=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib&gt;=3.7.2-&gt;py-dreambooth) (3.2.0)\nRequirement already satisfied: attrs&lt;24,&gt;=23.1.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (23.2.0)\nRequirement already satisfied: boto3&lt;2.0,&gt;=1.35.75 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.35.79)\nRequirement already satisfied: cloudpickle==2.2.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.2.1)\nRequirement already satisfied: docker in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (7.1.0)\nRequirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.115.6)\nRequirement already satisfied: google-pasta in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.2.0)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (4.23.0)\nRequirement already satisfied: omegaconf&lt;2.3,&gt;=2.2 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.2.3)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.2.2)\nRequirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.3.3)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (4.3.6)\nRequirement already satisfied: protobuf&lt;5.0,&gt;=3.12 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (4.25.5)\nRequirement already satisfied: sagemaker-core&lt;2.0.0,&gt;=1.0.17 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.0.17)\nRequirement already satisfied: schema in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.7.7)\nRequirement already satisfied: smdebug-rulesconfig==1.0.1 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.0.1)\nRequirement already satisfied: tblib&lt;4,&gt;=1.7.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (3.0.0)\nRequirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.32.1)\nRequirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (1.4.0)\nRequirement already satisfied: grpcio&gt;=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (1.68.1)\nRequirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (3.7)\nRequirement already satisfied: six&gt;1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (1.16.0)\nRequirement already satisfied: tensorboard-data-server&lt;0.8.0,&gt;=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (0.7.2)\nRequirement already satisfied: werkzeug&gt;=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard&gt;=2.13.0-&gt;py-dreambooth) (3.1.3)\nRequirement already satisfied: tokenizers&lt;0.21,&gt;=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers&gt;=4.33.2-&gt;py-dreambooth) (0.20.3)\nRequirement already satisfied: click!=8.0.0,&gt;=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb&gt;=0.15.11-&gt;py-dreambooth) (8.1.7)\nRequirement already satisfied: docker-pycreds&gt;=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb&gt;=0.15.11-&gt;py-dreambooth) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,&gt;=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb&gt;=0.15.11-&gt;py-dreambooth) (3.1.43)\nRequirement already satisfied: sentry-sdk&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb&gt;=0.15.11-&gt;py-dreambooth) (2.19.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb&gt;=0.15.11-&gt;py-dreambooth) (1.3.4)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,&gt;=1.0.0-&gt;wandb&gt;=0.15.11-&gt;py-dreambooth) (4.0.11)\nRequirement already satisfied: fsspec&gt;=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub&gt;=0.21.0-&gt;accelerate&gt;=0.23.0-&gt;py-dreambooth) (2024.10.0)\nRequirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata-&gt;diffusers&gt;=0.24.0-&gt;py-dreambooth) (3.21.0)\nRequirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf&lt;2.3,&gt;=2.2-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (4.9.3)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers&gt;=0.24.0-&gt;py-dreambooth) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers&gt;=0.24.0-&gt;py-dreambooth) (3.10)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;diffusers&gt;=0.24.0-&gt;py-dreambooth) (2024.8.30)\nRequirement already satisfied: pyasn1&gt;=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa&lt;4.8,&gt;=3.1.2-&gt;awscli&gt;=1.29.41-&gt;py-dreambooth) (0.6.1)\nRequirement already satisfied: pydantic&lt;3.0.0,&gt;=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.10.3)\nRequirement already satisfied: rich&lt;14.0.0,&gt;=13.0.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (13.9.4)\nRequirement already satisfied: mock&lt;5.0,&gt;4.0 in /usr/local/lib/python3.10/dist-packages (from sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (4.0.3)\nRequirement already satisfied: jsonschema-specifications&gt;=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2024.10.1)\nRequirement already satisfied: referencing&gt;=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.35.1)\nRequirement already satisfied: rpds-py&gt;=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.22.3)\nRequirement already satisfied: MarkupSafe&gt;=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug&gt;=1.0.1-&gt;tensorboard&gt;=2.13.0-&gt;py-dreambooth) (3.0.2)\nRequirement already satisfied: starlette&lt;0.42.0,&gt;=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.41.3)\nRequirement already satisfied: pytz&gt;=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2024.2)\nRequirement already satisfied: tzdata&gt;=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2024.2)\nRequirement already satisfied: ppft&gt;=1.7.6.9 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.7.6.9)\nRequirement already satisfied: dill&gt;=0.3.9 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.3.9)\nRequirement already satisfied: pox&gt;=0.3.5 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.3.5)\nRequirement already satisfied: multiprocess&gt;=0.70.17 in /usr/local/lib/python3.10/dist-packages (from pathos-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.70.17)\nRequirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy-&gt;torch==2.0.1-&gt;py-dreambooth) (1.3.0)\nRequirement already satisfied: h11&gt;=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.14.0)\nRequirement already satisfied: smmap&lt;6,&gt;=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython!=3.1.29,&gt;=1.0.0-&gt;wandb&gt;=0.15.11-&gt;py-dreambooth) (5.0.1)\nRequirement already satisfied: annotated-types&gt;=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic&lt;3.0.0,&gt;=2.0.0-&gt;sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.7.0)\nRequirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic&lt;3.0.0,&gt;=2.0.0-&gt;sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.27.1)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich&lt;14.0.0,&gt;=13.0.0-&gt;sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich&lt;14.0.0,&gt;=13.0.0-&gt;sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (2.18.0)\nRequirement already satisfied: anyio&lt;5,&gt;=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (3.7.1)\nRequirement already satisfied: sniffio&gt;=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio&lt;5,&gt;=3.4.0-&gt;starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.3.1)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio&lt;5,&gt;=3.4.0-&gt;starlette&lt;0.42.0,&gt;=0.40.0-&gt;fastapi-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (1.2.2)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich&lt;14.0.0,&gt;=13.0.0-&gt;sagemaker-core&lt;2.0.0,&gt;=1.0.17-&gt;sagemaker&gt;=2.183.0-&gt;py-dreambooth) (0.1.2)\n\n\nIndicamos el directorio de nuestros datos y donde queremos que se guarde nuestro modelo. Necesario crear la carpeta de las imágenes si no la tenemos creada.\n\nfrom py_dreambooth.dataset import LocalDataset\nfrom py_dreambooth.model import SdDreamboothModel\nfrom py_dreambooth.trainer import LocalTrainer\nfrom py_dreambooth.utils.image_helpers import display_images\nfrom py_dreambooth.utils.prompt_helpers import make_prompt\n\nDATA_DIR = \"data\"  # The directory where you put your prepared photos\nOUTPUT_DIR = \"models\"\n\n'dataset = LocalDataset(DATA_DIR)\\ndataset = dataset.preprocess_images(detect_face=True)\\n\\nSUBJECT_NAME = \"&lt;YOUR-NAME&gt;\"  \\nCLASS_NAME = \"person\"\\n\\nmodel = SdDreamboothModel(subject_name=SUBJECT_NAME, class_name=CLASS_NAME)\\ntrainer = LocalTrainer(output_dir=OUTPUT_DIR)\\n\\npredictor = trainer.fit(model, dataset)\\n\\n# Use the prompt helper to create an awesome AI avatar!\\nprompt = next(make_prompt(SUBJECT_NAME, CLASS_NAME))\\n\\nimages = predictor.predict(\\n    prompt, height=768, width=512, num_images_per_prompt=2,\\n)\\n\\ndisplay_images(images, fig_size=10)'\n\n\nCreamos el dataset e indicamos nuestro nombre\n\ndataset = LocalDataset(DATA_DIR)\ndataset = dataset.preprocess_images(detect_face=True)\n\nSUBJECT_NAME = \"&lt;YOUR-NAME&gt;\"  #Incluir tu nombre sin los &lt;&gt;!\nCLASS_NAME = \"person\"\n\nA total of 8 images were found.\n\n\n100%|██████████| 8/8 [00:00&lt;00:00, 10.87it/s]\n\n\nA total of 8 images were preprocessed and stored in the path 'data_preproc'.\n\n\n\n\n\nCreamos el modelo y lo entrenamos con nuestros datos\nSi se aumenta el parámetro de max_train_steps tardará más el entrenamiento (50 son 12 min aprox)\n\nmodel = SdDreamboothModel(subject_name=SUBJECT_NAME, class_name=CLASS_NAME, max_train_steps=20)\ntrainer = LocalTrainer(output_dir=OUTPUT_DIR)\n\npredictor = trainer.fit(model, dataset)\n\nThe model training has begun.\n'max_train_steps' is set to 50.\nThe model training has ended.\n\n\n\n\n\nThe model has loaded from the directory, 'models'.\n\n\nCreamos el prompt i creamos las imágenes con nuestro modelo ya entrenado\n\n#prompt = next(make_prompt(SUBJECT_NAME, CLASS_NAME)) #Es para crear un prompt random!!\n\nprompt = f\"A hyper-realistic and stunning depiction of {SUBJECT_NAME} {CLASS_NAME}, capturing the person's charisma and charm, trending on Behance, intricate textures, vivid color palette, reminiscent of Alex Ross and Norman Rockwell\"\n\nimages = predictor.predict(\n    prompt, height=768, width=512, num_images_per_prompt=2,\n)\n\ndisplay_images(images, fig_size=10)\n\nWarning: the subject and class names are not included in the prompt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/FactorialMethods/ACP.html",
    "href": "material/FactorialMethods/ACP.html",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "",
    "text": "L’anàlisi de correspondencies simples (ACS) s’utilitza per a descriure taules de contingència 1 (TC) mitjançant la representació geomètrica de les taules de condicionals fila i columna (perfils) derivades d’aquelles.\nL’objectiu de l’ACS és descriure les associacions entre les variables fila i columna, a través dels seus perfils:\n\nComparar els perfilis fila.\nComparar els perfilis columna.\nEstudiar les correspondències entre perfils fila i columna\n\nLa metodologia la va desenvolupar Benzecri, a principis dels anys 60 del segle XX en la Universitat de Renner (França). En essència. és un tipus especial d’anàlisi de components principals però realitzat sobre una taula de contingència i usant una distància euclidiana ponderada anomenada chi-quadrat (\\(\\chi^{2}\\))\n\n\nLa prova de chi-quadrat (\\(\\chi^{2}\\)) és un mètode estadístic que s’utilitza per a determinar si existeix una associació significativa entre variables categòriques comparant les freqüències observades i esperades en una taula de contingència.\nH0 : No hi ha associació significativa entre les variables.\nH1 : Hi ha una associació significativa entre les variables.\nPer a realitzar la prova chi-quadrat (\\(\\chi^{2}\\)):\n1- Crear una taula de contingència amb les freqüències observades per a cada categoria.\n2- Calcular les freqüències esperades assumint la independència entre les variables.\n3- Calcular l’estadístic chi-quadrat (\\(\\chi^{2}\\)).\nComparar l’estadístic calculat amb el valor crític de la distribució chi-quadrat (\\(\\chi^{2}\\)) per a determinar si es rebutja o no la hipòtesi nul·la.\n\\[\n  \\chi^{2} = \\sum{\\frac{(O_{ij}-E_{ij})^{2}}{E_{ij}}}\n\\] Ón:\n\n\\(chi-quadrat (\\)^{2}\\()\\): El estadístic de prova \\(\\chi^{2}\\), medeix la discrepancia entre els valors observats i els esperats\n\\(\\sum\\) (sigma): Suma els valors de cada cela de la taula de contingència.\n\\(O_{ij}\\): La freqüència observada en cada cel·la de la taula de contingència.\n\\(E_{ij}\\): La freqüència esperada en cada cel·la de la taula de contingència.\n\nCasos d’ús d’exemple\n\nAvaluar la relació entre les variables demogràfiques (per exemple, edat, gènere, ingressos) i les preferències del consumidor o el comportament de compra.\nExaminar l’associació entre els factors de risc i els resultats de les malalties, com el tabaquisme i la incidència el càncer de pulmó.\nExplorar la relació entre variables categòriques com el nivell educatiu i la situació laboral o l’afiliació política i el comportament electoral.\nDeterminar si els patrons d’herència observats són consistents amb les proporcions mendelianes esperades, o si uns certs marcadors genètics estan associats amb trets o malalties específiques.\nAvaluar la relació entre les variables de control de qualitat, com el tipus de defecte, i la línia de producció.\n\nSuposicions\n\nIndependència: L’ocurrència d’una observació no ha d’influir ni ser influenciada per una altra observació.\nCategòric: Totes dues variables són per a dades categòriques.\nMútuament excloents: Les observacions només poden pertànyer a una cel·la de la taula de contingència.\nGrandària de la mostra: Ha d’haver-hi almenys cinc observacions en cada cel·la de la taula de contingència.\n\nProves alternatives\nProva exacta de Fisher: adequada quan la grandària de la mostra és petit i les freqüències de cel·la esperades en la taula de contingència són inferiors a 5. Sovint s’utilitza com a alternativa a la prova de chi-quadrat en taules de contingència de 2x2.\nProva de McNemar: s’utilitza en analitzar dades categòriques aparellades, generalment en una taula de contingència de 2x2, on les observacions són dependents o estan relacionades. S’utilitza comunament en estudis d’abans i després o en estudis de casos i controls aparellats.\nProva de Cochran-Estovalles-Haenszel: s’utilitza en analitzar dades categòriques en estudis estratificats o aparellats. Permet la comparació de múltiples taules de contingència 2x2 mentre controla variables de confusió o factors d’estratificació.\n\nlibrary(\"factoextra\")\nlibrary(\"FactoMineR\")\nlibrary(\"gplots\")\nlibrary(\"dplyr\")\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/FactorialMethods/ACP.html#introducció",
    "href": "material/FactorialMethods/ACP.html#introducció",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "",
    "text": "L’anàlisi de correspondencies simples (ACS) s’utilitza per a descriure taules de contingència 1 (TC) mitjançant la representació geomètrica de les taules de condicionals fila i columna (perfils) derivades d’aquelles.\nL’objectiu de l’ACS és descriure les associacions entre les variables fila i columna, a través dels seus perfils:\n\nComparar els perfilis fila.\nComparar els perfilis columna.\nEstudiar les correspondències entre perfils fila i columna\n\nLa metodologia la va desenvolupar Benzecri, a principis dels anys 60 del segle XX en la Universitat de Renner (França). En essència. és un tipus especial d’anàlisi de components principals però realitzat sobre una taula de contingència i usant una distància euclidiana ponderada anomenada chi-quadrat (\\(\\chi^{2}\\))\n\n\nLa prova de chi-quadrat (\\(\\chi^{2}\\)) és un mètode estadístic que s’utilitza per a determinar si existeix una associació significativa entre variables categòriques comparant les freqüències observades i esperades en una taula de contingència.\nH0 : No hi ha associació significativa entre les variables.\nH1 : Hi ha una associació significativa entre les variables.\nPer a realitzar la prova chi-quadrat (\\(\\chi^{2}\\)):\n1- Crear una taula de contingència amb les freqüències observades per a cada categoria.\n2- Calcular les freqüències esperades assumint la independència entre les variables.\n3- Calcular l’estadístic chi-quadrat (\\(\\chi^{2}\\)).\nComparar l’estadístic calculat amb el valor crític de la distribució chi-quadrat (\\(\\chi^{2}\\)) per a determinar si es rebutja o no la hipòtesi nul·la.\n\\[\n  \\chi^{2} = \\sum{\\frac{(O_{ij}-E_{ij})^{2}}{E_{ij}}}\n\\] Ón:\n\n\\(chi-quadrat (\\)^{2}\\()\\): El estadístic de prova \\(\\chi^{2}\\), medeix la discrepancia entre els valors observats i els esperats\n\\(\\sum\\) (sigma): Suma els valors de cada cela de la taula de contingència.\n\\(O_{ij}\\): La freqüència observada en cada cel·la de la taula de contingència.\n\\(E_{ij}\\): La freqüència esperada en cada cel·la de la taula de contingència.\n\nCasos d’ús d’exemple\n\nAvaluar la relació entre les variables demogràfiques (per exemple, edat, gènere, ingressos) i les preferències del consumidor o el comportament de compra.\nExaminar l’associació entre els factors de risc i els resultats de les malalties, com el tabaquisme i la incidència el càncer de pulmó.\nExplorar la relació entre variables categòriques com el nivell educatiu i la situació laboral o l’afiliació política i el comportament electoral.\nDeterminar si els patrons d’herència observats són consistents amb les proporcions mendelianes esperades, o si uns certs marcadors genètics estan associats amb trets o malalties específiques.\nAvaluar la relació entre les variables de control de qualitat, com el tipus de defecte, i la línia de producció.\n\nSuposicions\n\nIndependència: L’ocurrència d’una observació no ha d’influir ni ser influenciada per una altra observació.\nCategòric: Totes dues variables són per a dades categòriques.\nMútuament excloents: Les observacions només poden pertànyer a una cel·la de la taula de contingència.\nGrandària de la mostra: Ha d’haver-hi almenys cinc observacions en cada cel·la de la taula de contingència.\n\nProves alternatives\nProva exacta de Fisher: adequada quan la grandària de la mostra és petit i les freqüències de cel·la esperades en la taula de contingència són inferiors a 5. Sovint s’utilitza com a alternativa a la prova de chi-quadrat en taules de contingència de 2x2.\nProva de McNemar: s’utilitza en analitzar dades categòriques aparellades, generalment en una taula de contingència de 2x2, on les observacions són dependents o estan relacionades. S’utilitza comunament en estudis d’abans i després o en estudis de casos i controls aparellats.\nProva de Cochran-Estovalles-Haenszel: s’utilitza en analitzar dades categòriques en estudis estratificats o aparellats. Permet la comparació de múltiples taules de contingència 2x2 mentre controla variables de confusió o factors d’estratificació.\n\nlibrary(\"factoextra\")\nlibrary(\"FactoMineR\")\nlibrary(\"gplots\")\nlibrary(\"dplyr\")"
  },
  {
    "objectID": "material/FactorialMethods/ACP.html#definició-del-problema",
    "href": "material/FactorialMethods/ACP.html#definició-del-problema",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "2 Definició del problema",
    "text": "2 Definició del problema\n\ndata(\"housetasks\")\nhead(housetasks)\n\n           Wife Alternating Husband Jointly\nLaundry     156          14       2       4\nMain_meal   124          20       5       4\nDinner       77          11       7      13\nBreakfeast   82          36      15       7\nTidying      53          11       1      57\nDishes       32          24       4      53\n\ncolnames(housetasks) &lt;- c(\"Dona\", \"Alternant\", \"Marit\", \"Conjuntament\")\nrownames(housetasks) &lt;- c(\"Bugaderia\", \"Dinar\", \"Sopar\", \"Esmorçar\", \"Ordenar\", \"Netejar_Plats\", \"Compres\", \"Oficial\", \"Conduir\", \"Finances\", \"Assegurança\", \"Reparacions\", \"Vacances\")\n\ndf &lt;- as.table(as.matrix(housetasks))\ndf\n\n              Dona Alternant Marit Conjuntament\nBugaderia      156        14     2            4\nDinar          124        20     5            4\nSopar           77        11     7           13\nEsmorçar        82        36    15            7\nOrdenar         53        11     1           57\nNetejar_Plats   32        24     4           53\nCompres         33        23     9           55\nOficial         12        46    23           15\nConduir         10        51    75            3\nFinances        13        13    21           66\nAssegurança      8         1    53           77\nReparacions      0         3   160            2\nVacances         0         1     6          153\n\n\n\nballoonplot(t(df), label=F, main=\"Tareas del hogar\")"
  },
  {
    "objectID": "material/FactorialMethods/ACP.html#prova-de-la-chi2",
    "href": "material/FactorialMethods/ACP.html#prova-de-la-chi2",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "3 Prova de la \\(\\chi^{2}\\)",
    "text": "3 Prova de la \\(\\chi^{2}\\)\n\\(H_{0}\\): Variables independents (hipòtesi nula) \\(H_{1}\\): Variables dependents (hipòtesi alternativa)\n\nchisq.test(housetasks)\n\n\n    Pearson's Chi-squared test\n\ndata:  housetasks\nX-squared = 1944.5, df = 36, p-value &lt; 2.2e-16\n\n\nEs refusa l’hipòtesi nula en favor de la alternativa, les parelles s’organitzen per fer les tasques de la llar."
  },
  {
    "objectID": "material/FactorialMethods/ACP.html#anàlisi-de-correspondència-simple-acs",
    "href": "material/FactorialMethods/ACP.html#anàlisi-de-correspondència-simple-acs",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "4 Anàlisi de Correspondència Simple (ACS)",
    "text": "4 Anàlisi de Correspondència Simple (ACS)\n\nhousetasks_CA &lt;- CA(housetasks, graph = F)\nprint(housetasks_CA)\n\n**Results of the Correspondence Analysis (CA)**\nThe row variable has  13  categories; the column variable has 4 categories\nThe chi square of independence between the two variables is equal to 1944.456 (p-value =  0 ).\n*The results are available in the following objects:\n\n   name              description                   \n1  \"$eig\"            \"eigenvalues\"                 \n2  \"$col\"            \"results for the columns\"     \n3  \"$col$coord\"      \"coord. for the columns\"      \n4  \"$col$cos2\"       \"cos2 for the columns\"        \n5  \"$col$contrib\"    \"contributions of the columns\"\n6  \"$row\"            \"results for the rows\"        \n7  \"$row$coord\"      \"coord. for the rows\"         \n8  \"$row$cos2\"       \"cos2 for the rows\"           \n9  \"$row$contrib\"    \"contributions of the rows\"   \n10 \"$call\"           \"summary called parameters\"   \n11 \"$call$marge.col\" \"weights of the columns\"      \n12 \"$call$marge.row\" \"weights of the rows\"         \n\n\n\nhousetasks_CA$col\n\n$coord\n                   Dim 1      Dim 2       Dim 3\nDona         -0.83762154  0.3652207 -0.19991139\nAlternant    -0.06218462  0.2915938  0.84858939\nMarit         1.16091847  0.6019199 -0.18885924\nConjuntament  0.14942609 -1.0265791 -0.04644302\n\n$contrib\n                 Dim 1     Dim 2      Dim 3\nDona         44.462018 10.312237 10.8220753\nAlternant     0.103739  2.782794 82.5492464\nMarit        54.233879 17.786612  6.1331792\nConjuntament  1.200364 69.118357  0.4954991\n\n$cos2\n                   Dim 1     Dim 2       Dim 3\nDona         0.801875947 0.1524482 0.045675847\nAlternant    0.004779897 0.1051016 0.890118521\nMarit        0.772026244 0.2075420 0.020431728\nConjuntament 0.020705858 0.9772939 0.002000236\n\n$inertia\n[1] 0.3010185 0.1178242 0.3813729 0.3147248\n\n\n\nhousetasks_CA$row\n\n$coord\n                   Dim 1      Dim 2       Dim 3\nBugaderia     -0.9918368  0.4953220 -0.31672897\nDinar         -0.8755855  0.4901092 -0.16406487\nSopar         -0.6925740  0.3081043 -0.20741377\nEsmorçar      -0.5086002  0.4528038  0.22040453\nOrdenar       -0.3938084 -0.4343444 -0.09421375\nNetejar_Plats -0.1889641 -0.4419662  0.26694926\nCompres       -0.1176813 -0.4033171  0.20261512\nOficial        0.2266324  0.2536132  0.92336416\nConduir        0.7417696  0.6534143  0.54445849\nFinances       0.2707669 -0.6178684  0.03479681\nAssegurança    0.6470759 -0.4737832 -0.28936051\nReparacions    1.5287787  0.8642647 -0.47208778\nVacances       0.2524863 -1.4350066 -0.12958665\n\n$contrib\n                   Dim 1      Dim 2       Dim 3\nBugaderia     18.2867003  5.5638913  7.96842443\nDinar         12.3888433  4.7355230  1.85868941\nSopar          5.4713982  1.3210221  2.09692603\nEsmorçar       3.8249284  3.6986131  3.06939857\nOrdenar        1.9983518  2.9656441  0.48873403\nNetejar_Plats  0.4261663  2.8441170  3.63429434\nCompres        0.1755248  2.5151584  2.22335679\nOficial        0.5207837  0.7956201 36.94038942\nConduir        8.0778371  7.6468564 18.59638635\nFinances       0.8750075  5.5585460  0.06175066\nAssegurança    6.1470616  4.0203590  5.25263863\nReparacions   40.7300940 15.8806509 16.59639139\nVacances       1.0773030 42.4539986  1.21261994\n\n$cos2\n                   Dim 1      Dim 2       Dim 3\nBugaderia     0.73998741 0.18455213 0.075460467\nDinar         0.74160285 0.23235928 0.026037873\nSopar         0.77664011 0.15370323 0.069656660\nEsmorçar      0.50494329 0.40023001 0.094826699\nOrdenar       0.43981243 0.53501508 0.025172490\nNetejar_Plats 0.11811778 0.64615253 0.235729693\nCompres       0.06365362 0.74765514 0.188691242\nOficial       0.05304464 0.06642648 0.880528877\nConduir       0.43201860 0.33522911 0.232752289\nFinances      0.16067678 0.83666958 0.002653634\nAssegurança   0.57601197 0.30880208 0.115185951\nReparacions   0.70673575 0.22587147 0.067392778\nVacances      0.02979239 0.96235977 0.007847841\n\n$inertia\n [1] 0.13415976 0.09069235 0.03824633 0.04112368 0.02466697 0.01958732\n [7] 0.01497017 0.05330000 0.10150885 0.02956446 0.05793584 0.31287411\n[13] 0.19631064\n\n\n\nfviz_screeplot(housetasks_CA, addlabel=T)\n\n\n\n\n\n\n\n\nEl 89% de la variança de les variables están explicades per les dimensiones 1 i 2.\n\nfviz_ca_biplot(housetasks_CA,repel = T)\n\n\n\n\n\n\n\n\nLa descripció del gràfic és el següent:\n\nBlau: Corresponen a les files\nVermell: Corresponen a les columnes\n\nD’aqui podem extreure les següents conclusions:\n1- Les tasques de dinar, sopar, estendre i esmorçar son realitzades amb més freqüéncia per les dones.\n2- Les tasques de conduir i fer reparacions es realitzen amb més freqüéncia pels marits.\n3- Les tasques de vacances, finances i seguretat ho fan en conjunt.\nPer tal de poder descriure les dimensions, podem realitzar un gràfic de correlacions.\n\nlibrary(corrplot)\ncorrplot(housetasks_CA$col$cos2)\n\n\n\n\n\n\n\n\nUtilitzem la distància \\(cos^{2}\\) per la variable de tasques.\n\ncorrplot(housetasks_CA$row$cos2 )\n\n\n\n\n\n\n\n\nD’aquí podem extreure que:\n\nLa 1a component fa referència a tasques realitzades de manera individual\nLa 2a component fa referència a tasques realitzades de manera col·lectiva.\n\nA continuació anem a veure la contribució de cada columna a cada dimensió:\n\nfviz_contrib(housetasks_CA, choice = \"col\" ,axes = 1)\n\n\n\n\n\n\n\n\n\nfviz_contrib(housetasks_CA, choice = \"col\" ,axes = 2)\n\n\n\n\n\n\n\n\n\nfviz_contrib(housetasks_CA, choice = \"col\" ,axes = 1:2)\n\n\n\n\n\n\n\n\n\nfviz_contrib(housetasks_CA, choice = \"row\" ,axes = 1)\n\n\n\n\n\n\n\n\n\nfviz_contrib(housetasks_CA, choice = \"row\" ,axes = 2)\n\n\n\n\n\n\n\n\n\nfviz_contrib(housetasks_CA, choice = \"row\" ,axes = 1:2)\n\n\n\n\n\n\n\n\n\nfviz_ca_biplot(housetasks_CA,repel = T, arrow = c(F,T), col.col = \"cos2\", \n               gradient.cols = c(\"red\", \"yellow\", \"green\"),\n               alpha.col = \"contrib\")"
  },
  {
    "objectID": "material/FactorialMethods/ACP.html#footnotes",
    "href": "material/FactorialMethods/ACP.html#footnotes",
    "title": "Anàlisis de Components Principals (ACP)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nEn estadística les taules de contingència s’empren per a registrar i analitzar l’associació entre dues o més variables, habitualment de naturalesa qualitativa (nominals o ordinals).↩︎"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html",
    "title": "Convolutional Neural Networks",
    "section": "",
    "text": "import numpy as np\nimport os\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n\n\n!pip install keras\n\nRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\nRequirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras) (3.12.1)\nRequirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras) (24.2)\nRequirement already satisfied: typing-extensions&gt;=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree-&gt;keras) (4.12.2)\nRequirement already satisfied: markdown-it-py&gt;=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (3.0.0)\nRequirement already satisfied: pygments&lt;3.0.0,&gt;=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich-&gt;keras) (2.18.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py&gt;=2.2.0-&gt;rich-&gt;keras) (0.1.2)\n\n\n\nimport keras\nfrom keras.utils import to_categorical\nfrom keras import Input, Model\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, LeakyReLU\nfrom keras.layers import Conv2D, MaxPooling2D\n\nVamos a emparejar el notebook de python con el google drive\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n\nLa red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a 784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n\n\nimagen\n\n\n\n\n\ndirname = os.path.join(os.getcwd(), 'drive/MyDrive/DOCENCIA/ANN/sports')\nimgpath = dirname + os.sep\n\n\nimages = []\ndirectories = []\ndircount = []\nprevRoot=''\ncant=0\n\nprint(\"leyendo imagenes de \",imgpath)\n\nfor root, dirnames, filenames in os.walk(imgpath):\n    for filename in filenames:\n        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n            cant=cant+1\n            filepath = os.path.join(root, filename)\n            image = plt.imread(filepath)\n            images.append(image)\n            b = \"Leyendo...\" + str(cant)\n            print (b, end=\"\\r\")\n            if prevRoot !=root:\n                print(root, cant)\n                prevRoot=root\n                directories.append(root)\n                dircount.append(cant)\n                cant=0\ndircount.append(cant)\n\ndircount = dircount[1:]\ndircount[0]=dircount[0]+1\nprint('Directorios leidos:',len(directories))\nprint(\"Imagenes en cada directorio\", dircount)\nprint('suma Total de imagenes en subdirs:',sum(dircount))\n\nleyendo imagenes de  /content/drive/MyDrive/DOCENCIA/ANN/sports/\n/content/drive/MyDrive/DOCENCIA/ANN/sports/ciclismo 1\n/content/drive/MyDrive/DOCENCIA/ANN/sports/f1 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/futbol 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/basket 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/tenis 1000\nDirectorios leidos: 5\nImagenes en cada directorio [1001, 1000, 1000, 1000, 999]\nsuma Total de imagenes en subdirs: 5000\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#imagenes-y-píxeles",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#imagenes-y-píxeles",
    "title": "Convolutional Neural Networks",
    "section": "",
    "text": "La red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a 784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n\n\nimagen\n\n\n\n\n\ndirname = os.path.join(os.getcwd(), 'drive/MyDrive/DOCENCIA/ANN/sports')\nimgpath = dirname + os.sep\n\n\nimages = []\ndirectories = []\ndircount = []\nprevRoot=''\ncant=0\n\nprint(\"leyendo imagenes de \",imgpath)\n\nfor root, dirnames, filenames in os.walk(imgpath):\n    for filename in filenames:\n        if re.search(\"\\.(jpg|jpeg|png|bmp|tiff)$\", filename):\n            cant=cant+1\n            filepath = os.path.join(root, filename)\n            image = plt.imread(filepath)\n            images.append(image)\n            b = \"Leyendo...\" + str(cant)\n            print (b, end=\"\\r\")\n            if prevRoot !=root:\n                print(root, cant)\n                prevRoot=root\n                directories.append(root)\n                dircount.append(cant)\n                cant=0\ndircount.append(cant)\n\ndircount = dircount[1:]\ndircount[0]=dircount[0]+1\nprint('Directorios leidos:',len(directories))\nprint(\"Imagenes en cada directorio\", dircount)\nprint('suma Total de imagenes en subdirs:',sum(dircount))\n\nleyendo imagenes de  /content/drive/MyDrive/DOCENCIA/ANN/sports/\n/content/drive/MyDrive/DOCENCIA/ANN/sports/ciclismo 1\n/content/drive/MyDrive/DOCENCIA/ANN/sports/f1 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/futbol 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/basket 1000\n/content/drive/MyDrive/DOCENCIA/ANN/sports/tenis 1000\nDirectorios leidos: 5\nImagenes en cada directorio [1001, 1000, 1000, 1000, 999]\nsuma Total de imagenes en subdirs: 5000"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#hacemos-el-one-hot-encoding-para-la-red",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#hacemos-el-one-hot-encoding-para-la-red",
    "title": "Convolutional Neural Networks",
    "section": "Hacemos el One-hot Encoding para la red",
    "text": "Hacemos el One-hot Encoding para la red\n\n# Change the labels from categorical to one-hot encoding\ntrain_Y_one_hot = to_categorical(train_Y)\ntest_Y_one_hot = to_categorical(test_Y)\n\n# Display the change for category label using one-hot encoding\nprint('Original label:', train_Y[0])\nprint('After conversion to one-hot:', train_Y_one_hot[0])\n\nOriginal label: 1\nAfter conversion to one-hot: [0. 1. 0. 0. 0.]"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#conjunto-de-kernels",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#conjunto-de-kernels",
    "title": "Convolutional Neural Networks",
    "section": "Conjunto de Kernels",
    "text": "Conjunto de Kernels\nCuando generamos nuestra matriz agregada, en realidad, no aplicaremos 1 sólo kernel, si no que tendremos muchos kernel (en su conjunto se llama filtros). Por ejemplo en esta primer convolución podríamos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como feature mapping), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra PRIMER CAPA OCULTA de neuronas.\n\n\nA medida que vamos desplazando el kernel y vamos obteniendo una nueva imagen filtrada por el kernel. En esta primer convolución y siguiendo con el ejemplo anterior, es como si obtuviéramos 32 imágenes filtradas nuevas. Estas imágenes nuevas lo que están “dibujando” son ciertas características de la imagen original. Esto ayudará en el futuro a poder distinguir un objeto de otro.\n\n\n\nimagen"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#max-pooling",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#max-pooling",
    "title": "Convolutional Neural Networks",
    "section": "Max-Pooling",
    "text": "Max-Pooling\nVamos a intentar explicarlo con un ejemplo: supongamos que haremos Max-pooling de tamaño 2×2. Esto quiere decir que recorreremos cada una de nuestras 32 imágenes de características obtenidas anteriormente de 28x28px de izquierda-derecha, arriba-abajo PERO en vez de tomar de a 1 pixel, tomaremos de “2×2” (2 de alto por 2 de ancho = 4 pixeles) e iremos preservando el valor “más alto” de entre esos 4 pixeles (por eso lo de “Max”). En este caso, usando 2×2, la imagen resultante es reducida “a la mitad”y quedará de 14×14 pixeles. Luego de este proceso de subsamplig nos quedarán 32 imágenes de 14×14, pasando de haber tenido 25.088 neuronas a 6.272, son bastantes menos y -en teoría- siguen almacenando la información más importante para detectar características deseadas.\n\n\n\nImagen\n\n\nMuy bien, pues esa ha sido una primer convolución: consiste de una entrada, un conjunto de filtros, generamos un mapa de características y hacemos un subsampling. Con lo cual, en el ejemplo de imágenes de 1 sólo color tendremos:\n\n\n\nImagen\n\n\nLa primer convolución es capaz de detectar características primitivas como lineas ó curvas. A medida que hagamos más capas con las convoluciones, los mapas de características serán capaces de reconocer formas más complejas, y el conjunto total de capas de convoluciones podrá ver.\nPues ahora deberemos hacer una Segunda convolución que será:\n\n\n\nImagen\n\n\nLa 3er convolución comenzará en tamaño 7×7 pixels y luego del max-pooling quedará en 3×3 con lo cual podríamos hacer sólo 1 convolución más. En este ejemplo empezamos con una imagen de 28x28px e hicimos 3 convoluciones. Si la imagen inicial hubiese sido mayor (de 224x224px) aún hubiéramos podido seguir haciendo convoluciones.\nLlegamos a la última convolución y nos queda el desenlace…\nPara terminar, tomaremos la última capa oculta a la que hicimos subsampling, que se dice que es tridimensional por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la aplanamos, esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas tradicionales, de las que ya conocíamos. Por ejemplo, podríamos aplanar (y conectar) a una nueva capa oculta de 100 neuronas feedforward.\n\n\n\nImagen\n\n\nEntonces, a esta nueva capa oculta tradicional, le aplicamos una función llamada Softmax que conecta contra la capa de salida final que tendrá la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, serán 2 neuronas. Si es el dataset Mnist numérico serán 10 neuronas de salida. Si clasificamos coches, aviones ó barcos serán 3, etc.\nLas salidas al momento del entrenamiento tendrán el formato conocido como one-hot-encoding en el que para perros y gatos sera: [1,0] y [0,1], para coches, aviones ó barcos será [1,0,0]; [0,1,0];[0,0,1].\nY la función de Softmax se encarga de pasar a probabilidad (entre 0 y 1) a las neuronas de salida. Por ejemplo una salida [0,2 0,8] nos indica 20% probabilidades de que sea perro y 80% de que sea gato."
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#backpropagation",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#backpropagation",
    "title": "Convolutional Neural Networks",
    "section": "Backpropagation",
    "text": "Backpropagation\nEl proceso es similar al de las redes tradicionales en las que tenemos una entrada y una salida esperada (por eso aprendizaje supervisado) y mediante el backpropagation mejoramos el valor de los pesos de las interconexiones entre capas de neuronas y a medida que iteramos esos pesos se ajustan hasta ser óptimos.\nEn el caso de la CNN, deberemos ajustar el valor de los pesos de los distintos kernels. Esto es una gran ventaja al momento del aprendizaje pues como vimos cada kernel es de un tamaño reducido, en nuestro ejemplo en la primer convolución es de tamaño de 3×3, eso son sólo 9 parámetros que debemos ajustar en 32 filtros dan un total de 288 parámetros. En comparación con los pesos entre dos capas de neuronas “tradicionales”: una de 748 y otra de 6272 en donde están TODAS interconectarlas con TODAS y eso equivaldría a tener que entrenar y ajustar más de 4,5 millones de pesos (repito: sólo para 1 capa)."
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#arquitectura-básica",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#arquitectura-básica",
    "title": "Convolutional Neural Networks",
    "section": "Arquitectura básica",
    "text": "Arquitectura básica\nResumiendo: podemos decir que los elementos que usamos para crear CNNs son:\n\nEntrada: Serán los pixeles de la imagen. Serán alto, ancho y profundidad será 1 sólo color o 3 para Red,Green,Blue.\nCapa De Convolución: procesará la salida de neuronas que están conectadas en “regiones locales” de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una pequeña región a la que están conectados en el volumen de entrada. Aquí usaremos por ejemplo 32 filtros o la cantidad que decidamos y ese será el volumen de salida.\n“CAPA RELU” aplicará la función de activación en los elementos de la matriz.\nPOOL ó SUBSAMPLING: Hará una reducción en las dimensiones alto y ancho, pero se mantiene la profundidad.\nCAPA “TRADICIONAL” red de neuronas feedforward que conectará con la última capa de subsampling y finalizará con la cantidad de neuronas que queremos clasificar."
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#declaración-de-parámetros",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#declaración-de-parámetros",
    "title": "Convolutional Neural Networks",
    "section": "Declaración de parámetros",
    "text": "Declaración de parámetros\n\n#declaramos variables con los parámetros de configuración de la red\nINIT_LR = 1e-3 # Valor inicial de learning rate. El valor 1e-3 corresponde con 0.001\nepochs = 10 # Cantidad de iteraciones completas al conjunto de imagenes de entrenamiento\nbatch_size = 64 # cantidad de imágenes que se toman a la vez en memoria"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#construcción-del-modelo",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#construcción-del-modelo",
    "title": "Convolutional Neural Networks",
    "section": "Construcción del modelo",
    "text": "Construcción del modelo\n\nsport_model = Sequential()\nsport_model.add(Input(shape = (21, 28, 3)))\nsport_model.add(Conv2D(32, kernel_size = (3, 3), activation = 'linear', padding = 'same'))\nsport_model.add(LeakyReLU(negative_slope = 0.1))\nsport_model.add(MaxPooling2D((2, 2), padding = 'same'))\nsport_model.add(Dropout(0.5))\nsport_model.add(Flatten())\nsport_model.add(Dense(32, activation = 'linear'))\nsport_model.add(LeakyReLU(negative_slope = 0.1))\nsport_model.add(Dropout(0.5))\nsport_model.add(Dense(nClasses, activation = 'softmax'))\n\n\nsport_model.summary()\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)                         ┃ Output Shape                ┃         Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d_1 (Conv2D)                    │ (None, 21, 28, 32)          │             896 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_2 (LeakyReLU)            │ (None, 21, 28, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (MaxPooling2D)       │ (None, 11, 14, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_2 (Dropout)                  │ (None, 11, 14, 32)          │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ flatten_1 (Flatten)                  │ (None, 4928)                │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_2 (Dense)                      │ (None, 32)                  │         157,728 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ leaky_re_lu_3 (LeakyReLU)            │ (None, 32)                  │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout_3 (Dropout)                  │ (None, 32)                  │               0 │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_3 (Dense)                      │ (None, 5)                   │             165 │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n\n\n\n Total params: 158,789 (620.27 KB)\n\n\n\n Trainable params: 158,789 (620.27 KB)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nfrom keras.utils import plot_model\n\nplot_model(sport_model, to_file='modelo_red_neuronal.png', show_shapes = True, show_layer_names = True)\n\n# Mostrar la imagen generada\nimg = plt.imread('modelo_red_neuronal.png')\nplt.imshow(img)\nplt.axis('off')  # Opcional: desactivar los ejes\nplt.show()\n\n\n\n\n\n\n\n\n\n# from tensorflow.keras.optimizers import Adagrad\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\n\n# Define un programador de tasa de aprendizaje\nlr_schedule = ExponentialDecay(\n    initial_learning_rate = INIT_LR,  # Tasa de aprendizaje inicial\n    decay_steps = 100,                # Número de pasos para aplicar el decaimiento\n    decay_rate = INIT_LR / 100,       # Factor de decaimiento (0.96 es un ejemplo)\n    staircase = False                 # `False` para un decaimiento continuo\n)\n\n\n# Compilamos el modelo\nsport_model.compile(loss = \"categorical_crossentropy\",\n                    optimizer = Adam(learning_rate = lr_schedule),\n                    metrics = ['accuracy'])"
  },
  {
    "objectID": "docs/material/ANN/Ejercicio_CNN_Deportes.html#tensorflow",
    "href": "docs/material/ANN/Ejercicio_CNN_Deportes.html#tensorflow",
    "title": "Convolutional Neural Networks",
    "section": "TENSORFLOW",
    "text": "TENSORFLOW\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import TensorBoard\n\n# Definir el callback de TensorBoard\ntensorboard_callback = TensorBoard(log_dir=\"./logs\", histogram_freq=1)\n\n\n# Compilar el modelo\nsport_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Entrenar el modelo con el callback\nsport_train = sport_model.fit(train_X, train_label, epochs = 10,\n                              callbacks = [tensorboard_callback],\n                              validation_data = (valid_X, valid_label))\n\nEpoch 1/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 24ms/step - accuracy: 0.9707 - loss: 0.0519 - val_accuracy: 0.9900 - val_loss: 0.0153\nEpoch 2/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 35ms/step - accuracy: 0.9760 - loss: 0.0437 - val_accuracy: 0.9875 - val_loss: 0.0167\nEpoch 3/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 3s 31ms/step - accuracy: 0.9758 - loss: 0.0464 - val_accuracy: 0.9912 - val_loss: 0.0142\nEpoch 4/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9744 - loss: 0.0399 - val_accuracy: 0.9900 - val_loss: 0.0144\nEpoch 5/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 22ms/step - accuracy: 0.9780 - loss: 0.0379 - val_accuracy: 0.9912 - val_loss: 0.0127\nEpoch 6/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9818 - loss: 0.0367 - val_accuracy: 0.9937 - val_loss: 0.0125\nEpoch 7/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 20ms/step - accuracy: 0.9846 - loss: 0.0299 - val_accuracy: 0.9950 - val_loss: 0.0110\nEpoch 8/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 31ms/step - accuracy: 0.9848 - loss: 0.0332 - val_accuracy: 0.9912 - val_loss: 0.0138\nEpoch 9/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 4s 20ms/step - accuracy: 0.9890 - loss: 0.0269 - val_accuracy: 0.9925 - val_loss: 0.0112\nEpoch 10/10\n100/100 ━━━━━━━━━━━━━━━━━━━━ 2s 21ms/step - accuracy: 0.9879 - loss: 0.0291 - val_accuracy: 0.9937 - val_loss: 0.0117\n\n\n\n# Crear un callback de TensorBoard\nimport datetime\nlog_dir = \"/content/logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\ntensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n\n# Iniciar TensorBoard en Colab\n%load_ext tensorboard\n%tensorboard --logdir /content/logs/fit\n\nThe tensorboard extension is already loaded. To reload it, use:\n  %reload_ext tensorboard\n\n\nReusing TensorBoard on port 6006 (pid 19935), started 0:01:09 ago. (Use '!kill 19935' to kill it.)"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html",
    "title": "DREAMBOOTH 🤖",
    "section": "",
    "text": "%load_ext autoreload\n%autoreload 2\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\nDreambooth es un modelo de generación de aprendizaje profundo, y que fue desarrollado en 2022 por un grupo de investigadores de Google Research y la Universidad de Boston. La misión de esta tecnología es la de poder entrenar a modelos de inteligencia artificial para personalizarlo según tus necesidades.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#como-funciona",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#como-funciona",
    "title": "DREAMBOOTH 🤖",
    "section": "¿Como funciona? 🔩",
    "text": "¿Como funciona? 🔩\nEl funcionamiento de esta técnica funciona en tres pasos.\n\nEn primer lugar, necesitas un modelo de difusión preentrenado, que es uno de esos sistemas de inteligencia artificial que pueden crear imágenes a partir de texto. Por ejemplo, se puede usar:\n\n\nStable Diffusion\nDALL-E\nMidjourney\n\nsiempre y cuando funcionen con el proceso de ruido y denoising.\nLo que hace esta técnica es crear una imagen completamente ruidosa, y luego ir quitando ese ruido reconstruyendo en el proceso una imagen totalmente original que se parezca a lo que le has pedido por texto. Pues es en este punto en el que Dreambooth ayudará con un modelo entrenado para que puedas obtener imágenes de sujetos concretos.\n\nel segundo paso, en el que necesitas un conjunto de imágenes del sujeto con el que quieres personalizar la IA. Puede ser un estilo, una cara, o lo que sea. Se recomienda tener un set de unas 8 o 10 imágenes como mínimo para poder entrenar el modelo.\n\nEntonces, lo que hace Dreambooth es utilizar este set de imágenes para entrenar al modelo de difusión, entrenar a la IA para que sepa reconocer lo que hay en ellas. Puede reconocer tu cara para luego poder dibujarla desde cero, así como un estilo o una posición.\n\nUna vez has usado Dreambooth para entrenar a la IA, este sistema usará las imágenes del sujeto como punto de partida para el proceso de crear la imagen aleatoria, permitiendo que la IA tenga más información sobre cómo es el sujeto que quieres dibujar, y que así pueda hacer imágenes que se parezcan a él.\n\n\n\n\nImagen"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#instalació-de-paquets",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#instalació-de-paquets",
    "title": "DREAMBOOTH 🤖",
    "section": "Instalació de paquets",
    "text": "Instalació de paquets\n\nInstal·leu el paquet de Python Py-Dreambooth tal com es mostra a continuació.\n\n\n!pip install -q py_dreambooth"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#importa-mòduls",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#importa-mòduls",
    "title": "DREAMBOOTH 🤖",
    "section": "Importa mòduls",
    "text": "Importa mòduls\n\nHi ha diversos tipus de classes de model, però estaràs utilitzant el model més bàsic, el model Stable Diffusion Dreambooth SDDreamboothModel, però no t’has de preocupar per això ara mateix. 🤷‍♂️\n\n\nfrom py_dreambooth.dataset import LocalDataset\nfrom py_dreambooth.model import SdDreamboothModel\nfrom py_dreambooth.predictor import LocalPredictor\nfrom py_dreambooth.trainer import LocalTrainer\nfrom py_dreambooth.utils.image_helpers import display_images\nfrom py_dreambooth.utils.prompt_helpers import make_prompt\n\nMontem la relació entre el google drive i el quadern de jupyter\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True)."
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#preparem-les-dades",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#preparem-les-dades",
    "title": "DREAMBOOTH 🤖",
    "section": "Preparem les dades 📸",
    "text": "Preparem les dades 📸\n\nDATA_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/data\"  # el directori amb fotos per a que el model s'entreni\nOUTPUT_DIR = \"/content/drive/MyDrive/ANN/DREAMBOOTH/models\"  # El directori on s'ubicaran els fitxers de model entrenats\n\ndataset = LocalDataset(DATA_DIR)\n\n\nMolt important! En el DATA_DIR definit anteriorment, posar les imatges (jpg o png) del subjecte que es vol entrenar.\nPer a aquesta tasca, necessitareu entre 10 i 20 solos, selfies d’alta qualitat preses amb diferents fons, il·luminació i expressions facials. Crec que es pot trobar un gran exemple al repositori de GitHub de Joe Penna.\n\n\n\n\nSamples\n\n\n\nUtilitzeu el mètode de processament d’imatges següent per retallar les imatges en un quadrat centrat a la cara. Si el subjecte que el model està tractant d’aprendre no és una persona (per exemple, un gos), estableix l’argument detect_face argumentant com a False.\n\n\ndataset = dataset.preprocess_images(detect_face=True)\n\nA total of 8 images were found.\n\n\n 38%|███▊      | 3/8 [00:00&lt;00:00,  6.17it/s]\n\n\nNo faces detected in the image '443008034_395930086752782_7217331932050061307_n.jpg'.\nNo faces detected in the image '440173417_1436258973657135_9081022692963550822_n.jpg'.\n\n\n 75%|███████▌  | 6/8 [00:00&lt;00:00,  6.41it/s]\n\n\nNo faces detected in the image '429164819_452647503759342_2302826312178258320_n.jpg'.\n\n\n100%|██████████| 8/8 [00:01&lt;00:00,  5.50it/s]\n\n\nA total of 5 images were preprocessed and stored in the path '/content/drive/MyDrive/ANN/DREAMBOOTH/data_preproc'."
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#carregar-el-model",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#carregar-el-model",
    "title": "DREAMBOOTH 🤖",
    "section": "Carregar el model 🤖",
    "text": "Carregar el model 🤖\n\nSi reinicieu el nucli del bloc de notes i voleu tornar a carregar els models que ja heu entrenat, podeu fer-ho de la següent manera.\n\n\npredictor = LocalPredictor(model, OUTPUT_DIR)"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#crea-imatges-com-vulgueu",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#crea-imatges-com-vulgueu",
    "title": "DREAMBOOTH 🤖",
    "section": "Crea imatges com vulgueu! 💃",
    "text": "Crea imatges com vulgueu! 💃\n\nUtilitzeu les indicacions per crear qualsevol imatge que vulgueu. El text de l’indicatiu ha de contenir el nom de l’assumpte i el nom de la classe definits anteriorment.\nTens problemes per arribar amb un bon prompte? No et preocupis. Podeu utilitzar la funció make_prompt per a generar una sol·licitud comissariada a l’atzar. Mira això. 🙆‍♀️\nLa creació de grans imatges pren paciència. Juga amb les indicacions, però si la qualitat de la pròpia generació és problemàtica, és possible que hagis de tornar a entrenar amb millors dades i paràmetres d’entrenament més adequats.\n\n\n%%time\nprompt = f\"A photo of {SUBJECT_NAME} {CLASS_NAME} with Simpsons\"\n# prompt = next(make_prompt(SUBJECT_NAME, CLASS_NAME))\n\nprint(f\"The prompt is as follows:\\n{prompt}\")\n\nimages = predictor.predict(\n    prompt,\n    height = 768,\n    width = 512,\n    num_images_per_prompt = 5,\n)\n\ndisplay_images(images, fig_size = 10)\n\nThe prompt is as follows:\nA photo of mire person with Simpsons\n\n\n\n\n\n\n\n\n\n\n\n\nCPU times: user 45.9 s, sys: 3.72 s, total: 49.6 s\nWall time: 50.3 s"
  },
  {
    "objectID": "docs/material/ANN/02_DreamBooth_parte2.html#bibliografia",
    "href": "docs/material/ANN/02_DreamBooth_parte2.html#bibliografia",
    "title": "DREAMBOOTH 🤖",
    "section": "Bibliografia 💃",
    "text": "Bibliografia 💃\n\nStable Diffusion\nDreamBooth\nPy-Dreambooth"
  },
  {
    "objectID": "material/SoftwareCarpentry/SoftwareCarpentry.html",
    "href": "material/SoftwareCarpentry/SoftwareCarpentry.html",
    "title": "Software Carpentry",
    "section": "",
    "text": "1 Objetivo\nEste notebook muestra cómo organizar un proyecto de R y controlar operaciones de sistema:\n\nEstructura recomendada de carpetas: syntax/, input/, output/, data/, temp/, logs/.\nManejo de rutas relativas con {here}.\nMensajes y nombres de archivo dinámicos con {glue}.\nCrear y buscar ficheros (dir.create(), file.path(), list.files(), fs::dir_create()…).\nRedirigir salida con sink().\nGuardar gráficos con pdf() y png().\nMini pipeline de ejemplo (leer → procesar → guardar).\n\n\nConsejo: evita setwd() y usa rutas relativas con {here} para que tu proyecto sea 100% reproducible.\n\n\n\n2 Paquetes y opciones\n\n\nCode\n# Paquetes base y útiles:\npacks &lt;- c(\"here\", \"glue\", \"fs\", \"readr\", \"dplyr\", \"ggplot2\")\nto_install &lt;- setdiff(packs, rownames(installed.packages()))\nif (length(to_install)) install.packages(to_install, quiet = TRUE)\n\nlibrary(here)    # Rutas relativas desde la raíz del proyecto\nlibrary(glue)    # Strings con llaves {var}\nlibrary(fs)      # Operaciones de sistema \"friendly\"\nlibrary(readr)   # Lectura/escritura rápida\nlibrary(dplyr)   # Manipulación de datos\nlibrary(ggplot2) # Gráficos\n\n# Opciones útiles\noptions(\n  scipen = 999,   # menos notación científica\n  digits = 4\n)\n\n# Mostrar dónde cree {here} que está la raíz del proyecto\nhere()\n\n\n¿Cómo define {here} la raíz?\n\nBuscar archivo(s) “ancla” (.Rproj, .here, DESCRIPTION, git/, etc).\nSi no encuentra, puede crear un archivo vacío llamado .here en la carpeta raíz del proyecto.\n\n\n\nCode\n# Crea un archivo marcador para que {here} sepa que esta carpeta es la raíz:\nfile_create(\".here\")\n\n\n\n\n3 Estructura del proyecto\nLa estructura propuesta es la siguiente:\n\nproject/\n├─ syntax/        # scripts R (funciones, notebooks, etc.)\n├─ input/         # insumos externos (CSV, XLSX, etc.) SOLO LECTURA\n├─ data/          # datos intermedios limpios/parquet/rds\n├─ output/        # resultados finales (tablas/figuras/listados)\n├─ temp/          # temporales desechables\n├─ logs/          # logs de ejecución\n├─ README.md\n└─ .here          # marca la raíz del proyecto p/ {here}\nPara crearlo, podemos hacerlo de la siguiente forma:\n\n\nCode\n# Crear la estructura de carpetas si no existe:\ndirs &lt;- c(\"syntax\", \"input\", \"data\", \"output\", \"temp\", \"logs\")\ndir_create(path = here(dirs))\ndir_ls(here(), type = \"directory\")\n\n\n\n\n4 Estructura del proyecto\nUsa here(\"carpeta\", \"sub\", \"archivo.ext\") para rutas portables:\n\n\nCode\n# Construir rutas de forma segura:\nruta_input  &lt;- here(\"input\", \"ventas_2025.csv\")\nruta_data   &lt;- here(\"data\",  \"ventas_limpio.rds\")\nruta_salida &lt;- here(\"output\",\"resumen_ventas.csv\")\n\nruta_input\nruta_data\nruta_salida\n\n# Con base R: file.path() también es portable\nfile.path(\"input\", \"ventas_2025.csv\")\n\n\nCon {glue} puedes crear nombres dinámicos:\n\n\nCode\nanio &lt;- 2025; mes &lt;- 9\nnombre_csv &lt;- glue(\"ventas_{anio}-{sprintf('%02d', mes)}.csv\")\nhere(\"input\", nombre_csv)\n\n\n\n\n5 Crear y escribir archivos\n\n\nCode\n# Datos de ejemplo:\ndf &lt;- tibble::tibble(\n  id = 1:5,\n  fecha = as.Date(\"2025-09-01\") + 0:4,\n  ventas = c(100, 80, 95, 120, 110)\n)\n\n# Guardar como CSV en output/\nwrite_csv(df, here(\"output\", \"tabla_ejemplo.csv\"))\n\n# Guardar como RDS en data/\nsaveRDS(df, here(\"data\", \"tabla_ejemplo.rds\"))\n\n\n\n\n6 Búsqueda de ficheros\nlist.files() (base) y fs::dir_ls() (recursivo, con globbing):\n\n\nCode\n# Listado simple\nlist.files(here(\"output\"))\n\n# Listado recursivo con patrón:\ndir_ls(here(), recurse = TRUE, glob = \"output/*.csv\")\n\n# Buscar por ext. en múltiples carpetas:\ndir_ls(here(c(\"input\",\"data\",\"output\")), recurse = TRUE, \n       regexp = \"\\\\.(csv|rds)$\")\n\n\n\n\n7 Redirección de salida con sink()\n\n\nCode\nlog_path &lt;- here(\"logs\", glue(\"log_{format(Sys.time(), '%Y%m%d_%H%M%S')}.txt\"))\n\nsink(log_path, split = TRUE)      # split=TRUE =&gt; también muestra en consola\ncat(\"=== INICIO ===\\n\")\nprint(sessionInfo())\ncat(\"Una línea cualquiera\\n\")\nsink()  # IMPORTANTÍSIMO: cerrar el sink\n\n# Revisa el contenido del log:\nreadLines(log_path, n = 8)\n\n\n⚠️ Cierra siempre el sink() con sink() (sin argumentos) o usa on.exit(sink()) dentro de una función para no “bloquear” la consola.\n\n\n8 Dispositivos gráficos: pdf() y png()\nPuedes abrir un dispositivo gráfico, dibujar y cerrado con dev.off().\n\n\nCode\npdf(here(\"output\", \"grafico_demo.pdf\"), width = 7, height = 5)\nplot(cars, main = \"Gráfico base R - cars\")\ndev.off()\n\n# PNG con resolución\npng(here(\"output\", \"grafico_demo.png\"), width = 1200, height = 900, res = 150)\nplot(pressure, main = \"Gráfico base R - pressure\")\ndev.off()\n\n\nCon ggplot2:\n\n\nCode\np &lt;- ggplot(mtcars, aes(disp, mpg)) + geom_point() +\n  labs(title = \"Relación cilindrada vs. mpg\")\n\n# Guardar directamente\nggsave(filename = here(\"output\", \"mtcars_disp_mpg.png\"), plot = p,\n       width = 7, height = 5, dpi = 150)\n\n# También PDF\nggsave(filename = here(\"output\", \"mtcars_disp_mpg.pdf\"), plot = p,\n       width = 7, height = 5)\n\n\n\n\n9 Buenas prácticas con {here}\n\nColoca un archivo .here o un .Rproj en la raíz\nNunca uses setwd() dentro de scripts reutilizables.\nEscribe funciones que reciban rutas como argumento o que construyan rutas con here().\n\n\n\nCode\n# Función ejemplo usando here()\nlee_input &lt;- function(nombre) {\n  readr::read_csv(here(\"input\", nombre), show_col_types = FALSE)\n}\n\n# Uso:\n# df &lt;- lee_input(\"ventas_2025.csv\")\n\n\n\n\n10 Mensajes y nombres con {glue}\n\n\nCode\n# Glue para strings explicativos\narchivo &lt;- \"ventas_2025.csv\"\nmensaje &lt;- glue(\"Leyendo el archivo '{archivo}' desde {here('input')}\")\nmensaje\n\n\nglue() evalúa expresiones dentro de {}:\n\n\nCode\nclientes &lt;- 1250\nglue(\"Este mes se han registrado {clientes} clientes (Δ = {clientes - 1200}).\")\n\n\n\n\n11 Mini pipeline: leer → procesar → guardar\nEjemplo autocontenido que crea un CSV de entrada, lo procesa y guarda resultados.\n\n\nCode\n# 1) Crear un CSV de ejemplo en input/\ndir_create(here(\"input\"))\ntoy &lt;- tibble::tibble(\n  id = 1:10,\n  fecha = as.Date(\"2025-09-01\") + 0:9,\n  ventas = sample(80:150, 10, replace = TRUE)\n)\nwrite_csv(toy, here(\"input\", \"toy_ventas.csv\"))\n\n# 2) Leer, procesar y registrar\nlog_path &lt;- here(\"logs\", \"mini_pipeline.log\")\nsink(log_path, split = TRUE)\ncat(\"== MINI PIPELINE ==\\n\")\n\nraw &lt;- read_csv(here(\"input\", \"toy_ventas.csv\"), show_col_types = FALSE)\ncat(glue(\"Leídas {nrow(raw)} filas.\\n\"))\n\nproc &lt;- raw |&gt;\n  mutate(\n    semana = format(fecha, \"%Y-%W\"),\n    ventas_norm = scale(ventas)[,1]\n  ) |&gt;\n  group_by(semana) |&gt;\n  summarise(ventas_media = mean(ventas), .groups = \"drop\")\n\ncat(glue(\"Semanas agregadas: {nrow(proc)}\\n\"))\n\n# 3) Guardar resultados\nwrite_csv(proc, here(\"output\", \"resumen_semanal.csv\"))\nsaveRDS(proc, here(\"data\", \"resumen_semanal.rds\"))\ncat(\"Archivos guardados en output/ y data/\\n\")\nsink()\n\n# 4) Graficar y guardar\np &lt;- ggplot(raw, aes(fecha, ventas)) + geom_line() +\n  labs(title = \"Ventas diarias (toy)\", x = \"Fecha\", y = \"Ventas\")\nggsave(here(\"output\", \"ventas_toy.png\"), plot = p, width = 7, \n       height = 5, dpi = 150)\n\n\n\n\n12 Utilidades (helpers) para tus scripts de syntax/\n\n\nCode\n# Guardar en syntax/helpers.R y luego source(\"syntax/helpers.R\") si quieres\n\ninit_log &lt;- function(prefix = \"run\") {\n  dir_create(here(\"logs\"))\n  path &lt;- here(\"logs\", \n               glue(\"{prefix}_{format(Sys.time(), '%Y%m%d_%H%M%S')}.log\"))\n  sink(path, split = TRUE)\n  cat(glue(\"[{Sys.time()}] INICIO\\n\"))\n  return(path)\n}\n\nclose_log &lt;- function() {\n  cat(glue(\"[{Sys.time()}] FIN\\n\"))\n  sink()\n}\n\nsafe_dir &lt;- function(...) {\n  # Crea una ruta y la carpeta si no existe\n  path &lt;- here(...)\n  dir_create(dirname(path))\n  return(path)\n}\n\nsave_table &lt;- function(df, ..., name, ext = \"csv\") {\n  # Guarda tabla df en output/ con nombre dinámico\n  base &lt;- glue(\"{name}.{ext}\")\n  path &lt;- safe_dir(\"output\", base)\n  if (ext == \"csv\") readr::write_csv(df, path)\n  if (ext == \"rds\") saveRDS(df, sub(\"\\\\.csv$\", \".rds\", path))\n  invisible(path)\n}\n\n\n\n\n13 Pautas de versión y limpieza\n\nTodo lo que no sea fuente, mételo bajo control (ej: borrar /temp/ al finalizar).\nUsa git para versionar scripts y notebooks.\nSepara lectura (input/) de resultados (output/) y datos de trabajo (data/).\n\n\n\nCode\n# Limpieza de temporales\nif (dir_exists(here(\"temp\"))) {\n  file_delete(dir_ls(here(\"temp\"), recurse = TRUE, type = \"file\"))\n}\n\n\n\n\n14 Apéndice: alternativas útiles\n\nfs::file_copy(), fs::file_move(), fs::file_delete() para copiar/mover/borrar.\nSys.getenv(\"VAR\") para leer variables de entorno.\nwithr::with_dir() para ejecutar código en otra dir sin cambiar tu wd global.\n\n\n\nCode\n# Copiar un archivo de ejemplo\nfs::file_copy(here(\"output\", \"tabla_ejemplo.csv\"),\n              here(\"temp\", \"copia_tabla.csv\"),\n              overwrite = TRUE)\n\n# Variables de entorno\nSys.getenv(\"HOME\")\n\n\n\n\n15 Session info\n\n\nCode\nsessionInfo()\n\n\n\n\n\n\n\n\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html",
    "href": "material/Preprocessing/Preprocessing.html",
    "title": "Preparación de los datos para el modelado",
    "section": "",
    "text": "Este conjunto de datos contiene registros de transacciones de cafeterías, incluyendo detalles sobre ventas, tipo de pago, hora de compra y preferencias del cliente.\nCon atributos que abarcan la hora del día, los días de la semana, los meses, los tipos de café y los ingresos, este conjunto de datos proporciona una base sólida para analizar el comportamiento del cliente, los patrones de ventas y las tendencias de rendimiento empresarial.\nEstructura del conjunto de datos:\n\nhour_of_day: Hora de compra (0–23)\ncash_type: Forma de pago (efectivo/tarjeta)\nmoney: Importe de la transacción (en moneda local)\ncoffee_name: Tipo de café comprado (p. ej., Latte, Americano, Chocolate caliente)\nTime_of_Day: Hora de compra (mañana, tarde, noche)\nWeekday: Día de la semana (p. ej., lun., mar., etc.)\nMonth_name: Mes de compra (p. ej., ene., feb., mar.)\nWeekdaysort: Representación numérica para ordenar por día de la semana (1 = lun., 7 = dom.)\nMonthsort: Representación numérica para ordenar por mes (1 = ene., 12 = dic.)\nDate: Fecha de la transacción (AAAA-MM-DD)\nTime: Hora exacta de la transacción (HH:MM:SS)\n\n\n\n  hour_of_day cash_type money         coffee_name Time_of_Day Weekday\n1          10      card  38.7               Latte     Morning     Fri\n2          12      card  38.7       Hot Chocolate   Afternoon     Fri\n3          12      card  38.7       Hot Chocolate   Afternoon     Fri\n4          13      card  28.9           Americano   Afternoon     Fri\n5          13      card  38.7               Latte   Afternoon     Fri\n6          15      card  33.8 Americano with Milk   Afternoon     Fri\n  Month_name Weekdaysort Monthsort       Date            Time\n1        Mar           5         3 2024-03-01 10:15:50.520000\n2        Mar           5         3 2024-03-01 12:19:22.539000\n3        Mar           5         3 2024-03-01 12:20:18.089000\n4        Mar           5         3 2024-03-01 13:46:33.006000\n5        Mar           5         3 2024-03-01 13:48:14.626000\n6        Mar           5         3 2024-03-01 15:39:47.726000\n\n\nA continuación vamos a detectar de que clase es cada una de las variables\n\nclases &lt;- sapply(datos, class)\nvarNum &lt;- names(clases)[which(clases %in% c(\"numeric\", \"integer\"))]\nvarCat &lt;- names(clases)[which(clases %in% c(\"character\", \"factor\"))]\n\nPara poder realizar una descriptiva correcta, descartaremos las variables Time y Date.\nEsta web está creada por Dante Conti y Sergi Ramírez, (c) 2024"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#univariant-analysis",
    "href": "material/Preprocessing/Preprocessing.html#univariant-analysis",
    "title": "Preparación de los datos para el modelado",
    "section": "2.1 Univariant analysis",
    "text": "2.1 Univariant analysis\n\n2.1.1 Numerical\n\n2.1.1.1 Description\n\nlibrary(psych)\npsych::describe(datos[, varNum])\n\n            vars    n  mean   sd median trimmed  mad   min  max range  skew\nhour_of_day    1 3547 14.19 4.23  14.00   14.11 5.93  6.00 22.0 16.00  0.12\nmoney          2 3547 31.65 4.88  32.82   31.98 4.36 18.12 38.7 20.58 -0.54\nWeekdaysort    3 3547  3.85 1.97   4.00    3.81 2.97  1.00  7.0  6.00  0.08\nMonthsort      4 3547  6.45 3.50   7.00    6.42 4.45  1.00 12.0 11.00  0.00\n            kurtosis   se\nhour_of_day    -1.13 0.07\nmoney          -0.67 0.08\nWeekdaysort    -1.23 0.03\nMonthsort      -1.38 0.06\n\n\n\n\n2.1.1.2 Graphic\n\nbaseggplot2\n\n\n\nfor (var in varNum) {\n  hist(datos[, var], main = paste0(\"Histograma variable \", var))\n  boxplot(datos[, var], main = paste0(\"Boxplot variable \", var))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\n\n\nAdjuntando el paquete: 'ggplot2'\n\n\nThe following objects are masked from 'package:psych':\n\n    %+%, alpha\n\nfor (var in varNum) {\n  \n  # Histograma\n  grafico &lt;- ggplot(datos, aes(x = get(var))) + \n    geom_histogram(aes(y = ..density..), colour = \"black\", fill = \"white\")+\n    geom_density(alpha=.2, fill=\"#FF6666\")  + \n    geom_vline(aes(xintercept = mean(get(var))),\n            color=\"blue\", linetype = \"dashed\", linewidth = 1)\n  print(grafico)\n  \n  # Boxplot\n  \n  grafico2 &lt;- ggplot(datos, aes(x=get(var))) + \n    geom_boxplot(outlier.colour=\"red\", outlier.shape=8,\n                outlier.size=4)\n  print(grafico2)\n  \n}\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.1.2 Categorical\n\n2.1.2.1 Description\n\nfor (var in varCat) {\n  tablaAbs &lt;- data.frame(table(datos[, var]))\n  tablaFreq &lt;- data.frame(table(datos[, var])/sum(table(datos[, var])))\n  m &lt;- match(tablaAbs$Var1, tablaFreq$Var1)\n  tablaAbs[, \"FreqRel\"] &lt;- tablaFreq[m, \"Freq\"]\n  colnames(tablaAbs) &lt;- c(\"Categoria\", \"FreqAbs\", \"FreqRel\")\n  \n  cat(\"===============\", var, \"===================================\\n\")\n  print(tablaAbs)\n  cat(\"==================================================\\n\")\n}\n\n=============== cash_type ===================================\n  Categoria FreqAbs FreqRel\n1      card    3547       1\n==================================================\n=============== coffee_name ===================================\n            Categoria FreqAbs    FreqRel\n1           Americano     564 0.15900761\n2 Americano with Milk     809 0.22808007\n3          Cappuccino     486 0.13701720\n4               Cocoa     239 0.06738089\n5             Cortado     287 0.08091345\n6            Espresso     129 0.03636876\n7       Hot Chocolate     276 0.07781224\n8               Latte     757 0.21341979\n==================================================\n=============== Time_of_Day ===================================\n  Categoria FreqAbs   FreqRel\n1 Afternoon    1205 0.3397237\n2   Morning    1181 0.3329574\n3     Night    1161 0.3273189\n==================================================\n=============== Weekday ===================================\n  Categoria FreqAbs   FreqRel\n1       Fri     532 0.1499859\n2       Mon     544 0.1533690\n3       Sat     470 0.1325063\n4       Sun     419 0.1181280\n5       Thu     510 0.1437835\n6       Tue     572 0.1612630\n7       Wed     500 0.1409642\n==================================================\n=============== Month_name ===================================\n   Categoria FreqAbs    FreqRel\n1        Apr     168 0.04736397\n2        Aug     272 0.07668452\n3        Dec     259 0.07301945\n4        Feb     423 0.11925571\n5        Jan     201 0.05666761\n6        Jul     237 0.06681703\n7        Jun     223 0.06287003\n8        Mar     494 0.13927262\n9        May     241 0.06794474\n10       Nov     259 0.07301945\n11       Oct     426 0.12010149\n12       Sep     344 0.09698337\n==================================================\n\n\n\n\n2.1.2.2 Graphic\n\nbaseggplot2\n\n\n\nfor (var in varCat) {\n  barplot(table(datos[, var]))\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfor (var in varCat) {\n  \n  tabla &lt;- data.frame(table(datos[, var])/sum(table(datos[, var])))\n  p &lt;- ggplot(data = tabla, aes(x = Var1, y = Freq)) +\n        geom_bar(stat = \"identity\", fill = \"steelblue\")+\n        geom_text(aes(label=paste0(round(Freq, 2)*100, \"%\")), vjust=1.6, color=\"white\", size=3.5)+\n        theme_minimal()\n  \n  print(p)\n}"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#bivariant-analysis",
    "href": "material/Preprocessing/Preprocessing.html#bivariant-analysis",
    "title": "Preparación de los datos para el modelado",
    "section": "2.2 Bivariant analysis",
    "text": "2.2 Bivariant analysis\n\n2.2.1 Numerical vs. numerical\n\n2.2.1.1 Description\n\ncor(datos[, varNum])\n\n             hour_of_day       money  Weekdaysort    Monthsort\nhour_of_day  1.000000000  0.20274794 -0.002613959  0.008292999\nmoney        0.202747935  1.00000000 -0.017264091 -0.050043191\nWeekdaysort -0.002613959 -0.01726409  1.000000000  0.044140930\nMonthsort    0.008292999 -0.05004319  0.044140930  1.000000000\n\n\n\n\n2.2.1.2 Graphic\n\nbaseggplot2\n\n\n\nlibrary(PerformanceAnalytics)\n\nCargando paquete requerido: xts\n\n\nCargando paquete requerido: zoo\n\n\n\nAdjuntando el paquete: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n\n\nAdjuntando el paquete: 'PerformanceAnalytics'\n\n\nThe following object is masked from 'package:graphics':\n\n    legend\n\nchart.Correlation(as.matrix(datos[, varNum]),histogram = TRUE,pch=12)\n\n\n\n\n\n\n\n\n\n\n\nlibrary(ggcorrplot)\n\nWarning: package 'ggcorrplot' was built under R version 4.4.3\n\ncorr &lt;- round(cor(datos[, varNum]), 1)\nggcorrplot(corr, lab = T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.2 Numerical vs. categorical\n\n2.2.2.1 Description\n\nfor (varN in varNum) {\n  for (varC in varCat) {\n   print(psych::describeBy(datos[, varN], group = datos[, varC])) \n  }\n}\n\n\n Descriptive statistics by group \ngroup: card\n   vars    n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 3547 14.19 4.23     14   14.11 5.93   6  22    16 0.12    -1.13 0.07\n\n Descriptive statistics by group \ngroup: Americano\n   vars   n  mean  sd median trimmed  mad min max range skew kurtosis   se\nX1    1 564 13.19 3.7     13      13 4.45   6  22    16 0.42    -0.53 0.16\n------------------------------------------------------------ \ngroup: Americano with Milk\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 809 13.62 4.31     13   13.39 4.45   6  22    16 0.37    -1.09 0.15\n------------------------------------------------------------ \ngroup: Cappuccino\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 486 14.92 4.23     15   15.05 5.93   6  22    16 -0.22    -1.05 0.19\n------------------------------------------------------------ \ngroup: Cocoa\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 239 15.26 4.26     16    15.4 5.93   7  22    15 -0.28    -1.14 0.28\n------------------------------------------------------------ \ngroup: Cortado\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 287 12.65 3.99     12   12.26 4.45   7  22    15 0.69     -0.6 0.24\n------------------------------------------------------------ \ngroup: Espresso\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 129 13.6 3.57     14   13.49 4.45   7  22    15 0.24    -0.78 0.31\n------------------------------------------------------------ \ngroup: Hot Chocolate\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 276 16.32 3.89     17   16.51 4.45   8  22    14 -0.41    -0.89 0.23\n------------------------------------------------------------ \ngroup: Latte\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 757 14.63 4.31     15   14.67 5.93   7  22    15 -0.08    -1.11 0.16\n\n Descriptive statistics by group \ngroup: Afternoon\n   vars    n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 1205 14.07 1.45     14   14.09 1.48  12  16     4 -0.06    -1.36 0.04\n------------------------------------------------------------ \ngroup: Morning\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 1181  9.4 1.27     10    9.47 1.48   6  11     5 -0.34    -0.93 0.04\n------------------------------------------------------------ \ngroup: Night\n   vars    n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 1161 19.18 1.63     19    19.1 1.48  17  22     5  0.2    -1.17 0.05\n\n Descriptive statistics by group \ngroup: Fri\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 532 13.83 4.46     14   13.64 5.93   6  22    16 0.23    -1.09 0.19\n------------------------------------------------------------ \ngroup: Mon\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 544 14.01 4.29     14   13.94 5.93   6  22    16 0.06    -1.17 0.18\n------------------------------------------------------------ \ngroup: Sat\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 470 13.93 3.89   13.5   13.71 3.71   7  22    15  0.4    -0.79 0.18\n------------------------------------------------------------ \ngroup: Sun\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 419 14.33 3.96     14   14.21 4.45   7  22    15 0.23    -1.02 0.19\n------------------------------------------------------------ \ngroup: Thu\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 510 14.74 4.27     15   14.76 5.93   7  22    15 -0.05     -1.2 0.19\n------------------------------------------------------------ \ngroup: Tue\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 572 14.27 4.39     14   14.24 5.93   7  22    15 0.04    -1.31 0.18\n------------------------------------------------------------ \ngroup: Wed\n   vars   n  mean  sd median trimmed  mad min max range skew kurtosis   se\nX1    1 500 14.23 4.2     14    14.2 5.93   7  22    15 0.08    -1.16 0.19\n\n Descriptive statistics by group \ngroup: Apr\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 168 14.4 3.13     14   14.38 4.45  10  20    10  0.1    -1.37 0.24\n------------------------------------------------------------ \ngroup: Aug\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 272 13.51 4.51     12   13.26 4.45   7  22    15  0.4    -1.18 0.27\n------------------------------------------------------------ \ngroup: Dec\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 259 14.33 4.39     15   14.25 5.93   7  22    15  0.1    -1.23 0.27\n------------------------------------------------------------ \ngroup: Feb\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 423 14.06 3.66     15   14.17 4.45   6  21    15 -0.23    -0.93 0.18\n------------------------------------------------------------ \ngroup: Jan\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 201 14.34 4.36     14   14.25 5.93   7  22    15 0.09     -1.1 0.31\n------------------------------------------------------------ \ngroup: Jul\n   vars   n  mean  sd median trimmed  mad min max range skew kurtosis   se\nX1    1 237 14.18 4.8     13   14.02 5.93   7  22    15  0.3    -1.35 0.31\n------------------------------------------------------------ \ngroup: Jun\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 223 15.23 4.59     16   15.38 5.93   7  22    15 -0.15    -1.47 0.31\n------------------------------------------------------------ \ngroup: Mar\n   vars   n  mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 494 13.51 3.37     14   13.53 4.45   6  21    15 -0.03    -1.02 0.15\n------------------------------------------------------------ \ngroup: May\n   vars   n mean  sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 241 15.2 4.1     15    15.3 5.93   7  22    15 -0.17    -1.12 0.26\n------------------------------------------------------------ \ngroup: Nov\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 259 14.1 4.27     14   14.06 4.45   7  22    15 0.08    -1.03 0.27\n------------------------------------------------------------ \ngroup: Oct\n   vars   n  mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 426 14.04 4.59     14   13.91 5.93   7  22    15  0.2    -1.21 0.22\n------------------------------------------------------------ \ngroup: Sep\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 344 14.4 4.73   13.5   14.34 6.67   7  22    15 0.14    -1.43 0.26\n\n Descriptive statistics by group \ngroup: card\n   vars    n  mean   sd median trimmed  mad   min  max range  skew kurtosis\nX1    1 3547 31.65 4.88  32.82   31.98 4.36 18.12 38.7 20.58 -0.54    -0.67\n     se\nX1 0.08\n\n Descriptive statistics by group \ngroup: Americano\n   vars   n  mean   sd median trimmed mad   min  max range  skew kurtosis   se\nX1    1 564 25.98 1.68  25.96   25.99   0 23.02 28.9  5.88 -0.25    -0.22 0.07\n------------------------------------------------------------ \ngroup: Americano with Milk\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 809 30.59 1.88  30.86   30.57 2.91 27.92 33.8  5.88 -0.17       -1 0.07\n------------------------------------------------------------ \ngroup: Cappuccino\n   vars   n  mean   sd median trimmed  mad   min  max range skew kurtosis   se\nX1    1 486 35.88 1.82  35.76   35.94 2.91 32.82 38.7  5.88 -0.4     -0.7 0.08\n------------------------------------------------------------ \ngroup: Cocoa\n   vars   n  mean   sd median trimmed mad   min  max range  skew kurtosis   se\nX1    1 239 35.65 1.23  35.76    35.7   0 32.82 38.7  5.88 -0.53        2 0.08\n------------------------------------------------------------ \ngroup: Cortado\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 287 25.73 2.09  25.96   25.68 2.91 23.02 28.9  5.88 -0.03    -1.23 0.12\n------------------------------------------------------------ \ngroup: Espresso\n   vars   n  mean   sd median trimmed  mad   min max range  skew kurtosis   se\nX1    1 129 20.85 1.97  21.06   20.81 2.91 18.12  24  5.88 -0.12    -1.09 0.17\n------------------------------------------------------------ \ngroup: Hot Chocolate\n   vars   n  mean   sd median trimmed mad   min  max range  skew kurtosis   se\nX1    1 276 35.99 1.44  35.76   36.03   0 32.82 38.7  5.88 -0.13     0.77 0.09\n------------------------------------------------------------ \ngroup: Latte\n   vars   n mean   sd median trimmed mad   min  max range  skew kurtosis   se\nX1    1 757 35.5 1.82  35.76   35.48   0 32.82 38.7  5.88 -0.18    -0.82 0.07\n\n Descriptive statistics by group \ngroup: Afternoon\n   vars    n  mean   sd median trimmed  mad   min  max range  skew kurtosis\nX1    1 1205 31.64 4.92  32.82   31.95 4.36 18.12 38.7 20.58 -0.53    -0.75\n     se\nX1 0.14\n------------------------------------------------------------ \ngroup: Morning\n   vars    n  mean   sd median trimmed  mad   min  max range  skew kurtosis\nX1    1 1181 30.42 4.94  30.86    30.6 7.26 18.12 38.7 20.58 -0.25     -0.8\n     se\nX1 0.14\n------------------------------------------------------------ \ngroup: Night\n   vars    n  mean   sd median trimmed  mad   min  max range  skew kurtosis\nX1    1 1161 32.89 4.43   33.8   33.38 2.91 18.12 38.7 20.58 -0.91    -0.02\n     se\nX1 0.13\n\n Descriptive statistics by group \ngroup: Fri\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 532 31.58 4.91  32.82   31.87 4.36 18.12 38.7 20.58 -0.51    -0.77 0.21\n------------------------------------------------------------ \ngroup: Mon\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 544 31.92 4.51  32.82   32.17 4.36 18.12 38.7 20.58 -0.53    -0.72 0.19\n------------------------------------------------------------ \ngroup: Sat\n   vars   n  mean sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 470 31.35  5  32.82   31.66 4.36 18.12 38.7 20.58 -0.52    -0.58 0.23\n------------------------------------------------------------ \ngroup: Sun\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 419 31.83 4.88  32.82   32.22 4.36 18.12 38.7 20.58 -0.59    -0.64 0.24\n------------------------------------------------------------ \ngroup: Thu\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 510 31.55 5.19  32.82   31.95 4.36 18.12 38.7 20.58 -0.57    -0.76 0.23\n------------------------------------------------------------ \ngroup: Tue\n   vars   n  mean   sd median trimmed  mad   min  max range  skew kurtosis  se\nX1    1 572 31.76 4.74  32.82   32.06 4.36 18.12 38.7 20.58 -0.53    -0.62 0.2\n------------------------------------------------------------ \ngroup: Wed\n   vars   n mean   sd median trimmed  mad   min  max range  skew kurtosis   se\nX1    1 500 31.5 4.94  32.82   31.85 4.36 18.12 38.7 20.58 -0.51     -0.8 0.22\n\n Descriptive statistics by group \ngroup: Apr\n   vars   n  mean   sd median trimmed  mad min  max range  skew kurtosis   se\nX1    1 168 34.05 4.49   33.8   34.33 7.26  24 38.7  14.7 -0.38    -1.31 0.35\n------------------------------------------------------------ \ngroup: Aug\n   vars   n  mean   sd median trimmed  mad   min   max range skew kurtosis   se\nX1    1 272 27.99 4.63  27.92   28.32 7.26 18.12 32.82  14.7 -0.4    -1.09 0.28\n------------------------------------------------------------ \ngroup: Dec\n   vars   n  mean   sd median trimmed mad   min   max range  skew kurtosis   se\nX1    1 259 31.81 4.61  35.76   32.31   0 21.06 35.76  14.7 -0.72    -0.78 0.29\n------------------------------------------------------------ \ngroup: Feb\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 423 31.24 4.69  30.86   31.58 7.26 21.06 35.76  14.7 -0.43    -1.23\n     se\nX1 0.23\n------------------------------------------------------------ \ngroup: Jan\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 201 31.84 4.33  30.86   32.23 7.26 21.06 35.76  14.7 -0.61    -0.92\n     se\nX1 0.31\n------------------------------------------------------------ \ngroup: Jul\n   vars   n  mean   sd median trimmed  mad   min   max range skew kurtosis   se\nX1    1 237 29.18 4.77  27.92   29.46 7.26 18.12 37.72  19.6 -0.5    -0.58 0.31\n------------------------------------------------------------ \ngroup: Jun\n   vars   n  mean   sd median trimmed mad   min   max range  skew kurtosis   se\nX1    1 223 34.16 4.29  37.72   34.76   0 23.02 37.72  14.7 -0.96    -0.06 0.29\n------------------------------------------------------------ \ngroup: Mar\n   vars   n  mean   sd median trimmed  mad   min  max range skew kurtosis   se\nX1    1 494 32.17 4.91   33.8    32.3 7.26 21.06 38.7 17.64 -0.3    -1.19 0.22\n------------------------------------------------------------ \ngroup: May\n   vars   n  mean   sd median trimmed mad   min   max range  skew kurtosis   se\nX1    1 241 33.88 4.44  37.72   34.32   0 23.02 37.72  14.7 -0.67     -0.9 0.29\n------------------------------------------------------------ \ngroup: Nov\n   vars   n  mean   sd median trimmed mad   min   max range  skew kurtosis   se\nX1    1 259 33.17 3.84  35.76   33.79   0 21.06 35.76  14.7 -1.18     0.12 0.24\n------------------------------------------------------------ \ngroup: Oct\n   vars   n  mean   sd median trimmed mad   min   max range  skew kurtosis   se\nX1    1 426 32.61 4.29  35.76   33.21   0 21.06 35.76  14.7 -1.01    -0.29 0.21\n------------------------------------------------------------ \ngroup: Sep\n   vars   n  mean   sd median trimmed  mad   min   max range  skew kurtosis\nX1    1 344 29.04 4.46  27.92   29.33 7.26 18.12 35.76 17.64 -0.57    -0.62\n     se\nX1 0.24\n\n Descriptive statistics by group \ngroup: card\n   vars    n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 3547 3.85 1.97      4    3.81 2.97   1   7     6 0.08    -1.23 0.03\n\n Descriptive statistics by group \ngroup: Americano\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 564 3.74 1.89      4    3.69 2.97   1   7     6 0.06    -1.14 0.08\n------------------------------------------------------------ \ngroup: Americano with Milk\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 809 3.82 2.02      4    3.78 2.97   1   7     6 0.12     -1.3 0.07\n------------------------------------------------------------ \ngroup: Cappuccino\n   vars   n mean sd median trimmed  mad min max range skew kurtosis   se\nX1    1 486 3.99  2      4    3.99 2.97   1   7     6 0.01    -1.23 0.09\n------------------------------------------------------------ \ngroup: Cocoa\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 239  3.7 1.94      4    3.63 2.97   1   7     6 0.17    -1.26 0.13\n------------------------------------------------------------ \ngroup: Cortado\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 287 4.18 2.01      4    4.22 2.97   1   7     6 -0.14     -1.3 0.12\n------------------------------------------------------------ \ngroup: Espresso\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 129 4.08 1.77      4    4.08 1.48   1   7     6 0.07    -0.93 0.16\n------------------------------------------------------------ \ngroup: Hot Chocolate\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 276 3.91 1.95      4    3.89 2.97   1   7     6 0.11    -1.15 0.12\n------------------------------------------------------------ \ngroup: Latte\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 757 3.71 1.99      4    3.64 2.97   1   7     6 0.15    -1.23 0.07\n\n Descriptive statistics by group \ngroup: Afternoon\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 1205 4.04 2.01      4    4.05 2.97   1   7     6 -0.06    -1.27 0.06\n------------------------------------------------------------ \ngroup: Morning\n   vars    n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 1181 3.75 1.97      4    3.69 2.97   1   7     6 0.12    -1.25 0.06\n------------------------------------------------------------ \ngroup: Night\n   vars    n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 1161 3.74 1.92      4    3.67 2.97   1   7     6 0.19    -1.11 0.06\n\n Descriptive statistics by group \ngroup: Fri\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 532    5  0      5       5   0   5   5     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Mon\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 544    1  0      1       1   0   1   1     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Sat\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 470    6  0      6       6   0   6   6     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Sun\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 419    7  0      7       7   0   7   7     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Thu\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 510    4  0      4       4   0   4   4     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Tue\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 572    2  0      2       2   0   2   2     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Wed\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 500    3  0      3       3   0   3   3     0  NaN      NaN  0\n\n Descriptive statistics by group \ngroup: Apr\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 168 3.89 2.06      4    3.87 2.97   1   7     6 0.03    -1.33 0.16\n------------------------------------------------------------ \ngroup: Aug\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 272 4.04 2.01      4    4.06 2.97   1   7     6 -0.07    -1.27 0.12\n------------------------------------------------------------ \ngroup: Dec\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 259 3.97 2.12      4    3.96 2.97   1   7     6 0.05    -1.42 0.13\n------------------------------------------------------------ \ngroup: Feb\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 423 3.47 1.87      3    3.37 2.97   1   7     6 0.25       -1 0.09\n------------------------------------------------------------ \ngroup: Jan\n   vars   n mean  sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 201 3.83 1.8      4    3.85 1.48   1   7     6 -0.11    -1.13 0.13\n------------------------------------------------------------ \ngroup: Jul\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 237 3.78 1.85      3    3.73 1.48   1   7     6 0.23    -1.12 0.12\n------------------------------------------------------------ \ngroup: Jun\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 223 4.17 2.02      4    4.21 2.97   1   7     6 -0.06     -1.3 0.14\n------------------------------------------------------------ \ngroup: Mar\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 494 3.82 1.87      4     3.8 2.97   1   7     6 0.03    -1.17 0.08\n------------------------------------------------------------ \ngroup: May\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 241 3.84 1.97      4     3.8 2.97   1   7     6 0.15    -1.12 0.13\n------------------------------------------------------------ \ngroup: Nov\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 259 4.08 1.99      4    4.11 2.97   1   7     6 -0.16    -1.33 0.12\n------------------------------------------------------------ \ngroup: Oct\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 426  3.7 1.94      4    3.63 2.97   1   7     6 0.23    -1.11 0.09\n------------------------------------------------------------ \ngroup: Sep\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 344 3.91 2.15      4    3.88 2.97   1   7     6 0.07    -1.44 0.12\n\n Descriptive statistics by group \ngroup: card\n   vars    n mean  sd median trimmed  mad min max range skew kurtosis   se\nX1    1 3547 6.45 3.5      7    6.42 4.45   1  12    11    0    -1.38 0.06\n\n Descriptive statistics by group \ngroup: Americano\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 564 5.23 3.35      4    4.92 2.97   1  12    11 0.62    -1.03 0.14\n------------------------------------------------------------ \ngroup: Americano with Milk\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 809 6.59 3.39      7     6.6 4.45   1  12    11 -0.11    -1.24 0.12\n------------------------------------------------------------ \ngroup: Cappuccino\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 486 6.24 3.35      6    6.15 4.45   1  12    11 0.17    -1.19 0.15\n------------------------------------------------------------ \ngroup: Cocoa\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 239 6.29 4.02      6     6.2 5.93   1  12    11  0.1    -1.71 0.26\n------------------------------------------------------------ \ngroup: Cortado\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis  se\nX1    1 287  7.1 3.37      8    7.22 2.97   1  12    11 -0.32    -1.07 0.2\n------------------------------------------------------------ \ngroup: Espresso\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis  se\nX1    1 129 6.37 3.37      7    6.28 4.45   1  12    11 0.06    -1.24 0.3\n------------------------------------------------------------ \ngroup: Hot Chocolate\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 276 6.96 3.81    7.5    7.02 5.19   1  12    11 -0.17     -1.6 0.23\n------------------------------------------------------------ \ngroup: Latte\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 757    7 3.37      8    7.11 4.45   1  12    11 -0.29    -1.24 0.12\n\n Descriptive statistics by group \ngroup: Afternoon\n   vars    n mean   sd median trimmed  mad min max range skew kurtosis  se\nX1    1 1205 6.02 3.61      5     5.9 4.45   1  12    11 0.23    -1.45 0.1\n------------------------------------------------------------ \ngroup: Morning\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis  se\nX1    1 1181 6.74 3.44      7    6.77 4.45   1  12    11 -0.15    -1.32 0.1\n------------------------------------------------------------ \ngroup: Night\n   vars    n mean   sd median trimmed  mad min max range  skew kurtosis  se\nX1    1 1161 6.61 3.41      7    6.61 4.45   1  12    11 -0.06    -1.27 0.1\n\n Descriptive statistics by group \ngroup: Fri\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 532 6.08 3.57      6       6 4.45   1  12    11 0.14    -1.44 0.15\n------------------------------------------------------------ \ngroup: Mon\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 544  6.3 3.58      6    6.22 4.45   1  12    11 0.06    -1.46 0.15\n------------------------------------------------------------ \ngroup: Sat\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 470 6.75 3.53      7     6.8 4.45   1  12    11 -0.11    -1.35 0.16\n------------------------------------------------------------ \ngroup: Sun\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 419 7.18 3.25      8    7.25 4.45   1  12    11 -0.2    -1.17 0.16\n------------------------------------------------------------ \ngroup: Thu\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 510 6.21 3.47      6    6.15 4.45   1  12    11 0.07    -1.37 0.15\n------------------------------------------------------------ \ngroup: Tue\n   vars   n mean   sd median trimmed  mad min max range  skew kurtosis   se\nX1    1 572 6.79 3.47      7    6.82 4.45   1  12    11 -0.14    -1.36 0.15\n------------------------------------------------------------ \ngroup: Wed\n   vars   n mean   sd median trimmed  mad min max range skew kurtosis   se\nX1    1 500 6.01 3.44      6    5.86 4.45   1  12    11  0.2    -1.33 0.15\n\n Descriptive statistics by group \ngroup: Apr\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 168    4  0      4       4   0   4   4     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Aug\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 272    8  0      8       8   0   8   8     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Dec\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 259   12  0     12      12   0  12  12     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Feb\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 423    2  0      2       2   0   2   2     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Jan\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 201    1  0      1       1   0   1   1     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Jul\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 237    7  0      7       7   0   7   7     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Jun\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 223    6  0      6       6   0   6   6     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Mar\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 494    3  0      3       3   0   3   3     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: May\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 241    5  0      5       5   0   5   5     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Nov\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 259   11  0     11      11   0  11  11     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Oct\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 426   10  0     10      10   0  10  10     0  NaN      NaN  0\n------------------------------------------------------------ \ngroup: Sep\n   vars   n mean sd median trimmed mad min max range skew kurtosis se\nX1    1 344    9  0      9       9   0   9   9     0  NaN      NaN  0\n\n\n\n\n2.2.2.2 Graphic\n\nfor (varC in varCat) {\n  for (varN in varNum) {\n    # Histogram by group in ggplot2\n  grafico &lt;- ggplot(datos, aes(x = get(varN), fill = get(varC))) + \n    geom_histogram(colour = \"black\",\n                   lwd = 0.75,\n                   linetype = 1,\n                   position = \"identity\")\n  print(grafico)\n  }\n}\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\n\n\n\n2.2.3 Categorical vs. categorical\n\n2.2.3.1 Description\n\nfor (varc1 in varCat) {\n  for (varc2 in varCat) {\n    if (varc1 != varc2) {\n      prop_table &lt;- prop.table(table(datos[, varc1], datos[, varc2]))\n      cat(\"=============\", varc1, \" vs. \", varc2, \"=========================\\n\")\n      print(prop_table)\n    }\n  }\n}\n\n============= cash_type  vs.  coffee_name =========================\n      \n        Americano Americano with Milk Cappuccino      Cocoa    Cortado\n  card 0.15900761          0.22808007 0.13701720 0.06738089 0.08091345\n      \n         Espresso Hot Chocolate      Latte\n  card 0.03636876    0.07781224 0.21341979\n============= cash_type  vs.  Time_of_Day =========================\n      \n       Afternoon   Morning     Night\n  card 0.3397237 0.3329574 0.3273189\n============= cash_type  vs.  Weekday =========================\n      \n             Fri       Mon       Sat       Sun       Thu       Tue       Wed\n  card 0.1499859 0.1533690 0.1325063 0.1181280 0.1437835 0.1612630 0.1409642\n============= cash_type  vs.  Month_name =========================\n      \n              Apr        Aug        Dec        Feb        Jan        Jul\n  card 0.04736397 0.07668452 0.07301945 0.11925571 0.05666761 0.06681703\n      \n              Jun        Mar        May        Nov        Oct        Sep\n  card 0.06287003 0.13927262 0.06794474 0.07301945 0.12010149 0.09698337\n============= coffee_name  vs.  cash_type =========================\n                     \n                            card\n  Americano           0.15900761\n  Americano with Milk 0.22808007\n  Cappuccino          0.13701720\n  Cocoa               0.06738089\n  Cortado             0.08091345\n  Espresso            0.03636876\n  Hot Chocolate       0.07781224\n  Latte               0.21341979\n============= coffee_name  vs.  Time_of_Day =========================\n                     \n                        Afternoon     Morning       Night\n  Americano           0.065689315 0.061742317 0.031575980\n  Americano with Milk 0.067380885 0.093318297 0.067380885\n  Cappuccino          0.046236256 0.034395264 0.056385678\n  Cocoa               0.021144629 0.016351847 0.029884409\n  Cortado             0.024809698 0.040315760 0.015787990\n  Espresso            0.015787990 0.012404849 0.008175923\n  Hot Chocolate       0.022554271 0.013814491 0.041443473\n  Latte               0.076120665 0.060614604 0.076684522\n============= coffee_name  vs.  Weekday =========================\n                     \n                              Fri         Mon         Sat         Sun\n  Americano           0.029602481 0.026219340 0.019453059 0.012968706\n  Americano with Milk 0.029038624 0.036086834 0.033831407 0.027910911\n  Cappuccino          0.017479560 0.020016916 0.019453059 0.019734987\n  Cocoa               0.014660276 0.009585565 0.006484353 0.006766281\n  Cortado             0.010431350 0.009867494 0.015787990 0.011840992\n  Espresso            0.005920496 0.002819284 0.003946997 0.004510854\n  Hot Chocolate       0.012686778 0.009867494 0.006766281 0.011277136\n  Latte               0.030166338 0.038906118 0.026783197 0.023118128\n                     \n                              Thu         Tue         Wed\n  Americano           0.023118128 0.022836200 0.024809698\n  Americano with Milk 0.029038624 0.040315760 0.031857908\n  Cappuccino          0.021708486 0.017761489 0.020862701\n  Cocoa               0.006484353 0.016069918 0.007330138\n  Cortado             0.011840992 0.012404849 0.008739780\n  Espresso            0.007612067 0.004510854 0.007048210\n  Hot Chocolate       0.013532563 0.013814491 0.009867494\n  Latte               0.030448266 0.033549478 0.030448266\n============= coffee_name  vs.  Month_name =========================\n                     \n                               Apr          Aug          Dec          Feb\n  Americano           0.0093036369 0.0104313504 0.0076120665 0.0329856217\n  Americano with Milk 0.0107132788 0.0202988441 0.0160699182 0.0239639132\n  Cappuccino          0.0101494220 0.0095855653 0.0107132788 0.0146602763\n  Cocoa               0.0011277136 0.0031012123 0.0059204962 0.0157879899\n  Cortado             0.0045108542 0.0112771356 0.0087397801 0.0028192839\n  Espresso            0.0011277136 0.0039469975 0.0033831407 0.0047927826\n  Hot Chocolate       0.0028192839 0.0016915703 0.0073301381 0.0090217085\n  Latte               0.0076120665 0.0163518466 0.0132506343 0.0152241331\n                     \n                               Jan          Jul          Jun          Mar\n  Americano           0.0070482098 0.0101494220 0.0039469975 0.0377784043\n  Americano with Milk 0.0146602763 0.0183253454 0.0186072738 0.0231181280\n  Cappuccino          0.0076120665 0.0090217085 0.0129687059 0.0163518466\n  Cocoa               0.0039469975 0.0025373555 0.0011277136 0.0101494220\n  Cortado             0.0062024246 0.0039469975 0.0053566394 0.0084578517\n  Espresso            0.0014096420 0.0039469975 0.0028192839 0.0053566394\n  Hot Chocolate       0.0042289259 0.0031012123 0.0039469975 0.0121229208\n  Latte               0.0115590640 0.0157879899 0.0140964195 0.0259374119\n                     \n                               May          Nov          Oct          Sep\n  Americano           0.0112771356 0.0070482098 0.0124048492 0.0090217085\n  Americano with Milk 0.0152241331 0.0146602763 0.0231181280 0.0293205526\n  Cappuccino          0.0146602763 0.0073301381 0.0124048492 0.0115590640\n  Cocoa               0.0022554271 0.0098674937 0.0090217085 0.0025373555\n  Cortado             0.0047927826 0.0036650691 0.0095855653 0.0115590640\n  Espresso            0.0019734987 0.0008457852 0.0033831407 0.0033831407\n  Hot Chocolate       0.0036650691 0.0104313504 0.0163518466 0.0031012123\n  Latte               0.0140964195 0.0191711305 0.0338314068 0.0265012687\n============= Time_of_Day  vs.  cash_type =========================\n           \n                 card\n  Afternoon 0.3397237\n  Morning   0.3329574\n  Night     0.3273189\n============= Time_of_Day  vs.  coffee_name =========================\n           \n              Americano Americano with Milk  Cappuccino       Cocoa     Cortado\n  Afternoon 0.065689315         0.067380885 0.046236256 0.021144629 0.024809698\n  Morning   0.061742317         0.093318297 0.034395264 0.016351847 0.040315760\n  Night     0.031575980         0.067380885 0.056385678 0.029884409 0.015787990\n           \n               Espresso Hot Chocolate       Latte\n  Afternoon 0.015787990   0.022554271 0.076120665\n  Morning   0.012404849   0.013814491 0.060614604\n  Night     0.008175923   0.041443473 0.076684522\n============= Time_of_Day  vs.  Weekday =========================\n           \n                   Fri        Mon        Sat        Sun        Thu        Tue\n  Afternoon 0.04849168 0.04990133 0.05469411 0.04736397 0.04764590 0.04510854\n  Morning   0.05441218 0.05441218 0.04426276 0.03383141 0.04116154 0.05835918\n  Night     0.04708204 0.04905554 0.03354948 0.03693262 0.05497604 0.05779532\n           \n                   Wed\n  Afternoon 0.04651818\n  Morning   0.04651818\n  Night     0.04792783\n============= Time_of_Day  vs.  Month_name =========================\n           \n                   Apr        Aug        Dec        Feb        Jan        Jul\n  Afternoon 0.02058077 0.02001692 0.02199041 0.04961940 0.02114463 0.01606992\n  Morning   0.01127714 0.03411334 0.02537356 0.03326755 0.01719763 0.02762898\n  Night     0.01550606 0.02255427 0.02565548 0.03636876 0.01832535 0.02311813\n           \n                   Jun        Mar        May        Nov        Oct        Sep\n  Afternoon 0.01522413 0.06146039 0.02199041 0.02847477 0.03834226 0.02480970\n  Morning   0.01888920 0.04623626 0.01691570 0.02368198 0.04341697 0.03495912\n  Night     0.02875670 0.03157598 0.02903862 0.02086270 0.03834226 0.03721455\n============= Weekday  vs.  cash_type =========================\n     \n           card\n  Fri 0.1499859\n  Mon 0.1533690\n  Sat 0.1325063\n  Sun 0.1181280\n  Thu 0.1437835\n  Tue 0.1612630\n  Wed 0.1409642\n============= Weekday  vs.  coffee_name =========================\n     \n        Americano Americano with Milk  Cappuccino       Cocoa     Cortado\n  Fri 0.029602481         0.029038624 0.017479560 0.014660276 0.010431350\n  Mon 0.026219340         0.036086834 0.020016916 0.009585565 0.009867494\n  Sat 0.019453059         0.033831407 0.019453059 0.006484353 0.015787990\n  Sun 0.012968706         0.027910911 0.019734987 0.006766281 0.011840992\n  Thu 0.023118128         0.029038624 0.021708486 0.006484353 0.011840992\n  Tue 0.022836200         0.040315760 0.017761489 0.016069918 0.012404849\n  Wed 0.024809698         0.031857908 0.020862701 0.007330138 0.008739780\n     \n         Espresso Hot Chocolate       Latte\n  Fri 0.005920496   0.012686778 0.030166338\n  Mon 0.002819284   0.009867494 0.038906118\n  Sat 0.003946997   0.006766281 0.026783197\n  Sun 0.004510854   0.011277136 0.023118128\n  Thu 0.007612067   0.013532563 0.030448266\n  Tue 0.004510854   0.013814491 0.033549478\n  Wed 0.007048210   0.009867494 0.030448266\n============= Weekday  vs.  Time_of_Day =========================\n     \n       Afternoon    Morning      Night\n  Fri 0.04849168 0.05441218 0.04708204\n  Mon 0.04990133 0.05441218 0.04905554\n  Sat 0.05469411 0.04426276 0.03354948\n  Sun 0.04736397 0.03383141 0.03693262\n  Thu 0.04764590 0.04116154 0.05497604\n  Tue 0.04510854 0.05835918 0.05779532\n  Wed 0.04651818 0.04651818 0.04792783\n============= Weekday  vs.  Month_name =========================\n     \n              Apr         Aug         Dec         Feb         Jan         Jul\n  Fri 0.007048210 0.009585565 0.008175923 0.020016916 0.011277136 0.010995207\n  Mon 0.008175923 0.011559064 0.011559064 0.024809698 0.008175923 0.006766281\n  Sat 0.006484353 0.013250634 0.011277136 0.009303637 0.009021708 0.007612067\n  Sun 0.006484353 0.010431350 0.012122921 0.009021708 0.002819284 0.006766281\n  Thu 0.006484353 0.012404849 0.007893995 0.017761489 0.010431350 0.007612067\n  Tue 0.007330138 0.009867494 0.012686778 0.015787990 0.007893995 0.013814491\n  Wed 0.005356639 0.009585565 0.009303637 0.022554271 0.007048210 0.013250634\n     \n              Jun         Mar         May         Nov         Oct         Sep\n  Fri 0.007330138 0.025091627 0.009021708 0.012122921 0.018325345 0.010995207\n  Mon 0.007612067 0.019453059 0.010431350 0.009585565 0.018325345 0.016915703\n  Sat 0.009867494 0.020298844 0.005638568 0.014942205 0.010713279 0.014096420\n  Sun 0.010995207 0.011277136 0.009867494 0.008175923 0.014096420 0.016069918\n  Thu 0.009303637 0.018889202 0.013532563 0.009867494 0.018043417 0.011559064\n  Tue 0.008739780 0.021426558 0.010149422 0.013250634 0.021990414 0.018325345\n  Wed 0.009021708 0.022836200 0.009303637 0.005074711 0.018607274 0.009021708\n============= Month_name  vs.  cash_type =========================\n     \n            card\n  Apr 0.04736397\n  Aug 0.07668452\n  Dec 0.07301945\n  Feb 0.11925571\n  Jan 0.05666761\n  Jul 0.06681703\n  Jun 0.06287003\n  Mar 0.13927262\n  May 0.06794474\n  Nov 0.07301945\n  Oct 0.12010149\n  Sep 0.09698337\n============= Month_name  vs.  coffee_name =========================\n     \n         Americano Americano with Milk   Cappuccino        Cocoa      Cortado\n  Apr 0.0093036369        0.0107132788 0.0101494220 0.0011277136 0.0045108542\n  Aug 0.0104313504        0.0202988441 0.0095855653 0.0031012123 0.0112771356\n  Dec 0.0076120665        0.0160699182 0.0107132788 0.0059204962 0.0087397801\n  Feb 0.0329856217        0.0239639132 0.0146602763 0.0157879899 0.0028192839\n  Jan 0.0070482098        0.0146602763 0.0076120665 0.0039469975 0.0062024246\n  Jul 0.0101494220        0.0183253454 0.0090217085 0.0025373555 0.0039469975\n  Jun 0.0039469975        0.0186072738 0.0129687059 0.0011277136 0.0053566394\n  Mar 0.0377784043        0.0231181280 0.0163518466 0.0101494220 0.0084578517\n  May 0.0112771356        0.0152241331 0.0146602763 0.0022554271 0.0047927826\n  Nov 0.0070482098        0.0146602763 0.0073301381 0.0098674937 0.0036650691\n  Oct 0.0124048492        0.0231181280 0.0124048492 0.0090217085 0.0095855653\n  Sep 0.0090217085        0.0293205526 0.0115590640 0.0025373555 0.0115590640\n     \n          Espresso Hot Chocolate        Latte\n  Apr 0.0011277136  0.0028192839 0.0076120665\n  Aug 0.0039469975  0.0016915703 0.0163518466\n  Dec 0.0033831407  0.0073301381 0.0132506343\n  Feb 0.0047927826  0.0090217085 0.0152241331\n  Jan 0.0014096420  0.0042289259 0.0115590640\n  Jul 0.0039469975  0.0031012123 0.0157879899\n  Jun 0.0028192839  0.0039469975 0.0140964195\n  Mar 0.0053566394  0.0121229208 0.0259374119\n  May 0.0019734987  0.0036650691 0.0140964195\n  Nov 0.0008457852  0.0104313504 0.0191711305\n  Oct 0.0033831407  0.0163518466 0.0338314068\n  Sep 0.0033831407  0.0031012123 0.0265012687\n============= Month_name  vs.  Time_of_Day =========================\n     \n       Afternoon    Morning      Night\n  Apr 0.02058077 0.01127714 0.01550606\n  Aug 0.02001692 0.03411334 0.02255427\n  Dec 0.02199041 0.02537356 0.02565548\n  Feb 0.04961940 0.03326755 0.03636876\n  Jan 0.02114463 0.01719763 0.01832535\n  Jul 0.01606992 0.02762898 0.02311813\n  Jun 0.01522413 0.01888920 0.02875670\n  Mar 0.06146039 0.04623626 0.03157598\n  May 0.02199041 0.01691570 0.02903862\n  Nov 0.02847477 0.02368198 0.02086270\n  Oct 0.03834226 0.04341697 0.03834226\n  Sep 0.02480970 0.03495912 0.03721455\n============= Month_name  vs.  Weekday =========================\n     \n              Fri         Mon         Sat         Sun         Thu         Tue\n  Apr 0.007048210 0.008175923 0.006484353 0.006484353 0.006484353 0.007330138\n  Aug 0.009585565 0.011559064 0.013250634 0.010431350 0.012404849 0.009867494\n  Dec 0.008175923 0.011559064 0.011277136 0.012122921 0.007893995 0.012686778\n  Feb 0.020016916 0.024809698 0.009303637 0.009021708 0.017761489 0.015787990\n  Jan 0.011277136 0.008175923 0.009021708 0.002819284 0.010431350 0.007893995\n  Jul 0.010995207 0.006766281 0.007612067 0.006766281 0.007612067 0.013814491\n  Jun 0.007330138 0.007612067 0.009867494 0.010995207 0.009303637 0.008739780\n  Mar 0.025091627 0.019453059 0.020298844 0.011277136 0.018889202 0.021426558\n  May 0.009021708 0.010431350 0.005638568 0.009867494 0.013532563 0.010149422\n  Nov 0.012122921 0.009585565 0.014942205 0.008175923 0.009867494 0.013250634\n  Oct 0.018325345 0.018325345 0.010713279 0.014096420 0.018043417 0.021990414\n  Sep 0.010995207 0.016915703 0.014096420 0.016069918 0.011559064 0.018325345\n     \n              Wed\n  Apr 0.005356639\n  Aug 0.009585565\n  Dec 0.009303637\n  Feb 0.022554271\n  Jan 0.007048210\n  Jul 0.013250634\n  Jun 0.009021708\n  Mar 0.022836200\n  May 0.009303637\n  Nov 0.005074711\n  Oct 0.018607274\n  Sep 0.009021708\n\n\n\n\n2.2.3.2 Graphic\n\nfor (varc1 in varCat) {\n  for (varc2 in varCat) {\n    if (varc1 != varc2) {\n      prop_table &lt;- prop.table(table(datos[, varc1], datos[, varc2]))\n      barplot(prop_table, beside = TRUE)\n    }\n  }\n}"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#features-selection",
    "href": "material/Preprocessing/Preprocessing.html#features-selection",
    "title": "Preparación de los datos para el modelado",
    "section": "3.1 Features selection",
    "text": "3.1 Features selection"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#outiliers",
    "href": "material/Preprocessing/Preprocessing.html#outiliers",
    "title": "Preparación de los datos para el modelado",
    "section": "3.2 Outiliers",
    "text": "3.2 Outiliers"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#imputation",
    "href": "material/Preprocessing/Preprocessing.html#imputation",
    "title": "Preparación de los datos para el modelado",
    "section": "3.3 Imputation",
    "text": "3.3 Imputation"
  },
  {
    "objectID": "material/Preprocessing/Preprocessing.html#new-variables",
    "href": "material/Preprocessing/Preprocessing.html#new-variables",
    "title": "Preparación de los datos para el modelado",
    "section": "3.4 New Variables",
    "text": "3.4 New Variables"
  }
]