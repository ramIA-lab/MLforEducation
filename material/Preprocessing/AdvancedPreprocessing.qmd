---
title: "Advance Preprocessing"
author: Dante Conti, Sergi Ramirez, (c) IDEAI
date: "`r Sys.Date()`"
date-modified: "`r Sys.Date()`"
toc: true
# language: es
number-sections: true
format: 
  html: 
    theme: cerulean
editor: visual
#execute: 
#  freeze: auto
---


# Descripci√≥n del problema

Para hacer el apartado de preprocessing vamos a utilizar la base de datos [`valentine_dataset.csv`](https://www.kaggle.com/datasets/anyasorc/valentine-dataset).

```{r}
#| label: lectura-datos
#| echo: false
#| warning: false
#| message: false
#| error: false

library(Hmisc)

# Lectura de los datos
dades <- read.csv("E:/PROYECTOS/ramIA-lab_repositorio/MLforEducation/MLforEducation/material/Preprocessing/valentine_dataset.csv")

tipus <- sapply(dades, class)
varNum <- names(tipus)[which(tipus %in% c("integer", "numeric"))]
varNum <- varNum[which(!varNum %in% c("Valentine_Date"))]
varCat <- names(tipus)[which(tipus %in% c("factor", "character"))]
```

# Limpieza de los datos 

## Limpieza de los datos a nivel de variable

Los **errores estructurales** a nivel de variable se centran fundamentalmente en el tipo de dato de las variables. En primer lugar, se visualizan los datos con la funci√≥n `diagnose()` de `dlookr`.

```{r}
#| label: diagnostico-variables
#| echo: true
#| warning: false
#| message: false
#| error: false

library(dlookr)
dlookr::diagnose(dades)
```

## Eliminaci√≥n de observaciones duplicadas o irrelevantes

Las **observaciones duplicadas** aparecen frecuentemente durante la recogida de datos e integraci√≥n de las bases de datos, por lo que dichas duplicidades deben ser eliminadas en esta fase de limpieza.

A continuaci√≥n, se usa la funci√≥n `overview()` del paquete `dlookr`.

```{r}
#| label: obervaciones-duplicadas
#| echo: true
#| warning: false
#| message: false
#| error: false

head(overview(dades), n = 9)
```

# Outliers

Un outlier es un valor extremo que se aleja significativamente del resto de observaciones. Detectarlos es importante porque pueden distorsionar las estad√≠sticas, influir en los modelos y generar conclusiones err√≥neas.

Existen diferentes enfoques: desde an√°lisis univariantes (una variable a la vez) hasta multivariantes (considerando la relaci√≥n entre varias variables).

Para detectar los valores at√≠picos podemos hacer uso de la funci√≥n `diagnose_numeric` y `diagnose_category`.

```{r}
diagnose_numeric(dades)
diagnose_category(dades)
```

## Univariate

En este caso analizamos variable por variable.

### Max and Min

La primera estrategia consiste en observar los valores m√≠nimos y m√°ximos de cada variable num√©rica. Esto nos da una primera idea de los rangos de los datos y de si existen valores extra√±os.

```{r}
#| label: min_max
#| echo: true
#| warning: false
#| message: false
#| error: false

mapply(function(x, name) {
  cat("var. ", name, ": \n\t min: ", min(x), "\n\t max: ", max(x), "\n")
  invisible(NULL)  # Evita la salida de valores NULL
}, dades[, varNum], colnames(dades[, varNum]))
```

### IQR

Otra manera de detectar outliers es usando el **rango intercuart√≠lico (IQR)**. Se definen como outliers los puntos que quedan fuera del intervalo:

$$
[Q1 - 1.5xIQR, Q3 + 1.5xIQR]
$$

donde $Q1$ es el primer cuartil, $Q3$ el tercer cuartil e $IQR = Q3 - Q1$.

```{r}
#| label: iqr
#| echo: true
#| warning: false
#| message: false
#| error: false

library(EnvStats)

IQROutlier <- function(variable, rmnas = TRUE) {
  IQ <- iqr(variable, na.rm = rmnas)
  intInf <- quantile(variable, probs = c(0.25, 0.75))[[1]] - 1.5*IQ
  intSup <- quantile(variable, probs = c(0.25, 0.75))[[2]] + 1.5*IQ
  posicions <- which(variable >= intSup | variable <= intInf)
  if (length(posicions) > 0) {
    cat("Existeixen outliers en les posicions:", paste0(posicions, collapse = ", "))
  } else {
    cat("No existeixen outliers")
  }
  return(posicions)
}
```

```{r}
#| label: iqr_valor
#| echo: false
#| warning: false
#| message: false
#| error: false

IQROutlier(dades[, "Confidence_Score"])
```

> üëâ Aqu√≠ veremos cu√°ntos valores son considerados extremos seg√∫n este criterio en cada variable num√©rica.

### Boxplot

Visualitzaci√≥ basada en IQR per detectar outliers.

```{r}
#| label: boxplot
#| echo: true
#| warning: false
#| message: false
#| error: false

library(ggplot2)

variable <- "Age"

boxplot(dades[, variable])
boxplot.stats(dades[, variable])$out

# Crear un boxplot
ggplot(dades, aes(y = get(variable))) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = paste0("Boxplot de ", variable)) +
  theme_minimal()
```

### Z-Score

Un outlier es un valor amb \|z\| \> 3 deviaci√≥ est√°ndar

```{r}
#| label: z_score
#| echo: true
#| warning: false
#| message: false
#| error: false

variable <- "Age"
valorEscalado <- scale(dades[, variable])
hist(valorEscalado)

ggplot(data.frame(valor = valorEscalado), aes(x = valor)) +
  geom_histogram(binwidth = 0.5, fill = "skyblue", color = "black") +  # Histograma
  geom_vline(xintercept = c(3, -3), linetype = "dashed", color = "red", size = 1) + # L√≠neas horizontales
  theme_minimal()
```

### Hampel Identifier

Utilitza la mediana i la desviaci√≥ absoluta mediana (MAD) en lloc de la mitjana

```{r}
#| label: hampel
#| echo: true
#| warning: false
#| message: false
#| error: false

variable <- "Age"

lower_bound <- median(dades[, variable]) - 3 * mad(dades[, variable], constant = 1)
upper_bound <- median(dades[, variable]) + 3 * mad(dades[, variable], constant = 1)
outlier_ind <- which((dades[, variable] < lower_bound) | (dades[, variable] > upper_bound))
outlier_ind
```

### Tests Estad√≠stics

#### Grubbs' Test

Detecta valors extrems en una distribuci√≥ normal

```{r}
#| label: grubbs_test
#| echo: true
#| warning: false
#| message: false
#| error: false

library(outliers)

variable <- "Age"
test <- outliers::grubbs.test(dades[, variable], opposite = TRUE)
# amb el par√†metre opposite controles quina de les dues cues est√°n buscant
test

```

#### Dixon's Test

Nom√©s utilitzar per a bbdd petites (entre 3 - 30) observacions

```{r}
#| label: dixon-test
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

variable <- "Age"
test <- outliers::dixon.test(dades[, variable], opposite = FALSE)
test
```

#### Rosner's Test

La prueba de Rosner para valores at√≠picos tiene las ventajas de que: 1. se utiliza para detectar varios valores at√≠picos a la vez (a diferencia de la prueba de Grubbs y Dixon, que debe realizarse de forma iterativa para detectar m√∫ltiples valores at√≠picos), 2. Est√° dise√±ado para evitar el problema del enmascaramiento, donde un valor at√≠pico cercano en valor a otro valor at√≠pico puede pasar desapercibido.

A diferencia de la prueba de Dixon, tenga en cuenta que la prueba de Rosner es m√°s apropiada cuando el tama√±o de la muestra es grande (n ‚â• 20).

Esta funci√≥n requiere al menos dos argumentos: - los datos - la cantidad de valores at√≠picos sospechosos k (k = 3 como cantidad predeterminada)

Asumeix normalitat de les dades

```{r}
#| label: rosner
#| echo: true
#| warning: false
#| message: false
#| error: false

library(EnvStats)

variable <- "Age"
test <- EnvStats::rosnerTest(dades[, variable], k = 1)
test
test$all.stats
```

## Multivariate

Hasta ahora hemos visto cada variable por separado. Sin embargo, a veces los outliers aparecen **en combinaci√≥n** de variables.

Para detectarlos se pueden usar m√©todos como la distancia de Mahalanobis o algoritmos m√°s avanzados de detecci√≥n de anomal√≠as.

```{r}
#| label: plot_multivariate
#| echo: true
#| warning: false
#| message: false
#| error: false

library(scatterplot3d)
library(readr)
dades <- readr::read_csv("https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv")
dades <- data.frame(dades[, c("DC", "temp", "RH")])
scatterplot3d(dades[,"DC"], dades[, "temp"],dades[, "RH"])
```

```{r}
#| label: 3d_scatterplot
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

library(rgl)

# Plot
rgl::plot3d(x = dades[, "DC"], y = dades[, "temp"], z = dades[, "RH"], 
col = "black", type = 'p', radius = .1)
```

```{r}
#| label: scatterplot_plotly
#| echo: true
#| warning: false
#| message: false
#| error: false

library(plotly)

(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, size = 1) %>% 
       add_markers())
```

### Cas general

```{r}
#| label: deteccio_outliers
#| echo: true
#| warning: false
#| message: false
#| error: false

library(mvoutlier)
dades2 <- dades; Y <- as.matrix(dades2)
distances <- dd.plot(Y,quan=1/2, alpha=0.025)
head(distances$md.cla)
head(distances$md.rob)
res <- aq.plot(Y,delta=qchisq(0.975,df=ncol(Y)),quan=1/2,alpha=0.05)
str(res)
head(res$outliers)
table(res$outliers)
#windows()
par(mfrow=c(1, 1))
library(MVN)
# mvnoutliers <- mvn(dades, multivariateOutlierMethod = "adj", showOutliers = TRUE, 
#                   showNewData = TRUE)
mvnoutliers <- mvn(data = dades, mvn_test = "royston", 
                   univariate_test = "AD", 
              multivariate_outlier_method = "adj",
              show_new_data = TRUE)
```

Visualitzem tots els outliers detectats com a true

```{r}
#| label: visualizacion_outliers
#| echo: true
#| warning: false
#| message: false
#| error: false

head(summary(mvnoutliers, select = "outliers"))
```

Visualitzem les variables originals quines han donat els que no son outliers

```{r}
#| label: datos_sin_outliers
#| echo: true
#| warning: false
#| message: false
#| error: false

head(summary(mvnoutliers, select = "new_data"))
```

Visualitzem els resultats del test de normalitat univariant

```{r}
#| label: test_normalidad_lof
#| echo: true
#| warning: false
#| message: false
#| error: false

head(summary(mvnoutliers, select = "mvn"))
```

i multivariant

```{r}
#| label: test_normalidad_multi_lof
#| echo: true
#| warning: false
#| message: false
#| error: false
#| 
head(summary(mvnoutliers, select = "univariate"))
```

### PCA

M√©todes basats en correlacions ens permeten detectar outliers

### Distancia de Mahalanobis

Medeix la distancia de un punt respecte a la mitjana considerant la covarian√ßa

```{r}
#| label: dist_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false
 
distancia_mahalanobis <- mahalanobis(dades, colMeans(dades), cov(dades))
```

Grafiquem el plot de la densitat de les distancies

```{r}
#| label: plot_density_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false

plot(density(distancia_mahalanobis))
```

Es mostren els valors de la bbdd que queden per sobre de el 99% de la distribuci√≥ chi-cuadrat

```{r}
#| label: cuttoff_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false

cutoff <- qchisq(p = 0.99, df = ncol(dades))
dades[distancia_mahalanobis>cutoff, ]
```

Ordenamos de forma decreciente, seg√∫n el score de Mahalanobis

```{r}
#| label: segmentar_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false

dades <- dades[order(distancia_mahalanobis, decreasing = TRUE),]
```

Visualitzem l'histograma de les distancies per veure on tallem els outliers

```{r}
#| label: plot_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false

par(mfrow=c(1,1))
hist(distancia_mahalanobis)
```

Descartamos los outliers seg√∫n un umbral

```{r}
#| label: umbral_mahalanobis
#| echo: true
#| warning: false
#| message: false
#| error: false

umbral <- 8
dades[, "outlier"] <- (distancia_mahalanobis > umbral)

dades[, "color"] <- ifelse(dades[, "outlier"], "red", "black")
scatterplot3d(dades[, "DC"], dades[, "temp"], dades[, "RH"], 
              color = dades[, "color"])

(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, 
                       color = ~color, colors = c('#0C4B8E', '#BF382A')) %>% 
                        add_markers())

(quienes <- which(dades[, "outlier"] == TRUE))
```

#### Mahalanobis Robusto

```{r}
#| label: mahalanobis_robusto
#| echo: true
#| warning: false
#| message: false
#| error: false

library(chemometrics)

dis <- chemometrics::Moutlier(dades[, c("DC", "temp", "RH")], quantile = 0.99, plot = TRUE)

par(mfrow = c(1, 1))
plot(dis$md, dis$rd, type = "n")
text(dis$md, dis$rd, labels = rownames(dades))
a <- which(dis$rd > 7)
print(a)
```

### Regresi√≥ Lineal i residus

Un punt amb un residu gran pot considerar-se un outlier

### Distancia de Cook

Identifica punts amb gran influ√®ncia en la regresi√≥. Un valor de Cook D_i \> 1 √©s un outliers.

### K-Nearest Neighbors (KNN) Outlier Score

Basats en la densitat local de les dades

```{r}
#| label: knn-outlier
#| echo: true
#| warning: false
#| message: false
#| error: false

library(adamethods)

do_knno(dades[, c("DC", "temp", "RH")], k=1, top_n = 30)

```

### Local Outlier Factor (LOF)

Compara la densidat de un punt amb la densidat dels seus ve√Øns. Un valor LOF alt

```{r}
#| label: lof1
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

library(DMwR2)
library(dplyr)

outlier.scores <- lofactor(dades[, c("DC", "temp", "RH")], k = 5)
par(mfrow=c(1,1))
plot(density(outlier.scores))
outlier.scores
outliers <- order(outlier.scores, decreasing=T)
outliers <- order(outlier.scores, decreasing=T)[1:5]
```

Aprofitarem el ACP per poder visualizar els outliers

```{r}
#| label: acp_lof
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

n <- nrow(dades[, c("DC", "temp", "RH")]); labels <- 1:n; labels[-outliers] <- "."
biplot(prcomp(dades[, c("DC", "temp", "RH")]), cex = .8, xlabs = labels)
```

Grafiquem les correlacions per veure els gr√°fics

```{r}
#| label: corrplot_lof
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false


pch <- rep(".", n)
pch[outliers] <- "+"
col <- rep("black", n)
col[outliers] <- "red"
pairs(dades[, c("DC", "temp", "RH")], pch = pch, col = col)
```

Ho visualitzem en 3D

```{r}
#| label: pca_3d_outliers
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

plot3d(dades[, "DC"], dades[, "temp"], dades[, "RH"], type = "s", col = col, size = 1)
```

#### Nueva versi√≥n de LOF

```{r}
#| label: lof2
#| echo: true
#| warning: false
#| message: false
#| error: false

library(Rlof)
outliers.scores <- Rlof::lof(dades[, c("DC", "temp", "RH")], k = 5)
plot(density(outliers.scores))
#outlier.scores <- lof(dades[, c("DC", "temp", "RH")], k=c(5:10))
```

### Isolation Forest

```{r}
#| label: isolation_forest_ddbb
#| echo: true
#| warning: false
#| message: false
#| error: false

### Cargamos las librerias necesarias
library(R.matlab)   # Lectura de archivos .mat
library(solitude)   # Modelo isolation forest
library(tidyverse)  # Preparaci√≥n de datos y gr√°ficos
library(MLmetrics)

# Carreguem les dades
cardio_mat  <- readMat("https://www.dropbox.com/s/galg3ihvxklf0qi/cardio.mat?dl=1")
df_cardio   <- as.data.frame(cardio_mat$X)
df_cardio$y <- as.character(cardio_mat$y)
datos <- df_cardio
```

```{r}
#| label: aplicar_isolationForest
#| echo: true
#| warning: false
#| message: false
#| error: false

isoforest <- isolationForest$new(
  sample_size = as.integer(nrow(datos)/2),
  num_trees   = 500, 
  replace     = TRUE,
  seed        = 123
)
isoforest$fit(dataset = datos %>% select(-y))
```

Ara anem a realitzar les prediccions.

```{r}
#| label: predicciones_isolationForest
#| echo: true
#| warning: false
#| message: false
#| error: false

predicciones <- isoforest$predict(
  data = datos %>% select(-y)
)
head(predicciones)
```

```{r}
#| label: plot_isolationForest
#| echo: true
#| warning: false
#| message: false
#| error: false

ggplot(data = predicciones, aes(x = average_depth)) +
  geom_histogram(color = "gray40") +
  geom_vline(
    xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),
    color      = "red",
    linetype   = "dashed") +
  labs(
    title = "Distribuci√≥n de las distancias medias del Isolation Forest",
    subtitle = "Cuantiles marcados en rojo"  ) +
  theme_bw() +
  theme(plot.title = element_text(size = 11))

cuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))
cuantiles
```

### TIPS: Detecci√≥n de anomal√≠as

Una vez que la distancia de separaci√≥n ha sido calculado, se puede emplear como criterio para identificar anomal√≠as. Asumiendo que las observaciones con valores at√≠picos en una o m√°s de sus variables se separan del resto con mayor facilidad, aquellas observaciones con menor distancia promedio deber√≠an ser las m√°s at√≠picas.

En la pr√°ctica, si se est√° empleando esta estrategia de detecci√≥n es porque no se dispone de datos etiquetados, es decir, no se conoce qu√© observaciones son realmente anomal√≠as. Sin embargo, como en este ejemplo se dispone de la clasificaci√≥n real, se puede verificar si realmente los datos an√≥malos tienen menores distancias.

```{r}
#| label: plot_deteccionAnomalias
#| echo: true
#| warning: false
#| message: false
#| error: false

datos <- datos %>%
  bind_cols(predicciones)

ggplot(data = datos,
       aes(x = y, y = average_depth)) +
  geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) + 
  geom_violin(alpha = 0) +
  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +
  stat_summary(fun = "mean", colour = "orangered2", size = 3, geom = "point") +
  labs(title = "Distancia promedio en el modelo Isolation Forest",
       x = "clasificaci√≥n (0 = normal, 1 = anomal√≠a)",
       y = "Distancia promedio") +
  theme_bw() + 
  theme(legend.position = "none",
        plot.title = element_text(size = 11)
  )

```

La distancia promedio en el grupo de las anomal√≠as (1) es claramente inferior. Sin embargo, al existir solapamiento, si se clasifican las n observaciones con menor distancia como anomal√≠as, se incurrir√≠a en errores de falsos positivos.

Acorde a la documentaci√≥n, el set de datos Cardiotocogrpahy contiene 176 anomal√≠as. V√©ase la matriz de confusi√≥n resultante si se clasifican como anomal√≠as las 176 observaciones con menor distancia predicha.

```{r}
#| label: matriz_confusion
#| echo: true
#| warning: false
#| message: false
#| error: false

resultados <- datos %>%
  select(y, average_depth) %>%
  arrange(average_depth) %>%
  mutate(clasificacion = if_else(average_depth <= 8.5, "1", "0"))

mat_confusion <- MLmetrics::ConfusionMatrix(
  y_pred = resultados$clasificacion,
  y_true = resultados$y)

mat_confusion
```

# Missing values (valores faltantes)

Los **valores faltantes** aparecen cuando una observaci√≥n no tiene registrado el valor en cierta variable.

Manejar correctamente los NA es esencial: eliminarlos puede reducir mucho el dataset, mientras que imputarlos incorrectamente puede introducir sesgos.

Existen varias t√©cnicas:

-   **Eliminaci√≥n de filas/columnas** con demasiados NA.
-   **Imputaci√≥n simple**, por ejemplo reemplazando con la media o moda.
-   **Imputaci√≥n avanzada**, como KNN o modelos predictivos.

> üëâ La elecci√≥n depende de la importancia de la variable, la cantidad de NA y el contexto del problema.

## Generate data with NA's

```{r}
#| label: generar_missings
#| echo: true
#| warning: false
#| message: false
#| error: false

colSums(is.na(iris))
iris.mis <- missForest::prodNA(iris, noNA = 0.1)
colSums((is.na(iris.mis)))
```

Otra forma de crear missings en el dataframe

```{r}
#| label: generar_missings2
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

iris.mis <- mi::create.missing(iris, pct.mis = 10)
```

## Little Test

Es un test que nos permite detectar con que tipo de NA's estamos enfrente:

```{r}
#| label: test_little
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

naniar::mcar_test(iris.mis)
```

Si el valor p de la prova √©s inferior a 0 aix√≤ vol dir que les dades amb NAs s'han generat aleat√≤riament.

## Patrons descriptius de NA en una base de dades

### Explorar les relacions de NA's

```{r}
#| label: vis_na_total
#| echo: true
#| warning: false
#| message: false
#| error: false

library(visdat)
library(ggplot2)
library(naniar)

vis_dat(airquality);
vis_dat(iris.mis)
vis_miss(airquality);
vis_miss(iris.mis)

ggplot(airquality, aes(x = Solar.R,y = Ozone)) + 
  geom_point()
ggplot(airquality, aes(x = Solar.R,  y = Ozone)) + 
  geom_miss_point()

ggplot(airquality, aes(x = Solar.R, y = Ozone)) + 
  geom_miss_point() + 
  facet_wrap(~Month)

ggplot(airquality, aes(x = Solar.R, y = Ozone)) + 
  geom_miss_point() + 
  facet_wrap(~Month) + 
  theme_dark()
```

### Visualitzaci√≥ dels NA's per variables

```{r}
#| label: vis_na_variables
#| echo: true
#| warning: false
#| message: false
#| error: false

gg_miss_var(airquality) + labs(y = "Look at all the missing ones")
```

### Detecci√≥ de NA's en la base de dades

```{r}
#| label: deteccio_na
#| echo: true
#| warning: false
#| message: false
#| error: false

aq_shadow <- bind_shadow(airquality)
```

Imprimeix el gr√†fic amb difer√®ncia a les NA i no a les NA,

```{r}
#| label: grafico_detec_na
#| echo: true
#| warning: false
#| message: false
#| error: false

airquality %>%
  bind_shadow() %>%
  group_by(Ozone_NA) %>%
  summarise_at(.vars = "Solar.R",
               .funs = c("mean", "sd", "var", "min", "max"),
               na.rm = TRUE)

ggplot(aq_shadow,
       aes(x = Temp,
           colour = Ozone_NA)) + 
  geom_density()
```

### Extreu estad√≠stiques amb NAs de la base de dades

```{r}
#| label: estadistiques_na
#| echo: true
#| warning: false
#| message: false
#| error: false

prop_miss_case(airquality)
pct_miss_case(airquality)
miss_case_summary(airquality)
miss_case_table(airquality)
prop_miss_var(airquality)
pct_miss_var(airquality)
miss_var_summary(airquality)
miss_var_table(airquality)
```

## Imputaci√≥ b√†sica

### Imputar con la media

```{r}
#| label: NA_valor_mitja
#| echo: true
#| warning: false
#| message: false
#| error: false

iris.mis[, "imputed_Sepal.Length"] <- with(iris.mis, Hmisc::impute(Sepal.Length, mean))
```

### Imputar con la mediana

```{r}
#| label: NA_valor_mediana
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

pre_median <- preProcess(dades, method = "medianImpute")
imputed_median <- predict(pre_median, dades)
diagnose(imputed_median)
```



### Imputar con un valor aleatorio

```{r}
#| label: NA_valor_aleatori
#| echo: true
#| warning: false
#| message: false
#| error: false

iris.mis[, "imputed_Sepal.Length2"] <- with(iris.mis, Hmisc::impute(Sepal.Length, 'random'))
```

De manera similar podeu utilitzar la mediana min, max, per imputar el valor que manca.

### Representa la distribuci√≥ a variables reals i d'imputaci√≥ a trav√©s del gr√°fico de densidad con ggplot2

```{r}
#| label: grafico_imputacion
#| echo: true
#| warning: false
#| message: false
#| error: false

df_long <- iris.mis %>%
  select(Sepal.Length, imputed_Sepal.Length, imputed_Sepal.Length2) %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red", "green"))

iris.mis[, c("imputed_Sepal.Length", "imputed_Sepal.Length2")] <- NULL
```

Otra forma es usando el paquete `argImpute`.

```{r}
#| label: argImpute
#| echo: true
#| warning: false
#| message: false
#| error: false

(impute_arg <- Hmisc::aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +
                           Species, data = iris.mis, n.impute = 5))
```

Revisamos la variable `Sepal.Length` con la imputaci√≥n realizada en cada una de las rondas.

```{r}
#| label: imputacion_SL
#| echo: true
#| warning: false
#| message: false
#| error: false

impute_arg$imputed$Sepal.Length
```

Calculamos la media para las 5 simulaciones.

```{r}
#| label: media_simulaciones
#| echo: true
#| warning: false
#| message: false
#| error: false

imputed_Sepal.Length <- rowMeans(impute_arg$imputed$Sepal.Length)
new_var_imputed <- iris$Sepal.Length
new_var_imputed[as.numeric(names(imputed_Sepal.Length))] <- imputed_Sepal.Length
```

Revisamos la diferencia entre las dos imputaciones.

```{r}
#| label: grafico_media_simulaciones
#| echo: true
#| warning: false
#| message: false
#| error: false

newBD <- data.frame(real = iris[, "Sepal.Length"], imputed = new_var_imputed)
df_long <- newBD %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

## Multiple Iterative Regression Imputation (MI method)

Imputamos los valores NA's con mi

```{r}
#| label: mi_imputation
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

mi_data <- mi::mi(iris.mis, seed = 335)
```

Revisamos la informaci√≥n de las imputaciones.

```{r}
#| label: grafico_mi_imputation
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

summary(mi_data)
plot(mi_data)
par(ask = FALSE)
```

Revisamos las interaciones de la base de datos

```{r}
#| label: graficamos_mi_iteration
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

mi_data@data
```

## Media con una variable target

Definimos la variable target

```{r}
target = "Species"
```

Definimos la base de datos con NA's

```{r}

data <- subset(iris, select = -c(get(target)))
data <- missForest::prodNA(data, noNA = 0.1)
data$Species <- iris[, target]
```

Definir variables a imputar (excluyendo la variable target)

```{r}

varImp <- colnames(data)[which(!colnames(data) %in% target)]
```

Calcular las medias por grupo

```{r}

means <- aggregate(data[, varImp], list(data[, target]), mean, na.rm = TRUE)
```

Imputar valores faltantes

```{r}
for (c in varImp) {
  for (g in means[, "Group.1"]) {
    cond <- data[, target] == g  # Condici√≥n booleana en vez de which()
    na_index <- is.na(data[, c]) & cond  # Seleccionar NA dentro del grupo
    
    # Asignar valores imputados
    data[na_index, c] <- means[means[, "Group.1"] == g, c]
  }
}
summary(data)
```

Visualizamos la diferencia entre las imputaciones

```{r}

iris[, "Tipo"] <- "original"
data[, "Tipo"] <- "imputed"
```

Unimos en un mismo dataframe

```{r}

data_long <- bind_rows(iris, data)
cols_numeric <- names(data_long)[sapply(data_long, is.numeric) & names(data_long) != "Tipo"]

# Convert a large data
data_long <- data_long %>%
  pivot_longer(cols = all_of(cols_numeric), names_to = "Variable", values_to = "Valor")

```

Creamos el gr√°fico con ggplot

```{r}

ggplot(data_long, aes(x = Valor, fill = Tipo)) +
  geom_density(alpha = 0.3) +  # Transparencia para comparaci√≥n
  facet_wrap(~Variable, scales = "free") +  # Un gr√°fico por variable
  labs(title = "Comparaci√≥n de Distribuciones: Original vs Imputado",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

Removemos la tipologia de variable

```{r}

iris.mis[, "Tipo"] <- NULL
```

## Multiple Imputation by Chained Equations (MICE)

Eliminamos las variables categoricas

```{r}

quiCat <- which(lapply(iris.mis, class) %in% c("character", "factor"))
categories <- names(iris.mis)[quiCat]
iris.mis2 <- subset(iris.mis, select = -c(get(categories)))
summary(iris.mis2)
```

Visualizamos los patrones de NA's de la base de datos

```{r}

par(mfrow = c(1, 1))
mice::md.pattern(iris.mis2, rotate.names = TRUE)
```

Tambi√©n lo podemos visualizar con el paquete VIM

```{r}

mice_plot <- VIM::aggr(iris.mis2, col=c('navyblue','yellow'),
                  numbers=TRUE, sortVars=TRUE,
                  labels=names(iris.mis), cex.axis=.7,
                  gap=3, ylab=c("Missing data","Pattern"))
```

A continuaci√≥n realizamos la imputaci√≥n de los valores faltanes de manera multivariada

```{r}

imputed_Data <- mice::mice(iris.mis2, m=5, maxit = 50, method = 'pmm', seed = 500)
summary(imputed_Data)
```

Inspeccionamos la calidad de las imputaciones

```{r}
mice::stripplot(imputed_Data, Sepal.Width, pch = 19, xlab = "Imputation number")
imputed_Data$imp$Sepal.Width
```

Al final seleccionamos una de las iteracciones y la dejamos como imputaci√≥n de los valores faltantes.

```{r}
completeData <- mice::complete(imputed_Data, action = "long")
```

### Exercices:

1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe

## KNN

```{r}
tipos <- sapply(iris.mis, class)
varNum <- names(tipos)[which(tipos %in% c("numeric", "integer"))]
data_knn_imputation <- multiUS::KNNimp(iris.mis[, varNum], k = 1)
summary(data_knn_imputation)
```

Visualizamos la diferencia entre las dos imputaciones.

```{r}
newBD <- data.frame(real = iris[, "Sepal.Length"], imputed = data_knn_imputation[, "Sepal.Length"])
df_long <- newBD %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

Otra forma de hacerlo en R seria la siguiente: 

```{r}

#| label: graficamos_mi_iteration
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

library("caret")
pre_knn <- preProcess(dades, method = "knnImpute", k = 2)
imputed_knn <- predict(pre_knn, dades)
diagnose(imputed_knn)
```

### Exercices:

1.  Deploy the multiple plot to compare the imputation and not imputation with all numeric vars in dataframe

## missForest

Imputamos los missings usando todos los parametros con los valores por defectos.

```{r}
library(missForest)
iris.imp <- missForest(iris.mis, variablewise = T, verbose = T) 
```

Visualizamos los valores imputados

```{r}

iris.imp$ximp
```

Visualizamos el error cometido en las imputaciones.

```{r}

iris.imp$OOBerror
```

NRMSE √©s un error normalitzat mitj√† al quadrat. S'utilitza per representar l'error derivat d'imputar valors continus. El PFC (proporci√≥ de falsament classificada) s'utilitza per representar l'error derivat d'imputar valors categ√≤rics.

Comparamos el accuracy actual,

```{r}

(iris.err <- mixError(iris.imp$ximp, iris.mis, iris))
```

Miramos la diferencia entre las dos imputaciones

```{r}
newBD <- data.frame(real = iris[, "Sepal.Length"], imputed =  iris.imp$ximp[, "Sepal.Length"])
df_long <- newBD %>%
  pivot_longer(cols = everything(), names_to = "Variable", values_to = "Valor")

ggplot(df_long, aes(x = Valor, fill = Variable)) +
  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n
  labs(title = "Densidad de las tres variables",
       x = "Valor",
       y = "Densidad") +
  theme_minimal() +
  scale_fill_manual(values = c("blue", "red"))
```

### Exercises:

1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe

### Extra

Quan es tracta de valors que manquen, √©s possible que vulgueu reempla√ßar valors per valors que manquen (NA). Aix√≤ √©s √∫til en els casos en qu√® es coneix l'origen de les dades i es pot estar segur de quins valors han de faltar. Per exemple, podr√≠eu saber que tots els valors de ¬´N/A¬ª, ¬´N A¬ª i ¬´No disponible¬ª, o -99 o -1 se suposa que falten.

naniar proporciona funcions per treballar espec√≠ficament en aquest tipus de problemes utilitzant la funci√≥ replace.with.na. Aquesta funci√≥ √©s el compliment a tidyr::replace els NA's, que reempla√ßa un valor NA per un valor especificat, mentre que naniar::replace,with_na reempla√ßa un valor per un NA:

```{r}
#| label: code_ejemplo
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

tidyr::replace_na: Missing values turns into a value (NA ‚Äì> -99)
naniar::replace_with_na: Value becomes a missing value (-99 ‚Äì> NA)
```

## MIMMI

Puedes descargar el fichero de MIMMI pinchando [aqu√≠](03_02_MIMMI.R)

# Features Selection

La selecci√≥n de variables involucra un conjunto de t√©cnicas cuyo objetivo es seleccionar el subconjunto de variables predictoras m√°s relevante para las fases de modelizaci√≥n. Esto es importante porque:

-   Variables predictoras redundantes pueden distraer o enga√±ar a los algoritmos de aprendizaje, lo que posiblemente se traduzca en un menor rendimiento, no solo predictivo (exactitud y precisi√≥n), sino tambi√©n en t√©rminos de tiempo de computaci√≥n.

-   Igualmente, la inclusi√≥n de variables irrelevantes aumenta el coste computacional y dificulta la interpretabilidad.

Una adecuada selecci√≥n de variables tiene ventajas importantes:

1.  Elimina las variables con informaci√≥n redundante
2.  Reduce el grado de complejidad de los modelos
3.  Evita o reduce el sobreajuste
4.  Incrementa de la precisi√≥n de las predicciones
5.  Reduce la carga computacional 

Debe comprobarse la magnitud de la varianza de las variables candidatas a ser seleccionadas y de sus correlaciones dos a dos, as√≠ como si existen combinaciones lineales entre ellas (multicolinealidad).

Los m√©todos de selecci√≥n de variables se pueden resumir en 2 grandes grupos: 

1.  Los que utilizan variables objetivo (supervisados)
2.  Los que no (no supervisados)

Nos centraremos en los que utilizan variable objetivo (supervisados). Estos se pueden dividir en los siguientes grupos: 

1.  **M√©todos tipo filtro** *(Filter)*: puntua de mayor a menor cada variable predictora en base a su capacidad predictiva y selecciona un subconjunto de variables dependiendo de dicha puntuaci√≥n. 
2.  **M√©todos tipo envoltura** *(wrapper)*: Elige un subconjunto de vaiables que dan como resultado el modelo con mayores prestaciones en cuanto a calidad de resultados y eficiencia.
3.  **M√©todos tipo intr√≠nsecos** *(embedded)*: Seleccionan las variables autom√°ticamente como parte del ajuste del modelo durante el entrenamiento.

## Preselecci√≥n de variables

### Varianza nula

Uno de los aspectos fundamentales en la selecci√≥n de variables es comprobar si su varianza es cero o cercana a cero porque, si es as√≠, sus valores son iguales o similares, respectivamente, y, por tanto, esas variables estar√°n perfectamente o cuasiperfectamente correlacionadas con el t√©rmino independiente del modelo, con lo cual, en el mejor de los casos, solo a√±adir√°n ruido al modelo. Este tipo de efecto acaba afectando en la divisi√≥n de los conjuntos de entrenamiento y validaci√≥n de los datos. 

Para visualizarlo en R, podemos hacer lo siguiente: 

```{r}
#| label: varianza_nula
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library(caret)
library(idealista18)
library(tidyverse)

Madrid_Sale <- as.data.frame(Madrid_Sale)
numeric_cols <- sapply(Madrid_Sale, is.numeric)
Madrid_Sale_num <- Madrid_Sale[, numeric_cols]

varianza <- nearZeroVar(Madrid_Sale_num, saveMetrics = T)
head(varianza, 2)
```

### Correlaci√≥n entre variables 

Una de las cuestiones a tener en cuenta en el proceso de selecci√≥n de variables es la magnitud de las **correlaciones entre variables** ya que esto puede afectar a la fiabilidad de las predicciones al tener variables muy correlacionadas. En el caso extreno el modelo tendr√° problemas de colinealidad o multicolinealidad. 

Para detectar las variables con muy elevada correlaci√≥n entre ellas, se le pasa la funci√≥n `findCorrelation()` de `caret`, con valor 0,9, a la matriz de correlaciones lineales entre las variables susceptibles de ser seleccionadas.

```{r}
#| label: correlaciones
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

madrid_cor <- cor(Madrid_Sale_num[, 1:20])
(alta_corr <- findCorrelation(madrid_cor, cutoff = .9))
```
Para visualizar, podemos ver el `corrplot`: 

```{r}
#| label: grafico_correlaciones
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library("corrplot")

matriz_corr <- cor(Madrid_Sale_num[, 1:8])
corrplot(matriz_corr, method = "circle")
```

### Combinaciones lineales

En la mayor√≠a de los casos las variables que se utilizan como predictoras no son ortogonales, sino que tienen cierto grado de dependencia lineal entre ellas. Si dicho grado es moderado, las consecuencias de la no ortogonalidad en la predicci√≥n no son graves, pero en los casos de dependencia lineal cuasiperfecta las inferencias resultantes del modelo estimado distan mucho de la realidad. Dichas consecuencias son a√∫n m√°s graves en el caso de que las combinaciones lineales sean perfectas. Por ello, la existencia de colinealidad o combinaciones lineales entre las variables seleccionables tambi√©n es una circunstancia a evitar. 

Las principales fuentes de multicolinealidad son:

*   El m√©todo utilizado en la recogida de datos (subespacios)
*   Restricciones en el modelo o en la poblaci√≥n (existencia de variables correlacionadas)
*   Especificaci√≥n del modelo (polinomios)
*   M√°s variables que observaciones

Los efectos de la multicolinealidad en los modelos son los siguientes: 

*   Los estimadores tendr√°n grandes varianzas y covarianzas
*   Las estimaciones de los coeficientes del modelo ser√°n demasiado grandes
*   Los signos de los coeficientes estimados suelen ser distintos a los esperados
*   Peque√±as variaciones en los datos, o en las especificaciones del modelo, provocar√°n grandes cambios en los coeficientes

Utilizando la funci√≥n `findLinearCombos()` del paquete `caret` permite encontrar combinaciones lineales de las variables predictoras. 

```{r}
#| label: busqueda_combinaciones
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

Madrid_Sale_num_na <- tidyr::drop_na(Madrid_Sale_num) # Es necesario eliminar los NA.
(combos <- findLinearCombos(Madrid_Sale_num_na))
```

En caso de encontrarse con problemas de multicolinealidad se deberia de realizar: 

* Eliminaci√≥n de variables predictoras que se encuentren altamente relacionadas con otras que permanecen en el modelo

* Sustituir las variables predictoras por componentes principales

* Incluir informaci√≥n externa a los datos originales. Esta alternativa implica utilizar estimadores contra√≠dos (de Stein o ridge) o bayesianos. 

Si quisieramos eliminar variables que son combinaciones lineales deberiamos de hacer lo siguiente: 

```{r}
#| label: eliminar_combinaci√≥n
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

head(Madrid_Sale_num_na[, -combos$remove])
```

## M√©todos de selecci√≥n de variables 

En el *subset* de variables que sobrevivien al proceso anterior, es necesario detectar cuales de ellas han de entrar en el modelo. Esta fase se realiza porque: 

* Queremos simplificar los modelos para hacerlos m√°s interpretables
* Mejorar la precisi√≥n del modelo
* Reducir el tiempo de computaci√≥n. Entrenar algoritmos con mayor velocidad
* Evitar la maldici√≥n de la dimensionalidad (efecto Huges), que se refiere a las consecuencias no deseadas que tiene lugar cuando la dimensionalidad de un problema es muy elevada. 
* Reducir la probabilidad de sobreajuste

### *Filters*

Los **m√©todos de selecci√≥n de variables tipo filtro** usan t√©cnicas estad√≠sticas para evaluar la relaci√≥n entre cada variable predictora y la variable objetivo. Generalmente, consideran la influencia de cada variable predictora sobre la variable objetivo por separado. Las puntuaciones obtenidas se utilizan como base para clasificar y elegir las variables predictoras que se utilizar√°n en el modelo.

Si la variable predictora es num√©rica, entonces se usa el coeficiente de correlaci√≥n de Pearson o el de Spearman (si es o no lineal). Si las variables fueran todas categ√≥ricas se podria usar medidas de asociaci√≥n para tablas de contingencia. Por lo contrario si la entregada es categorica y la salida es num√©rica se podrian usar t√©cnicas de ANOVA para analizar que variables son influeyentes. 

Podemos usar diferentes paquetes como `FSelector`, `caret` para implementar dicha t√©cnica. En este caso, usaremos el paquete `FSinR`. A continuaci√≥n se muestra un ejemplo para variables predictoras num√©ricas. Para ello, se toma una muestra del conjunto de datos. Una vez en disposici√≥n de la muestra, primeramente se transforma la variable objetivo en categ√≥rica, siendo las categor√≠as (intervalos) cuatro cortes de la distribuci√≥n de sus valores; dicha categorizaci√≥n se lleva a cabo mediante **binning** Tambi√©n se eliminan los registros con datos faltantes.

```{r}
#| label: muestreo
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library("rsample")

# Se toma una muestra con el paquete rsample
set.seed(7)
Madrid_Sale_num_sample <- sample(1:nrow(Madrid_Sale_num), size = 5000, replace = FALSE)
Madrid_Sale_num_sample <- Madrid_Sale_num[Madrid_Sale_num_sample, ]
# Se realiza binning con cuatro bins
Madrid_Sale_num_sample_bin <- Madrid_Sale_num_sample |>
  mutate(price_bin = cut(PRICE, breaks = c(0, 250000, 500000, 750000, 10000000), labels = c("primerQ", "segundoQ", "tercerQ", "c"), include.lowest = TRUE)) |>
  select(price_bin, CONSTRUCTEDAREA, ROOMNUMBER, BATHNUMBER, HASTERRACE, HASLIFT)
# Se eliminan los registros con valores missing
Madrid_Sale_sample_na <- drop_na(Madrid_Sale_num_sample_bin)
```

Una vez discretizada la variable objetivo, se selecciona el conjunto de variables predictoras de la variable objetivo `price_bin`, que es la variable `PRICE` transformada mediante *binning*. Como m√©todo tipo filtro se utiliza minimum description length (MDLM), que es un m√©todo de selecci√≥n de variables que se basa en una medida de la complejidad del modelo denominada ‚Äúlongitud m√≠nima de la descripci√≥n‚Äù (de ah√≠ el nombre del modelo), por lo que su objetivo es encontrar el modelo m√°s sencillo que proporcione una explicaci√≥n aceptable de los datos. Como algoritmo de b√∫squeda se utiliza sequential forward selection.

```{r}
#| label: Filter
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

library("FSinR")

# M√©todo tipo filtro MDLC (Minimum-Description_Length-Criterion)
evaluador <- filterEvaluator("MDLC")

# Se genera el algoritmo de b√∫squeda
buscador <- searchAlgorithm("sequentialForwardSelection")

# Se implementa el proceso, pasando a la funci√≥n los dos par√°metros anteriores
resultados <- featureSelection(Madrid_Sale_sample_na, "price_bin", buscador, evaluador)

# Se muestran los resultados
resultados$bestFeatures
resultados$bestValue
```


### *Wrappers*

Este enfoque realiza una b√∫squeda a trav√©s de diferentes combinaciones o subconjuntos de variables predictoras/clasificadoras para comprobar el efecto que tienen en la precisi√≥n del modelo.

Los m√©todos wrapper son de gran eficacia a la hora de eliminar variables irrelevantes y/o redundantes (cosa que no ocurre en los de tipo filtro porque se centran en el poder predictor de cada variable de forma aislada). 

tienen en cuenta la circunstancia de que dos o m√°s variables, aparentemente irrelevantes en cuanto a su capacidad predictiva o clasificatoria cuando se consideran una por una, pueden ser relevantes cuando se consideran conjuntamente. Sin embargo, son muy lentos, ya que tienen que aplicar much√≠simas veces el algoritmo de b√∫squeda, cambiando cada vez el n√∫mero de variables, siguiendo cada vez alg√∫n criterio tanto de b√∫squeda como de paro. 

```{r}
#| label: Wrapper
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

# Se fijan los par√°metros
evaluador <- wrapperEvaluator("rpart1SE")
buscador <- searchAlgorithm("sequentialForwardSelection")
# Se eval√∫an sobre Madrid_Sale_sample_na
results <- featureSelection(Madrid_Sale_sample_na, "price_bin", buscador, evaluador)
resultados$bestFeatures
resultados$bestValue
```

### *Embeddings*

Hay algunos algoritmos de aprendizaje autom√°tico que realizan la selecci√≥n autom√°tica de variables como parte del aprendizaje del modelo. Estos son los m√©todos de selecci√≥n de tipo intr√≠nseco, que aglutinan las ventajas de los m√©todos de filtro y envoltura.

```{r}
#| label: Embeddings
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

library("randomForest")

# Usar random forest para la selecci√≥n de variables
rf_modelo <- randomForest(price_bin ~ ., data = Madrid_Sale_num_sample_bin)

# Listar las variables m√°s importantes
varImp(rf_modelo)
```

# Features Enginineering

La ingenier√≠a de variables consiste en el proceso de conseguir, a partir de la informaci√≥n disponible, las variables id√≥neas (y en el n√∫mero apropiado) para que los modelos o clasificadores proporcionen los mejores resultados posibles, dados los datos disponibles y el modelo a ejecutar. 

Una de las herramientas m√°s populares es el **One-hot encoding**. El **One-hot encoding** consiste en asignar a cada etiqueta un n√∫mero entero o valor √∫nico seg√∫n el orden alfab√©tico. Es la codificaci√≥n m√°s popular y ampliamente utilizada.

```{r}
#| label: one-hot-encoding
#| echo: true
#| eval: false
#| warning: false
#| message: false
#| error: false

dummies <- dummyVars("  ~ .", data = Madrid_Sale_num_sample_bin)
head(predict(dummies, newdata = Madrid_Sale_num_sample_bin))
```

# Validaci√≥n y control de calidad 

Al final del proceso de limpieza de datos, estos deber√≠an ser consistentes y seguir las reglas apropiadas para su campo de negocio. De no ser as√≠, los modelos que se estimen en base a ellos no representar√°n convenientemente la realidad objeto de estudio y las conclusiones que se obtengan de dichos modelos no ser√°n de utilidad para dicha realidad.

La verificaci√≥n de si los datos son o no consistentes y si siguen o no las reglas del campo de negocio del cual proceden se puede llevar a cabo con el paquete `tidyverse`, que permite hacer selecciones, filtrados o tablas de frecuencias, entre otras acciones.

Una opci√≥n m√°s sofisticada es el paquete `validate`, donde se pueden introducir las reglas de negocio dentro del propio c√≥digo o bien desde un fichero externo. A continuaci√≥n, se realiza un ejemplo con las reglas incrustadas en el propio c√≥digo. Estas reglas pueden ser avisos o normas que indican error en esos datos. En este ejemplo, se han definido siete reglas: por ejemplo, `PRICE` ‚â• 0, o que la suma de las variables `HASNORTHORIENTATION`, `HASSOUTHORIENTATION`, `HASEASTORIENTATION` y `HASWESTORIENTATION` sea la unidad. La salida que se obtiene se presenta a continuaci√≥n. 

```{r}
#| label: bbdd_validate
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false

Madrid_Sale_int <- as.data.frame(Madrid_Sale) |> select(-geometry)
```

```{r}
#| label: validate
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library("validate")

Madrid_Sale_int |>
  check_that(
    HASLIFT >= 0,
    PRICE >= 0,
    HASNORTHORIENTATION + HASSOUTHORIENTATION + HASEASTORIENTATION + HASWESTORIENTATION == 1,
    is.numeric(PRICE),
    UNITPRICE * CONSTRUCTEDAREA == PRICE,
    if (ROOMNUMBER > 3) PRICE > 100000,
    nrow(.) >= 20000
  ) |>
  summary()
```

En un esquema tradicional de validaci√≥n, adem√°s de las reglas de validaci√≥n aportadas por los expertos en el tema del que se trate, debe incluirse tambi√©n un listado de reglas de correcci√≥n (igualmente aportado por los expertos en la materia) que indique c√≥mo hay que corregir un registro cuando no cumple con una determinada regla de validaci√≥n. Este modo de proceder, adem√°s de suponer un doble esfuerzo, puede conducir a inconsistencias o validaciones c√≠clicas.

El **M√©todo de Fellegi y Holt (MFH)** da una soluci√≥n a este problema, evitando dichas inconsistencias, proporcionando un procedimiento que genera un conjunto completo de reglas de validaci√≥n, incorporando reglas impl√≠citas a las formuladas por los expertos de manera expl√≠cita.

Dicho m√©todo asegura el cumplimiento de las siguientes tres premisas:

* Minimizar el n√∫mero de campos a corregir en un registro para hacerlo pasar todas las validaciones.
* Mantener, en la medida de lo posible, la distribuci√≥n conjunta original del conjunto de datos.
* Derivar las reglas de correcci√≥n, directamente y de forma impl√≠cita, de las reglas de validaci√≥n. Por tanto, dichas reglas de correcci√≥n no son propuestas por el experto o, en su caso, por el validador.

El **MFH** no est√° exento de limitaciones. La primera es el incremento del coste computacional, que puede llegar a constituir un problema en caso de que el n√∫mero de reglas impl√≠citas sea muy elevado, lo cual es muy frecuente. De hecho, hay casos en los que hay m√°s reglas impl√≠citas que registros. Para solucionar este problema, denominado *‚Äúproblema de localizaci√≥n del error‚Äù*, que consiste, b√°sicamente, en determinar el conjunto m√≠nimo de variables a corregir para cada validaci√≥n, se han propuesto varias alternativas, que incluyen m√©todos de investigaci√≥n de operaciones, √°rboles binarios y metaheur√≠sticas como algoritmos gen√©ticos y similares.

A efectos pr√°cticos, el MFH se puede aplicar con la funci√≥n `locate_errors()` del paquete `errorlocate`, determin√°ndose as√≠ cu√°les son las variables a corregir para solventar los errores en las reglas de negocio establecidas (objeto rules). 

```{r}
#| label: deteccion_error
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library("errorlocate")

Madrid_Sale_red2 <- mutate(Madrid_Sale_int, price_bin = cut2(PRICE, g=4))

rules <- validator(if (ROOMNUMBER >= 10) price_bin == "[502000,7138000]")
(el <- locate_errors(Madrid_Sale_red2, rules) |>
  summary(el))
```

¬øY qu√© se debe hacer con los registros que no cumplen las normas de validaci√≥n? La respuesta es, como norma, ‚Äúsiempre que se disponga de informaci√≥n de negocio, esta debe preponderar sobre cualquier tipo de imputaci√≥n‚Äù. A partir de este punto se puede proceder a realizar imputaciones determin√≠sticas para solucionar los problemas detectados.

En el ejemplo anterior, se propone imputar el valor `ROOMNUMBER=5` a los casos de los tres primeros cuartiles (todos menos el m√°s caro) que tengan m√°s de 10 habitaciones. Para ello, se utiliza la funci√≥n `modify_so()` del paquete `dcmodify`. Para comprobar que la imputaci√≥n se ha llevado a cabo con √©xito, se pueden comparar los conjuntos de datos antes y despu√©s de la imputaci√≥n con la funci√≥n `compare()`, comprob√°ndose que tal imputaci√≥n se ha realizado exitosamente en los 2 registros que presentaban problemas con la regla `ROOMNUMBER >= 10`.

```{r}
#| label: modificar_reglas
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false

library("dcmodify")
out <- Madrid_Sale_red2 |>
  modify_so(if (ROOMNUMBER >= 10 & price_bin != "[502000,7138000]") ROOMNUMBER <- 5)
rules <- validator(if (ROOMNUMBER >= 10) price_bin == "[502000,7138000]")
compare(rules, raw = Madrid_Sale_red2, modified = out)
```

# Bibliograf√≠a

## Outliers

-   https://statsandr.com/blog/outliers-detection-in-r/#z-scores
-   https://m-mburu.github.io/datacamp/anomaly_detection_R/anomaly_detection.html
-   https://github.com/pridiltal/ctv-AnomalyDetection

## Imputaci√≥n

-   http://naniar.njtierney.com/articles/replace-with-na.html
-   https://cran.r-project.org/web/packages/visdat/vignettes/using_visdat.html
-   https://cran.r-project.org/web/packages/DMwR2/DMwR2.pdf
-   https://ltorgo.github.io/DMwR2/RintroDM.html#data_pre-processing
-   https://www.rdocumentation.org/packages/DMwR/versions/0.4.1/topics/knnImputation
-   https://amices.org/mice/
