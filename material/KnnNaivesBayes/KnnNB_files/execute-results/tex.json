{
  "hash": "6fdbdf4071d2940fb65cfd49a2e2acb4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Machine Learning I\"\nsubtitle: \"KNN y Naives Bayes\"\nauthor: Dante Conti, Sergi Ramirez, (c) IDEAI\ndate: \"2025-10-14\"\ndate-modified: \"2025-10-14\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: show\n    code-tools: true\n    theme: cerulean\n  pdf:\n    toc: true\n    number-sections: true\n    theme: cerulean\nexecute:\n  echo: true\n  eval: true\n  warning: false\n  message: false\neditor: visual\n---\n\n\n\n\n\n\n\n\n\n\n\n\n## Definición del problema \n\n\n### Contexto\n\nUna tienda está planteando la venta final del año. Queremos lanzar una oferta. Será válido sólo para los clientes existentes y la campaña a través de las llamadas telefónicas que se está planificando actualmente para ellos. La dirección considera que la mejor manera de reducir el coste de la campaña es hacer un modelo predictivo que clasifique a los clientes que puedan comprar la oferta. \n\nLas variables que contiene la base de datos son: \n\n-   **Response (target)**: 1 si el cliente aceptó la oferta en la última campaña, 0 en caso contrario\n-   **ID**: ID único de cada cliente\n-   **Year_Birth** - Edad del cliente\n-   **Complain** - 1 si el cliente presentó una queja en los últimos 2 años\n-   **Dt_Customer** - Fecha de alta del cliente en la empresa\n-   **Education** - Nivel de estudios del cliente\n-   **Marital** - Estado civil del cliente\n-   **Kidhome** - Número de niños pequeños en el hogar del cliente\n-   **Teenhome** - Número de adolescentes en el hogar del cliente\n-   **Income** - Ingresos anuales del hogar del cliente\n-   **MntFishProducts** - Cantidad gastada en productos de pescado en los últimos 2 años\n-   **MntMeatProducts** - Cantidad gastada en productos cárnicos en los últimos 2 años\n-   **MntFruits** - Cantidad gastada en frutas en los últimos 2 años\n-   **MntSweetProducts** - cantidad gastada en productos dulces en los últimos 2 años\n-   **MntWines** - cantidad gastada en productos de vino en los últimos 2 años\n-   **MntGoldProds** - cantidad gastada en productos de oro en los últimos 2 años\n-   **NumDealsPurchases** - número de compras realizadas con descuento\n-   **NumCatalogPurchases** - número de compras realizadas por catálogo (comprando productos con envío por correo)\n-   **NumStorePurchases** - número de compras realizadas directamente en tiendas\n-   **NumWebPurchases** - número de compras realizadas a través del sitio web de la empresa\n-   **NumWebVisitsMonth** - número de visitas al sitio web de la empresa en el último mes\n-   **Recency** - número de días desde la última compra\n\n### Objetivo \n\nLs supertienda quiere predecir la probabilidad que el cliente de una respuesta positiva y identificar los diferentes factores que afectan la respuesta del cliente.\n\nPodéis encontrar la base de datos en la siguiente [web](https://www.kaggle.com/datasets/ahsan81/superstore-marketing-campaign-dataset)\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n  Income Kidhome Teenhome Recency MntWines MntFruits MntMeatProducts\n1  84835       0        0       0      189       104             379\n2  57091       0        0       0      464         5              64\n3  67267       0        1       0      134        11              59\n4  32474       1        1       0       10         0               1\n5  21474       1        0       0        6        16              24\n6  71691       0        0       0      336       130             411\n  MntFishProducts MntSweetProducts MntGoldProds NumDealsPurchases\n1             111              189          218                 1\n2               7                0           37                 1\n3              15                2           30                 1\n4               0                0            0                 1\n5              11                0           34                 2\n6             240               32           43                 1\n  NumWebPurchases NumCatalogPurchases NumStorePurchases NumWebVisitsMonth\n1               4                   4                 6                 1\n2               7                   3                 7                 5\n3               3                   2                 5                 2\n4               1                   0                 2                 7\n5               3                   1                 2                 7\n6               4                   7                 5                 2\n  Response Edad Education_Basic Education_Graduation Education_Master\n1      Yes   55               0                    1                0\n2      Yes   64               0                    1                0\n3       No   67               0                    1                0\n4       No   58               0                    1                0\n5      Yes   36               0                    1                0\n6      Yes   67               0                    0                0\n  Education_PhD Marital_Status_Alone Marital_Status_Divorced\n1             0                    0                       1\n2             0                    0                       0\n3             0                    0                       0\n4             0                    0                       0\n5             0                    0                       0\n6             1                    0                       0\n  Marital_Status_Married Marital_Status_Single Marital_Status_Together\n1                      0                     0                       0\n2                      0                     1                       0\n3                      1                     0                       0\n4                      0                     0                       1\n5                      0                     1                       0\n6                      0                     1                       0\n  Marital_Status_Widow Marital_Status_YOLO mes_cliente_2 mes_cliente_3\n1                    0                   0             0             0\n2                    0                   0             0             0\n3                    0                   0             0             0\n4                    0                   0             0             0\n5                    0                   0             0             0\n6                    0                   0             0             1\n  mes_cliente_4 mes_cliente_5 mes_cliente_6 mes_cliente_7 mes_cliente_8\n1             0             0             1             0             0\n2             0             0             1             0             0\n3             0             1             0             0             0\n4             0             0             0             0             0\n5             0             0             0             0             1\n6             0             0             0             0             0\n  mes_cliente_9 mes_cliente_10 mes_cliente_11 mes_cliente_12 Complain_Yes\n1             0              0              0              0            0\n2             0              0              0              0            0\n3             0              0              0              0            0\n4             0              0              1              0            0\n5             0              0              0              0            0\n6             0              0              0              0            0\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## KNN\n\n### KNN Classifier\n\n#### Definimos los conjuntos de datos\n\n::: panel-tabset\n\n## R: R Base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1994)\n\nind_col <- c(16)\n\ndefault_idx = sample(nrow(datos), nrow(datos)*0.7)\ntrain <- datos[default_idx, ]; test <- datos[-default_idx, ]\nX_train <- train[, -ind_col]; X_test <- test[, -ind_col]\ny_train <- train[, ind_col]; y_test <- test[, ind_col]\n\n# Convertimos todas las columnas en numéricas para que se pueda utilizar el algoritmo\n# de KNN\nX_train <- data.frame(lapply(X_train, as.numeric))\nX_test <- data.frame(lapply(X_test, as.numeric))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\nset.seed(1994)\n\nind_col <- c(16)\ndefault_idx <- createDataPartition(datos$Response, p = 0.7, list = FALSE)\nX_trainC <- datos[default_idx, ]\nX_testC <- datos[-default_idx, ]\ny_testC <- X_testC[, ind_col]\nX_testC <- X_testC[, -ind_col]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelLookup(\"knn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  model parameter      label forReg forClass probModel\n1   knn         k #Neighbors   TRUE     TRUE      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = datos_py.drop([\"Response\"], axis=1)\ny = datos_py['Response']\n\nX_trainPy, X_testPy, y_trainPy, y_testPy = train_test_split(X, y, test_size = 0.3, random_state = 1994)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Escalamos los datos \n\n::: panel-tabset\n\n## R: R Base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scales)\n\n# Suponemos que X_train y X_test son data.frames numéricos\ncols <- colnames(X_train)\n\n# Calcular medias y desviaciones estándar con X_train\nmeans <- sapply(X_train, mean)\nsds <- sapply(X_train, sd)\n\n# Estandarizar X_train\nX_train <- scale(X_train, center = means, scale = sds)\n\n# Aplicar la misma transformación a X_test\nX_test <- scale(X_test, center = means, scale = sds)\n\n# Convertir de nuevo a data.frame\nX_train <- as.data.frame(X_train)\nX_test <- as.data.frame(X_test)\n\n# Mantener nombres de columnas\ncolnames(X_train) <- cols\ncolnames(X_test) <- cols\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\n# Crear preprocesador para centrado y escalado\npreproc <- preProcess(X_trainC, method = c(\"center\", \"scale\"))\n\n# Aplicar transformación\nX_trainC <- predict(preproc, X_trainC)\nX_testC <- predict(preproc, X_testC)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ncols = X_trainPy.columns\n\nfrom sklearn.preprocessing import StandardScaler\nimport pandas as pd\n\nscaler = StandardScaler()\nX_trainPy = scaler.fit_transform(X_trainPy)\nX_testPy = scaler.transform(X_testPy)\n\nX_trainPy = pd.DataFrame(X_trainPy, columns=[cols])\nX_testPy = pd.DataFrame(X_testPy, columns=[cols])\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Entrenamiento del modelo \n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediccion <- knn(train = X_train, test  = X_test, cl = y_train, k = 3)\nhead(prediccion)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] No  Yes No  No  No  Yes\nLevels: No Yes\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(entrenamiento <- train(Response ~ ., data = X_trainC, method = \"knn\",\n                        trControl = trainControl(method = \"cv\", number = 5),\n                        # preProcess = c(\"center\", \"scale\"),\n                        tuneGrid = expand.grid(k = seq(1, 31, by = 2))))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nk-Nearest Neighbors \n\n1553 samples\n  39 predictor\n   2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (5 fold) \nSummary of sample sizes: 1243, 1242, 1243, 1242, 1242 \nResampling results across tuning parameters:\n\n  k   Accuracy   Kappa      \n   1  0.8325879  0.279679994\n   3  0.8473976  0.213133436\n   5  0.8493185  0.131995536\n   7  0.8544695  0.126768918\n   9  0.8538347  0.110964792\n  11  0.8493206  0.054785486\n  13  0.8486796  0.032064246\n  15  0.8467483  0.023317027\n  17  0.8467524  0.006447460\n  19  0.8473955  0.007760759\n  21  0.8493289  0.011490079\n  23  0.8480386  0.003353250\n  25  0.8486817  0.004620608\n  27  0.8493248  0.005851422\n  29  0.8486796  0.004579949\n  31  0.8493227  0.005847308\n\nAccuracy was used to select the optimal model using the largest value.\nThe final value used for the model was k = 7.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nentrenamiento$modelType\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Classification\"\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# import KNeighbors ClaSSifier from sklearn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# instantiate the model\nknn = KNeighborsClassifier(n_neighbors = 3)\n\n# fit the model to the training set\nknn.fit(X_trainPy, y_trainPy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsClassifier(n_neighbors=3)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### *Tunning parameters*: Selección del valor de k\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nk_to_try = 1:100\nerr_k = rep(x = 0, times = length(k_to_try))\n\nfor (i in seq_along(k_to_try)) {\n  pred <- knn(train = X_train, \n             test  = X_test, \n             cl    = y_train, \n             k     = k_to_try[i], \n             prob = T)\n  err_k[i] <- calc_class_err(y_test, pred)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# plot error vs choice of k\nplot(err_k, type = \"b\", col = \"dodgerblue\", cex = 1, pch = 20, \n     xlab = \"k, number of neighbors\", ylab = \"classification error\",\n     main = \"(Test) Error Rate vs Neighbors\")\n# add line for min error seen\nabline(h = min(err_k), col = \"darkorange\", lty = 3)\n# add line for minority prevalence in test set\nabline(h = mean(y_test == \"Yes\"), col = \"grey\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/visualizar_movimiento_base-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_best_result = function(caret_fit) {\n  best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))\n  best_result = caret_fit$results[best, ]\n  rownames(best_result) = NULL\n  best_result\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(entrenamiento$results, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  k  Accuracy     Kappa  AccuracySD    KappaSD\n1 1 0.8325879 0.2796800 0.012589167 0.04474886\n2 3 0.8473976 0.2131334 0.015312908 0.09135524\n3 5 0.8493185 0.1319955 0.014549182 0.10608590\n4 7 0.8544695 0.1267689 0.007133587 0.06311837\n5 9 0.8538347 0.1109648 0.007330331 0.05904349\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(entrenamiento)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_accuracy_caret-1.pdf){fig-pos='H'}\n:::\n\n```{.r .cell-code}\ntablaResultados <- entrenamiento$results\ntablaResultados$error <- 1 - tablaResultados$Accuracy\n\n# plot error vs choice of k\nplot(tablaResultados$error, type = \"b\", col = \"dodgerblue\", cex = 1, pch = 20, \n     xlab = \"k, number of neighbors\", ylab = \"classification error\",\n     main = \"(Test) Error Rate vs Neighbors\")\n# add line for min error seen\nabline(h = min(err_k), col = \"darkorange\", lty = 3)\n# add line for minority prevalence in test set\nabline(h = mean(y_test == \"Yes\"), col = \"grey\", lty = 2)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_accuracy_caret-2.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nget_best_result(entrenamiento)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  k  Accuracy     Kappa  AccuracySD    KappaSD\n1 7 0.8544695 0.1267689 0.007133587 0.06311837\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nentrenamiento$finalModel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n7-nearest neighbor model\nTraining set outcome distribution:\n\n  No  Yes \n1319  234 \n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt # for data visualization purposes\n\nk_range = range(1, 20)\nscores = []\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_trainPy, y_trainPy)\n    scores.append(knn.score(X_testPy, y_testPy))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsClassifier(n_neighbors=1)\nKNeighborsClassifier(n_neighbors=2)\nKNeighborsClassifier(n_neighbors=3)\nKNeighborsClassifier(n_neighbors=4)\nKNeighborsClassifier()\nKNeighborsClassifier(n_neighbors=6)\nKNeighborsClassifier(n_neighbors=7)\nKNeighborsClassifier(n_neighbors=8)\nKNeighborsClassifier(n_neighbors=9)\nKNeighborsClassifier(n_neighbors=10)\nKNeighborsClassifier(n_neighbors=11)\nKNeighborsClassifier(n_neighbors=12)\nKNeighborsClassifier(n_neighbors=13)\nKNeighborsClassifier(n_neighbors=14)\nKNeighborsClassifier(n_neighbors=15)\nKNeighborsClassifier(n_neighbors=16)\nKNeighborsClassifier(n_neighbors=17)\nKNeighborsClassifier(n_neighbors=18)\nKNeighborsClassifier(n_neighbors=19)\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.figure()\nplt.xlabel('k')\nplt.ylabel('accuracy')\nplt.scatter(k_range, scores)\nplt.xticks([0,5,10,15,20])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n([<matplotlib.axis.XTick object at 0x0000024CB0FCBA90>, <matplotlib.axis.XTick object at 0x0000024CB0FE20D0>, <matplotlib.axis.XTick object at 0x0000024CB0FD93D0>, <matplotlib.axis.XTick object at 0x0000024CC0006710>, <matplotlib.axis.XTick object at 0x0000024CC0016FD0>], [Text(0, 0, '0'), Text(5, 0, '5'), Text(10, 0, '10'), Text(15, 0, '15'), Text(20, 0, '20')])\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/mejor_modelo_python-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Predicción de la variable respuesta\n\n::: panel-tabset\n\n## R: R base\n\nLa própia función que entrena el algoritmo ya devuelve las predicciones del algoritmo de KNN. \n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(predict(entrenamiento, newdata = X_testC, type = \"prob\"), n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n          No       Yes\n1  0.8571429 0.1428571\n2  0.8571429 0.1428571\n3  1.0000000 0.0000000\n4  0.7142857 0.2857143\n5  0.8571429 0.1428571\n6  0.8571429 0.1428571\n7  1.0000000 0.0000000\n8  1.0000000 0.0000000\n9  0.7142857 0.2857143\n10 0.8571429 0.1428571\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n##### Predicción de la etiqueta\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_predPy = knn.predict(X_testPy)\ny_predPy[:20]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray(['No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No',\n       'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No', 'No'], dtype=object)\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n##### Predicción de pertenecer a cada etiqueta\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\n# probability of getting output as 2 - benign cancer\nknn.predict_proba(X_testPy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([[0.68421053, 0.31578947],\n       [0.84210526, 0.15789474],\n       [0.89473684, 0.10526316],\n       ...,\n       [0.89473684, 0.10526316],\n       [1.        , 0.        ],\n       [1.        , 0.        ]], shape=(665, 2))\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Validación de la *performance* del modelo\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_class_err = function(actual, predicted) {\n  mean(actual != predicted)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_class_err(actual    = y_test,\n               predicted = knn(train = X_train,\n                               test  = X_test,\n                               cl    = y_train,\n                               k     = 5))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.1684211\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmax(which(err_k == min(err_k)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npredicciones <- knn(train = X_train, test = X_test, cl = y_train, k = 5)\ntable(predicciones, y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            y_test\npredicciones  No Yes\n         No  539  90\n         Yes  22  14\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Paquetes\nlibrary(class)      # knn\nlibrary(ggplot2)    # plotting\nlibrary(dplyr)      # %>%, mutate\nlibrary(tidyr)\n\n# --- Datos de entrada esperados ---\n# X_train, X_test: data.frames/ matrices numéricas\n# y_train, y_test: vector/factor de etiquetas (clases)\n\nk <- 5\n\n# 1) PCA AJUSTADO EN TRAIN (con centrado y escalado). Proyectamos train y test.\npca <- prcomp(X_train, center = TRUE, scale. = TRUE)\n\nZ_train <- predict(pca, newdata = X_train)[, 1:2]\nZ_test  <- predict(pca, newdata = X_test)[, 1:2]\n\ncolnames(Z_train) <- c(\"PC1\",\"PC2\")\ncolnames(Z_test)  <- c(\"PC1\",\"PC2\")\n\n# 2) Rango para el grid (usamos TRAIN para coherencia)\nh <- 0.02\nx_min <- min(Z_train[,1]) - 1; x_max <- max(Z_train[,1]) + 1\ny_min <- min(Z_train[,2]) - 1; y_max <- max(Z_train[,2]) + 1\n\ngrid <- expand.grid(\n  PC1 = seq(x_min, x_max, by = h),\n  PC2 = seq(y_min, y_max, by = h)\n)\n\n# 3) kNN en el plano PCA (class::knn no \"entrena\"; predice dado train/test)\n#    Usamos las coordenadas PCA de train como \"train\", y el grid como \"test\".\n#    Asegura que y_train sea factor.\ny_train <- factor(y_train)\ny_test  <- factor(y_test, levels = levels(y_train))\n\ngrid_pred <- knn(\n  train = Z_train,\n  test  = grid,\n  cl    = y_train,\n  k     = k\n)\n\ngrid$pred <- factor(grid_pred, levels = levels(y_train))\n\n# 4) Data frames para puntos\ndf_train <- data.frame(Z_train, clase = y_train, split = \"Train\")\ndf_test  <- data.frame(Z_test,  clase = y_test,  split = \"Test\")\n\n# 5) Paleta (ajusta si hay >2 clases)\npal_cls  <- c(\"#FF0000\", \"#00ffff\")           # puntos (clases)\npal_fill <- c(\"#FFAAAA\", \"#b3ffff\")           # fondo (clases)\nnames(pal_cls)  <- levels(y_train)\nnames(pal_fill) <- levels(y_train)\n\n# 6) Plot: fondo (grid) + puntos (train/test)\nggplot() +\n  geom_raster(data = grid, aes(x = PC1, y = PC2, fill = pred), alpha = 1) +\n  scale_fill_manual(values = pal_fill, name = \"Clase (fondo)\") +\n  geom_point(data = df_train, aes(PC1, PC2, color = clase), size = 1.8, stroke = .2) +\n  geom_point(data = df_test,  aes(PC1, PC2, color = clase), size = 2.2, stroke = .2, shape = 21) +\n  scale_color_manual(values = pal_cls, name = \"Clase (puntos)\") +\n  labs(\n    title = sprintf(\"Frontera kNN en plano PCA (k=%d, weights='distance')\", k),\n    x = \"PC1\", y = \"PC2\"\n  ) +\n  coord_equal(expand = FALSE, xlim = c(x_min, x_max), ylim = c(y_min, y_max)) +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_pca_modelo-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaret::confusionMatrix(predict(entrenamiento, newdata = X_testC), y_testC)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction  No Yes\n       No  555  89\n       Yes   9  10\n                                          \n               Accuracy : 0.8522          \n                 95% CI : (0.8229, 0.8783)\n    No Information Rate : 0.8507          \n    P-Value [Acc > NIR] : 0.4833          \n                                          \n                  Kappa : 0.1275          \n                                          \n Mcnemar's Test P-Value : 1.461e-15       \n                                          \n            Sensitivity : 0.9840          \n            Specificity : 0.1010          \n         Pos Pred Value : 0.8618          \n         Neg Pred Value : 0.5263          \n             Prevalence : 0.8507          \n         Detection Rate : 0.8371          \n   Detection Prevalence : 0.9713          \n      Balanced Accuracy : 0.5425          \n                                          \n       'Positive' Class : No              \n                                          \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nlibrary(reshape2)\n\n# Crear matriz de confusión como tabla\nconf_tbl <- table(Predicted = predict(entrenamiento, newdata = X_testC), Actual = y_testC)\n\n# Convertir a data.frame para ggplot\nconf_df <- as.data.frame(conf_tbl)\ncolnames(conf_df) <- c(\"Predicted\", \"Actual\", \"Freq\")\n\n# Visualización con ggplot2\nggplot(conf_df, aes(x = Actual, y = Predicted, fill = Freq)) +\n  geom_tile(color = \"white\") +\n  geom_text(aes(label = Freq), size = 5) +\n  scale_fill_gradient(low = \"#f7fcf0\", high = \"#084081\") +\n  labs(title = \"Matriz de confusión\", x = \"Valor real\", y = \"Predicción\") +\n  theme_minimal()\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/confusion_matrix_ggplot2-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# --- Si X_trainC incluye la columna 'Response', separamos:\n#     (si ya la tienes separada, omite estas dos líneas y usa tus objetos)\ny_trainC <- factor(X_trainC$Response)\nX_train_num <- X_trainC[, setdiff(names(X_trainC), \"Response\"), drop = FALSE]\n\n# Asegura que los predictores son numéricos\nX_train_num[] <- lapply(X_train_num, function(col) as.numeric(as.character(col)))\n\n# 1) Preprocesado SOLO sobre predictores (center, scale, pca=2)\npreproc <- preProcess(X_train_num, method = c(\"center\", \"scale\", \"pca\"), pcaComp = 2)\n\nZ_train <- predict(preproc, X_train_num)  # tendrá columnas PC1 y PC2\n\n# --- Prepara también el test de forma consistente ---\n# Si X_testC tiene 'Response', sepárala:\nif (\"Response\" %in% names(X_testC)) {\n  y_testC  <- factor(X_testC$Response, levels = levels(y_trainC))\n  X_test_num <- X_testC[, setdiff(names(X_testC), \"Response\"), drop = FALSE]\n} else {\n  # si ya tienes y_testC aparte:\n  X_test_num <- X_testC\n  y_testC    <- factor(y_testC, levels = levels(y_trainC))\n}\nX_test_num[] <- lapply(X_test_num, function(col) as.numeric(as.character(col)))\nZ_test <- predict(preproc, X_test_num)\n\n# 2) Control de entrenamiento (CV estratificada)\nctrl <- trainControl(method = \"cv\", number = 5)\n\n# 3) Entrenar kNN en el espacio PCA\nk <- 5\nmodelo_knn <- train(\n  x = Z_train,\n  y = y_trainC,\n  method = \"knn\",\n  tuneGrid = data.frame(k = k),\n  trControl = ctrl,\n  metric = \"Accuracy\"\n)\n\n# 3) Grid en el plano PCA (rango del TRAIN)\nh <- 0.02\nx_min <- min(Z_train$PC1) - 1; x_max <- max(Z_train$PC1) + 1\ny_min <- min(Z_train$PC2) - 1; y_max <- max(Z_train$PC2) + 1\n\ngrid <- expand.grid(\n  PC1 = seq(x_min, x_max, by = h),\n  PC2 = seq(y_min, y_max, by = h)\n)\n\n# 4) Predicción del fondo en el grid\ngrid$pred <- predict(modelo_knn, newdata = grid)\n\n# 5) Data frames para puntos\ndf_train <- data.frame(Z_train, clase = y_trainC, split = \"Train\")\ndf_test  <- data.frame(Z_test,  clase = y_testC,  split = \"Test\")\n\n# 6) Paletas\npal_cls  <- c(\"#FF0000\", \"#00ffff\")\npal_fill <- c(\"#FFAAAA\", \"#b3ffff\")\nnames(pal_cls)  <- levels(y_trainC)\nnames(pal_fill) <- levels(y_trainC)\n\n# 7) Plot\nggplot() +\n  geom_raster(data = grid, aes(x = PC1, y = PC2, fill = pred), alpha = 1) +\n  scale_fill_manual(values = pal_fill, name = \"Clase (fondo)\") +\n  geom_point(data = df_train, aes(PC1, PC2, color = clase), size = 1.8, stroke = .2) +\n  geom_point(data = df_test,  aes(PC1, PC2, color = clase), size = 2.2, stroke = .2, shape = 21) +\n  scale_color_manual(values = pal_cls, name = \"Clase (puntos)\") +\n  labs(\n    title = sprintf(\"Frontera kNN en plano PCA (k=%d)\", k),\n    x = \"PC1\", y = \"PC2\"\n  ) +\n  coord_equal(expand = FALSE, xlim = c(x_min, x_max), ylim = c(y_min, y_max)) +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_pca_caret-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import accuracy_score\nprint('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_testPy, y_predPy)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nModel accuracy score: 0.8571\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n#### Estudio del sobreajuste\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nprint('Training set score: {:.4f}'.format(knn.score(X_trainPy, y_trainPy)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTraining set score: 0.8478\n```\n\n\n:::\n\n```{.python .cell-code}\nprint('Test set score: {:.4f}'.format(knn.score(X_testPy, y_testPy)))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nTest set score: 0.8571\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport seaborn as sns # for data visualization\nfrom sklearn.metrics import confusion_matrix\n\n# visualize confusion matrix with seaborn heatmap\n\nplt.figure(figsize=(6,4))\nconfMatrix = confusion_matrix(y_testPy, y_predPy)\ncm_matrix = pd.DataFrame(data=confMatrix, columns=['Actual Positive:1', 'Actual Negative:0'], index=['Predict Positive:1', 'Predict Negative:0'])\n\nsns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/heatmap_matriz_confusion_python-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_testPy, y_predPy))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              precision    recall  f1-score   support\n\n          No       0.86      1.00      0.92       570\n         Yes       0.00      0.00      0.00        95\n\n    accuracy                           0.86       665\n   macro avg       0.43      0.50      0.46       665\nweighted avg       0.73      0.86      0.79       665\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as mpatches\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# ==== Parámetros ====\nn_neighbors = 5\nweights = 'distance'\nh = 0.02\n\n# ==== 0) Asegurar tipos correctos ====\nX_trainPy = np.asarray(X_trainPy, dtype=float)\nX_testPy  = np.asarray(X_testPy,  dtype=float)\ny_trainPy = np.asarray(y_trainPy)\ny_testPy  = np.asarray(y_testPy)\n\n# Codificar etiquetas a enteros (necesario para c= y pcolormesh)\nle = LabelEncoder()\ny_train_num = le.fit_transform(y_trainPy)\ny_test_num  = le.transform(y_testPy)\n\n# ==== 1) Estandarizar con medias/SD de train + PCA en train ====\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_trainPy)\nX_test_scaled  = scaler.transform(X_testPy)\n\npca = PCA(n_components=2, random_state=0)\nZ_train = pca.fit_transform(X_train_scaled).astype(float)   # coords PCA train\nZ_test  = pca.transform(X_test_scaled).astype(float)        # coords PCA test\n\n# ==== 2) Entrenar KNN en el espacio PCA (train) ====\nclf = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\nclf.fit(Z_train, y_train_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsClassifier(weights='distance')\n```\n\n\n:::\n\n```{.python .cell-code}\n# ==== 3) Mallado en el plano PCA (usando rango de TRAIN para coherencia) ====\nx_min, x_max = Z_train[:, 0].min() - 1, Z_train[:, 0].max() + 1\ny_min, y_max = Z_train[:, 1].min() - 1, Z_train[:, 1].max() + 1\n\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\n\nZ_grid_pred_num = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n# ==== 4) Paletas (binario por tus colores; amplía si hay >2 clases) ====\ncmap_light = ListedColormap(['#FFAAAA', '#b3ffff'])\ncmap_bold  = ListedColormap(['#FF0000', '#00ffff'])\n\n# ==== 5) Plot fondo + puntos ====\nplt.figure(figsize=(7, 5))\nplt.pcolormesh(xx, yy, Z_grid_pred_num, cmap=cmap_light, shading='auto')\n\n# Train\nplt.scatter(Z_train[:, 0], Z_train[:, 1], c=y_train_num, cmap=cmap_bold,\n            edgecolor='k', s=25, alpha=0.8, label='Train')\n\n# Test\nplt.scatter(Z_test[:, 0],  Z_test[:, 1],  c=y_test_num,  cmap=cmap_bold,\n            edgecolor='k', s=35, marker='o', label='Test')\n\nplt.xlim(xx.min(), xx.max())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(-6.339168687276463, 7.340831312723245)\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.ylim(yy.min(), yy.max())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(-4.743849161138547, 5.6961508388612305)\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title(f\"Frontera KNN en plano PCA (k={n_neighbors}, weights='{weights}')\")\n\n# Leyenda de clases con nombres originales\nclasses = list(le.classes_)\npalette = ['#FF0000', '#00ffff']  # ajusta si hay más clases\npatches = [mpatches.Patch(color=palette[i % len(palette)], label=str(lbl))\n           for i, lbl in enumerate(classes)]\nlegend_classes = plt.legend(handles=patches, title=\"Clases\",\n                            loc='upper right', bbox_to_anchor=(1.32, 1.0))\nplt.gca().add_artist(legend_classes)\n\nplt.legend(loc='best')  # leyenda Train/Test\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_clasificacion_python-3.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n### KNN Regresor\n\n#### Definimos los conjuntos de datos\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(FNN)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1994)\n\ndefault_idx = sample(nrow(datos), nrow(datos)*0.7)\n\ndatos <- datos[, -c(1)]\n\ntrain <- datos[default_idx, ]; test <- datos[-default_idx, ]\nX_train <- train[, -6]; X_test <- test[, -6]\ny_train <- train[, 6]; y_test <- test[, 6]\n\n# Convertimos todas las columnas en numéricas para que se pueda utilizar el algoritmo\n# de KNN\nX_train <- data.frame(lapply(X_train, as.numeric))\nX_test <- data.frame(lapply(X_test, as.numeric))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\n\nset.seed(1994)\n\ndefault_idx <- createDataPartition(datos$Recency, p = 0.7, list = FALSE)\nX_trainC <- datos[default_idx, ]\nX_testC <- datos[-default_idx, ]\ny_testC <- X_testC[, 6]\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = datos_py.drop([\"Recency\"], axis=1)\ny = datos_py['Recency']\n\nX_trainPy, X_testPy, y_trainPy, y_testPy = train_test_split(X, y, test_size = 0.3, random_state = 1994)\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.pipeline import Pipeline\n\n# y para regresión debe ser numérico:\ny_train = np.asarray(y_trainPy, dtype=float)\ny_test  = np.asarray(y_testPy,  dtype=float)\n\n# Detecta tipos\nnum_cols = X_trainPy.select_dtypes(include=[np.number]).columns.tolist()\ncat_cols = X_trainPy.select_dtypes(exclude=[np.number]).columns.tolist()\n\n# Preprocesador: escala numéricas y one-hot en categóricas\npreprocess = ColumnTransformer(\n    transformers=[\n        (\"num\", StandardScaler(), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), cat_cols),\n    ],\n    remainder=\"drop\"\n)\n\n# Transforma los datos usando el preprocesador ya ajustado\nX_trainPy = preprocess.fit_transform(X_trainPy)\nX_testPy  = preprocess.transform(X_testPy)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Entrenamiento del modelo\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred <- knn.reg(train = X_train, test = X_test, y = y_train, k = 1)\nhead(pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$call\nknn.reg(train = X_train, test = X_test, y = y_train, k = 1)\n\n$k\n[1] 1\n\n$n\n[1] 665\n\n$pred\n  [1] 171  14 102  32 469  14  38  67  64 171   2  43 746 217  17  69 818 333\n [19]   1 222 223  11  22 711  42 483  38   3  31 300  44  81  21  50  45 319\n [37] 352  31  42  62  24  24 115 300   6 117   8 223  16   5 186  90  13 168\n [55]  35   6  56   5  40   4 345 300  61 194  38 717 226  58  58   5  24  30\n [73] 168  27 145 689 107  67  16  50  44  70 100  21  46  92 431 178 570 161\n [91] 292   5  10  99  26 348  71  50 597  26 252  18   7  13  13 132  21 694\n[109]  30  24  17  24   8   8 141  14   8  14 175 115 161  13   3  69 320 185\n[127] 215  13  16  13  63 128 189  24 860  39 417  97   2 689  13   4  26 194\n[145] 199 364   4 860 215 195 119 507  73  27 142   5  28  11 711  75 172  92\n[163]  10  12 267 929  12   6   3 101  65  22 161 129 129   3  30   2 561 129\n[181]  29  47 108  92  11   2 384  83  11 249  46  44  24 217 294  18 212   8\n[199]   8 128   2 178 501 127 132 119 413 559  11 704 843  50  46 137  22 137\n[217]   3  35  10   4   7  69 929  11  19  10  92   7  31 568  47 243 424 689\n[235]   8  14 130 212  31  15 420 395  40  49 706  50 107 142 108 333  50   7\n[253]   8  22  18 132  50 535   8   6 226   8  14   5 275  83 119 119   5 845\n[271]  23  57  17   6  27  21  59 154   4   5  40 746 746  39  43   5 204 295\n[289]  13 264 132  83 107 160   4   5  17  81 205  16   6 305 305 845 107  18\n[307]  92  65 238  18 253 169  18 194 292  50  15  64   2 100 100  85 746  98\n[325]  11  32  46  29  81 317 259   8   3  10  46  84  18 237  10  13  29  75\n[343]  29 639  17  27  60  89  18  10 189 123  11  51 864   4   7  29   7  16\n[361]   3  29 594  17  29 445   3  27  17 206 913  97 377  22   9  21  84  11\n[379]  16 149  10  10   4  51 238 238 345 171  30  76  16 215   5  13 493 403\n[397] 128 107  21 444 756 104 104 345 345  57  27  49 298 352  12 131 216   7\n[415]  20 154  28 217 160  10  13  14  31  44 403 403 128 137  64 294  14 925\n[433]  74 790  19   7   5 590 590  33 142 217   5 101  93 100 180   8  46  93\n[451]  15   1   6 247  64   3 140  93   8  10  21 257 697  19  72  15  14 109\n[469]  93 124   6 108 462 568  83  10  29 160   6 465  74  14  14  66  71   7\n[487] 756  20 567  85 183  12  76 112 690 168 179 140  56   5  26 309 128  11\n[505] 137  13  15  11  54  54  16 151  24 387 133   9  16  27  30 324 287   7\n[523]  12 170  15  12  24 430  30  24 114 447 129  25  25  28 239  92   7  18\n[541]   5 612 154  10  22 168  73 368  15  11   5 253  76 287 112 217 133  19\n[559]   3  60 329   7  25 815  73 487  14 135  15   9  19   2 264  63  63 936\n[577]  16  79 359  88 415  65 792 387 449  11  12 278 221  10 534 428  18  19\n[595]  63   2  11 213  17 387  24  48 159   7   7   3  60  19 430  23  19 113\n[613]   9  46  54  41  21 500 103  74 597  23 420  39  25   4  14  43 106  33\n[631]  55 103  20 363 217  21  19 110   3  15 103  10   5 414  14  14 255  99\n[649]  22 159  19   3 838 818  15  11 128 838   6  24 142   3  21 159 500\n\n$residuals\nNULL\n\n$PRESS\nNULL\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncaret::modelLookup(\"knn\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  model parameter      label forReg forClass probModel\n1   knn         k #Neighbors   TRUE     TRUE      TRUE\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nknn <- train(Recency ~ ., data = X_trainC, method = \"knn\",\n             preProc = c(\"center\", \"scale\"), tuneGrid = data.frame(k = 1:10),\n             trControl = trainControl(method = \"cv\", number = 10))\n\nggplot(knn, highlight = TRUE) # Alternativamente: plot(knn)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/training_caret_regresion-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# Create and train the KNN regressor\nknn_regressor = KNeighborsRegressor(n_neighbors = 5)\nknn_regressor.fit(X_trainPy, y_trainPy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsRegressor()\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### **Tunning parameters:** Selección del valor de k \n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse = function(actual, predicted) {\n  sqrt(mean((actual - predicted) ^ 2))\n}\n\n# define helper function for getting knn.reg predictions\n# note: this function is highly specific to this situation and dataset\nmake_knn_pred <- function(k = 1, training, predicting, valueTarget) {\n  pred = FNN::knn.reg(train = training, \n                      test = predicting, \n                      y = valueTarget, k = k)$pred\n  act  = predicting$Recency\n  rmse(predicted = pred, actual = act)\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# define values of k to evaluate\nk = c(1, 5, 10, 25, 50, 250)\n\n# get requested train RMSEs\nknn_trn_rmse <- sapply(k, make_knn_pred, training = X_train, \n                      predicting = X_train, \n                      valueTarget = y_train)\n\n# determine \"best\" k\nbest_k <- k[which.min(knn_trn_rmse)]\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nregSummary <- function(data, lev = NULL, model = NULL) {\n  out <- c(\n    RMSE = RMSE(data$pred, data$obs),\n    Rsquared = R2(data$pred, data$obs),\n    MAE = MAE(data$pred, data$obs)\n  )\n  out\n}\n\n# Definimos un método de remuestreo\ncv <- trainControl(\n  method = \"repeatedcv\",\n  number = 10,\n  repeats = 5,\n  classProbs = TRUE,\n  preProcOptions = list(\"center\"),\n  summaryFunction = regSummary, \n  savePredictions = \"final\")\n\n# Definimos la red de posibles valores del hiperparámetro\nhyper_grid <- expand.grid(k = c(1:10,15,20,30,50,75,100))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1994)\n\n# Se entrena el modelo ajustando el hiperparámetro óptimo\nmodel <- train(\n  Recency ~ .,\n  data = X_trainC,\n  method = \"knn\",\n  trControl = cv,\n  tuneGrid = hyper_grid,\n  metric = \"MAPE\")\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport matplotlib.pyplot as plt # for data visualization purposes\n\ndef mean_absolute_percentage_error(y_true, y_pred):\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    # Evitar divisiones por cero\n    mask = y_true != 0\n    return np.mean(np.abs((y_true[mask] - y_pred[mask]) / y_true[mask])) * 100\n\nk_range = range(1, 20)\nscores = []\n\nfor k in k_range:\n    knn = KNeighborsRegressor(n_neighbors=k)\n    knn.fit(X_trainPy, y_trainPy)\n    y_pred = knn.predict(X_testPy)\n    mape = mean_absolute_percentage_error(y_testPy, y_pred)\n    scores.append(mape)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nKNeighborsRegressor(n_neighbors=1)\nKNeighborsRegressor(n_neighbors=2)\nKNeighborsRegressor(n_neighbors=3)\nKNeighborsRegressor(n_neighbors=4)\nKNeighborsRegressor()\nKNeighborsRegressor(n_neighbors=6)\nKNeighborsRegressor(n_neighbors=7)\nKNeighborsRegressor(n_neighbors=8)\nKNeighborsRegressor(n_neighbors=9)\nKNeighborsRegressor(n_neighbors=10)\nKNeighborsRegressor(n_neighbors=11)\nKNeighborsRegressor(n_neighbors=12)\nKNeighborsRegressor(n_neighbors=13)\nKNeighborsRegressor(n_neighbors=14)\nKNeighborsRegressor(n_neighbors=15)\nKNeighborsRegressor(n_neighbors=16)\nKNeighborsRegressor(n_neighbors=17)\nKNeighborsRegressor(n_neighbors=18)\nKNeighborsRegressor(n_neighbors=19)\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.figure(figsize=(6,4))\nplt.plot(k_range, scores, marker='o')\nplt.xlabel('k')\nplt.ylabel('MAPE (%)')\nplt.title('Error porcentual medio absoluto vs número de vecinos (k)')\nplt.xticks([0,5,10,15,20])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n([<matplotlib.axis.XTick object at 0x0000024CE182DB90>, <matplotlib.axis.XTick object at 0x0000024CE19A2390>, <matplotlib.axis.XTick object at 0x0000024CF2CDE210>, <matplotlib.axis.XTick object at 0x0000024CF2CDF3D0>, <matplotlib.axis.XTick object at 0x0000024CF2CEAE10>], [Text(0, 0, '0'), Text(5, 0, '5'), Text(10, 0, '10'), Text(15, 0, '15'), Text(20, 0, '20')])\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.show()\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/entrenamiento_cv_python-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n#### Predicción de la variable respuesta\n\n::: panel-tabset\n\n## R: R base\n\nLa própia función que entrena el algoritmo ya devuelve las predicciones del algoritmo de KNN.\n\n## R: packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(predict(model, newdata = X_testC), n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] 53.42667 45.97333 45.33333 45.33333 49.16000 50.50667 42.37333 51.86667\n [9] 41.64474 45.14667\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\ny_predPy = knn_regressor.predict(X_testPy)\ny_predPy[:10]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\narray([59.8, 56.4, 52. , 30.6, 24.6, 64.2, 48.8, 19.8, 56.6, 44. ])\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n## Naives Bayes (*Classifier*)\n\n### Definición de los conjuntos de datos\n\n::: panel-tabset\n\n## R: R Base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1994)\n\nind_col <- c(16)\n\ndefault_idx = sample(nrow(datos), nrow(datos)*0.7)\ntrain <- datos[default_idx, ]; test <- datos[-default_idx, ]\nX_train <- train; \n# X_train <- train[, -ind_col];\nX_test <- test[, -ind_col]\ny_train <- train[, ind_col]; y_test <- test[, ind_col]\n\n# Convertimos todas las columnas en numéricas para que se pueda utilizar el algoritmo\n# de KNN\n# X_train <- data.frame(lapply(X_train, as.numeric))\n# X_test <- data.frame(lapply(X_test, as.numeric))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"caret\")\nlibrary(\"naivebayes\")\nlibrary(\"reshape\")\nlibrary(\"ggplot2\")\n\nset.seed(1994)\n\nind_col <- c(16)\ndefault_idx <- createDataPartition(datos$Response, p = 0.7, list = FALSE)\nX_trainC <- datos[default_idx, ]\nX_testC <- datos[-default_idx, ]\ny_testC <- X_testC[, ind_col]\nX_testC <- X_testC[, -ind_col]\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nmodelLookup(\"naive_bayes\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n        model parameter                label forReg forClass probModel\n1 naive_bayes   laplace   Laplace Correction  FALSE     TRUE      TRUE\n2 naive_bayes usekernel    Distribution Type  FALSE     TRUE      TRUE\n3 naive_bayes    adjust Bandwidth Adjustment  FALSE     TRUE      TRUE\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import train_test_split\n\nX = datos_py.drop([\"Response\"], axis=1)\ny = datos_py['Response']\n\nX_trainPy, X_testPy, y_trainPy, y_testPy = train_test_split(X, y, test_size = 0.3, random_state = 1994)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n### Entrenamiento del modelo \n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(e1071)\n\n(nb_base <- naiveBayes(Response ~ ., data = X_train))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nNaive Bayes Classifier for Discrete Predictors\n\nCall:\nnaiveBayes.default(x = X, y = Y, laplace = laplace)\n\nA-priori probabilities:\nY\n       No       Yes \n0.8523533 0.1476467 \n\nConditional probabilities:\n     Kidhome\nY          [,1]      [,2]\n  No  0.4349470 0.5383867\n  Yes 0.3799127 0.5041390\n\n     Teenhome\nY          [,1]      [,2]\n  No  0.5378215 0.5437755\n  Yes 0.2969432 0.4857977\n\n     Recency\nY         [,1]     [,2]\n  No  51.97731 28.59796\n  Yes 34.79476 27.41649\n\n     MntWines\nY         [,1]     [,2]\n  No  274.1944 303.7532\n  Yes 491.6987 425.0553\n\n     MntFruits\nY         [,1]     [,2]\n  No  25.40847 39.46007\n  Yes 38.14410 46.63587\n\n     MntMeatProducts\nY         [,1]     [,2]\n  No  150.5719 210.0253\n  Yes 289.3406 288.9687\n\n     MntFishProducts\nY         [,1]     [,2]\n  No  35.83888 53.15100\n  Yes 53.18341 64.71829\n\n     MntSweetProducts\nY         [,1]     [,2]\n  No  26.44781 40.62991\n  Yes 41.91266 50.01554\n\n     MntGoldProds\nY         [,1]     [,2]\n  No  41.22617 49.78208\n  Yes 58.64192 56.85865\n\n     NumDealsPurchases\nY         [,1]     [,2]\n  No  2.274584 1.841840\n  Yes 2.305677 2.078084\n\n     NumWebPurchases\nY         [,1]     [,2]\n  No  3.925870 2.684626\n  Yes 4.982533 2.630731\n\n     NumCatalogPurchases\nY         [,1]     [,2]\n  No  2.472769 2.870076\n  Yes 4.283843 3.201254\n\n     NumStorePurchases\nY         [,1]     [,2]\n  No  5.806354 3.278682\n  Yes 6.213974 3.247479\n\n     NumWebVisitsMonth\nY         [,1]     [,2]\n  No  5.245083 2.443703\n  Yes 5.275109 2.655405\n\n     Edad\nY         [,1]     [,2]\n  No  56.27837 12.05355\n  Yes 54.92576 12.28602\n\n     Education_Basic\nY            [,1]       [,2]\n  No  0.027231467 0.16281882\n  Yes 0.008733624 0.09324869\n\n     Education_Graduation\nY          [,1]      [,2]\n  No  0.5136157 0.5000037\n  Yes 0.4454148 0.4981003\n\n     Education_Master\nY          [,1]      [,2]\n  No  0.1641452 0.3705475\n  Yes 0.1441048 0.3519653\n\n     Education_PhD\nY          [,1]      [,2]\n  No  0.2027231 0.4021801\n  Yes 0.3231441 0.4687017\n\n     Marital_Status_Alone\nY             [,1]       [,2]\n  No  0.0007564297 0.02750327\n  Yes 0.0043668122 0.06608186\n\n     Marital_Status_Divorced\nY           [,1]      [,2]\n  No  0.09077156 0.2873927\n  Yes 0.15283843 0.3606199\n\n     Marital_Status_Married\nY          [,1]      [,2]\n  No  0.4054463 0.4911640\n  Yes 0.3100437 0.4635243\n\n     Marital_Status_Single\nY          [,1]      [,2]\n  No  0.1891074 0.3917421\n  Yes 0.3144105 0.4652977\n\n     Marital_Status_Together\nY          [,1]      [,2]\n  No  0.2813918 0.4498484\n  Yes 0.1659389 0.3728407\n\n     Marital_Status_Widow\nY           [,1]      [,2]\n  No  0.03101362 0.1734201\n  Yes 0.04803493 0.2143085\n\n     Marital_Status_YOLO\nY             [,1]       [,2]\n  No  0.0007564297 0.02750327\n  Yes 0.0000000000 0.00000000\n\n     mes_cliente_2\nY              0          1\n  No  0.91527988 0.08472012\n  Yes 0.90829694 0.09170306\n\n     mes_cliente_3\nY              0          1\n  No  0.90544629 0.09455371\n  Yes 0.92576419 0.07423581\n\n     mes_cliente_4\nY              0          1\n  No  0.91830560 0.08169440\n  Yes 0.91266376 0.08733624\n\n     mes_cliente_5\nY              0          1\n  No  0.90922844 0.09077156\n  Yes 0.95633188 0.04366812\n\n     mes_cliente_6\nY              0          1\n  No  0.91906203 0.08093797\n  Yes 0.92576419 0.07423581\n\n     mes_cliente_7\nY              0          1\n  No  0.93948563 0.06051437\n  Yes 0.93886463 0.06113537\n\n     mes_cliente_8\nY              0          1\n  No  0.90771558 0.09228442\n  Yes 0.89956332 0.10043668\n\n     mes_cliente_9\nY              0          1\n  No  0.93267776 0.06732224\n  Yes 0.90829694 0.09170306\n\n     mes_cliente_10\nY              0          1\n  No  0.91301059 0.08698941\n  Yes 0.86462882 0.13537118\n\n     mes_cliente_11\nY              0          1\n  No  0.91981846 0.08018154\n  Yes 0.92576419 0.07423581\n\n     mes_cliente_12\nY              0          1\n  No  0.90771558 0.09228442\n  Yes 0.92576419 0.07423581\n\n     Complain_Yes\nY           [,1]      [,2]\n  No  0.01059002 0.1024002\n  Yes 0.01310044 0.1139540\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# se fija la semilla aleatoria\nset.seed(1994)\n\n# se entrena el modelo\nmodel <- train(Response ~ .,\n            data=X_trainC,\n            method=\"nb\",\n            metric=\"Accuracy\",\n            trControl=trainControl(classProbs = TRUE,\n                                   method = \"cv\",\n                                   number = 10))\n\n# se muestra la salida del modelo\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNaive Bayes \n\n1553 samples\n  38 predictor\n   2 classes: 'No', 'Yes' \n\nNo pre-processing\nResampling: Cross-Validated (10 fold) \nSummary of sample sizes: 1397, 1398, 1397, 1397, 1398, 1398, ... \nResampling results across tuning parameters:\n\n  usekernel  Accuracy  Kappa   \n  FALSE           NaN       NaN\n   TRUE      0.845491  0.237876\n\nTuning parameter 'fL' was held constant at a value of 0\nTuning\n parameter 'adjust' was held constant at a value of 1\nAccuracy was used to select the optimal model using the largest value.\nThe final values used for the model were fL = 0, usekernel = TRUE and adjust\n = 1.\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport pandas as pd\n\n# --- 0) Asegura DataFrames (ajusta nombres si los tuyos son otros)\nX_train_df = pd.DataFrame(X_trainPy).copy()\nX_test_df  = pd.DataFrame(X_testPy).copy()\ny_train = np.asarray(y_trainPy)   # 'No'/'Yes' OK\ny_test  = np.asarray(y_testPy)\n\n# --- 1) Detecta columnas category (tus mes_cliente_*)\ncat_cols = [c for c, dt in X_train_df.dtypes.items() if str(dt) == 'category']\n\n# Convierte category -> numérico 0/1 (maneja '0'/'1' o niveles raros)\ndef cat_to_01(s: pd.Series) -> pd.Series:\n    # pasa a string, mapea '0'->0, '1'->1; si hay otros niveles, coerciona a num\n    out = pd.to_numeric(s.astype(str).map({'0': '0', '1': '1'}).fillna(s.astype(str)),\n                        errors='coerce')\n    return out.fillna(0).astype(np.int64)\n\nfor df in (X_train_df, X_test_df):\n    for c in cat_cols:\n        df[c] = cat_to_01(df[c])\n\n# --- 2) Asegura que TODO es numérico y ≥0\n# convierte posibles 'object' residuales a num (si los hubiera)\nfor df in (X_train_df, X_test_df):\n    for c in df.columns:\n        if df[c].dtype == 'O':\n            df[c] = pd.to_numeric(df[c], errors='coerce')\n\n# rellena NaN con 0\nX_train_df = X_train_df.fillna(0)\nX_test_df  = X_test_df.fillna(0)\n\n# clip a [0, +inf) por si hubiera algún negativo residual\nX_train_df = X_train_df.clip(lower=0)\nX_test_df  = X_test_df.clip(lower=0)\n\n# --- 3) Alinear columnas TEST = columnas TRAIN (mismo orden)\nX_test_df = X_test_df.reindex(columns=X_train_df.columns, fill_value=0)\n\n# (opcional) comprobaciones útiles\nassert not X_train_df.isna().any().any(), \"NaN en train\"\nassert not X_test_df.isna().any().any(),  \"NaN en test\"\nassert (X_train_df.dtypes != 'O').all(),   \"Quedan object en train\"\nassert (X_test_df.dtypes  != 'O').all(),   \"Quedan object en test\"\nassert (X_train_df.values >= 0).all(),     \"Negativos en train\"\nassert (X_test_df.values  >= 0).all(),     \"Negativos en test\"\n```\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\n# Build the model\nfrom sklearn.naive_bayes import MultinomialNB\n\n# Train the model\nnaive_bayes = MultinomialNB()\nnaive_bayes_fit = naive_bayes.fit(X_train_df, y_trainPy)\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n### *Tunning parameters*: Selección de los valores óptimos\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define tuning grid \nnb_grid <- expand.grid(usekernel = c(TRUE, FALSE),\n                       laplace = c(0, 0.5, 1), \n                       adjust = c(0.75, 1, 1.25, 1.5))\naccuracys <- c()\n\nfor (i in 1:nrow(nb_grid)) {\n  kn <- nb_grid[i, \"usekernel\"]\n  lp <- nb_grid[i, \"laplace\"]\n  nb_base <- naiveBayes(Response ~ ., data = X_train, laplace = lp, kernel = kn)\n  prediccion <- predict(nb_base, X_train)\n  tabla <- table(prediccion, y_train)\n  accuracy <- sum(diag(tabla))/sum(tabla)\n  accuracys <- c(accuracys, accuracy)\n}\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define tuning grid \nnb_grid <- expand.grid(usekernel = c(TRUE, FALSE),\n                       laplace = c(0, 0.5, 1), \n                       adjust = c(0.75, 1, 1.25, 1.5))\n\n# Fit the Naive Bayes model with parameter tuning\nset.seed(2550)\nnaive_bayes_via_caret2 <- train(Response ~ ., \n                                data = X_trainC, \n                                method = \"naive_bayes\",\n                                usepoisson = TRUE,\n                                tuneGrid = nb_grid)\n\n# View the selected tuning parameters\nnaive_bayes_via_caret2$finalModel$tuneValue\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   laplace usekernel adjust\n13       0      TRUE   0.75\n```\n\n\n:::\n\n```{.r .cell-code}\n# Visualize the tuning process\nplot(naive_bayes_via_caret2)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/nb_caret_parametrizar-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.model_selection import GridSearchCV, StratifiedKFold\nfrom sklearn.naive_bayes import MultinomialNB, BernoulliNB, ComplementNB\n\n# Métrica (elige la que te convenga)\nscorer = \"balanced_accuracy\"  # o 'balanced_accuracy', 'roc_auc', 'accuracy', etc.\n\n\npipe = Pipeline([\n    (\"clf\", MultinomialNB())  # nombre del paso = 'clf'\n])\n\n# Espacio de búsqueda: probamos 3 NB distintos\nparam_grid = [\n  {  # MultinomialNB\n    \"clf\": [MultinomialNB()],\n    \"clf__alpha\": [1e-3, 1e-2, 1e-1, 1.0, 2.0],\n    \"clf__fit_prior\": [True, False],\n  },\n  {  # ComplementNB\n    \"clf\": [ComplementNB()],\n    \"clf__alpha\": [1e-3, 1e-2, 1e-1, 1.0, 2.0],\n    \"clf__fit_prior\": [True, False],\n    \"clf__norm\": [True, False],\n  },\n  {  # BernoulliNB\n    \"clf\": [BernoulliNB()],\n    \"clf__alpha\": [1e-3, 1e-2, 1e-1, 1.0, 2.0],\n  },\n]\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\ngrid = GridSearchCV(\n    estimator=pipe,\n    param_grid=param_grid,\n    scoring=\"roc_auc\",\n    cv=cv,\n    n_jobs=1,     # importante en tu entorno\n    refit=True,\n    verbose=1\n)\n\ngrid.fit(X_train_df, y_trainPy)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nFitting 5 folds for each of 35 candidates, totalling 175 fits\nGridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n             estimator=Pipeline(steps=[('clf', MultinomialNB())]), n_jobs=1,\n             param_grid=[{'clf': [MultinomialNB()],\n                          'clf__alpha': [0.001, 0.01, 0.1, 1.0, 2.0],\n                          'clf__fit_prior': [True, False]},\n                         {'clf': [ComplementNB()],\n                          'clf__alpha': [0.001, 0.01, 0.1, 1.0, 2.0],\n                          'clf__fit_prior': [True, False],\n                          'clf__norm': [True, False]},\n                         {'clf': [BernoulliNB()],\n                          'clf__alpha': [0.001, 0.01, 0.1, 1.0, 2.0]}],\n             scoring='roc_auc', verbose=1)\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"Best:\", grid.best_estimator_)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBest: Pipeline(steps=[('clf', ComplementNB(alpha=2.0, norm=True))])\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"Params:\", grid.best_params_)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nParams: {'clf': ComplementNB(), 'clf__alpha': 2.0, 'clf__fit_prior': True, 'clf__norm': True}\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"CV score:\", grid.best_score_)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCV score: 0.7211343106077495\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n### Predicción de la variable respuesta\n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(predict(nb_base, X_test, type = \"class\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] Yes No  No  No  Yes No \nLevels: No Yes\n```\n\n\n:::\n\n```{.r .cell-code}\nhead(predict(nb_base, X_test, type = \"raw\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n               No        Yes\n[1,] 2.226092e-01 0.77739080\n[2,] 5.937698e-01 0.40623023\n[3,] 6.046064e-01 0.39539356\n[4,] 9.384762e-01 0.06152378\n[5,] 3.985234e-05 0.99996015\n[6,] 8.472974e-01 0.15270257\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(predict(naive_bayes_via_caret2, X_testC))\nhead(predict(naive_bayes_via_caret2, X_testC, type = \"prob\"))\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import confusion_matrix, balanced_accuracy_score\n\n# Make predictions\ntrain_predict = naive_bayes_fit.predict(X_train_df)\ntest_predict = naive_bayes_fit.predict(X_test_df)\n\ndef get_scores(y_real, predict):\n  ba_train = balanced_accuracy_score(y_real, predict)\n  cm_train = confusion_matrix(y_real, predict)\n\n  return ba_train, cm_train \n\ndef print_scores(scores):\n  return f\"Balanced Accuracy: {scores[0]}\\nConfussion Matrix:\\n {scores[1]}\"\n\ntrain_scores = get_scores(y_trainPy, train_predict)\ntest_scores = get_scores(y_testPy, test_predict)\n\n\nprint(\"## Train Scores\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n## Train Scores\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(print_scores(train_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBalanced Accuracy: 0.6493724679513846\nConfussion Matrix:\n [[966 347]\n [104 134]]\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(\"\\n\\n## Test Scores\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\n## Test Scores\n```\n\n\n:::\n\n```{.python .cell-code}\nprint(print_scores(test_scores))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBalanced Accuracy: 0.6157894736842106\nConfussion Matrix:\n [[432 138]\n [ 50  45]]\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n### Validación de la *performance* del modelo \n\n::: panel-tabset\n\n## R: R base\n\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnb_trn_pred = predict(nb_base, X_train)\nnb_tst_pred = predict(nb_base, X_test)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_class_err(predicted = nb_trn_pred, actual = y_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncalc_class_err(predicted = nb_tst_pred, actual = y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(predicted = nb_tst_pred, actual = y_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n         actual\npredicted 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52\n      No   0  0  0  3  1  4  4  4  3  9  6  4  6  6 11  3 13 18 11 21 15 15 15\n      Yes  1  1  2  2  3  4  3  1  4  2  2  3  6  5  3  5  1  5  5  9 12  7  6\n         actual\npredicted 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75\n      No  18 20 18 15  9  8  8 12  6  6 13  7  8  7  5  8 10 10  7  6  7  8  2\n      Yes 11  9  5  6  7  3  8  8 10  5  9  3  4  7  4  5 11  7 11  3  8  5  3\n         actual\npredicted 76 77 78 79 80 81 82 84 125\n      No   3  1  1  3  0  0  0  0   0\n      Yes  6  2  3  1  3  3  3  1   1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(e1071)\nlibrary(ggplot2)\n\ny_train <- factor(y_train)\ny_test  <- factor(y_test, levels = levels(y_train))\n\n# 1) Pasar predictores a numérico con dummies (model.matrix)\n#    Si X_* ya NO incluyen la respuesta, usa ~ . - 1\nmm_train <- model.matrix(~ . - 1, data = X_train)  # matriz numérica\nmm_test  <- model.matrix(~ . - 1, data = X_test)\n\n# 2) PCA en TRAIN (centrado y escalado), proyectar TEST\npca <- prcomp(mm_train, center = TRUE, scale. = TRUE)\nZ_train <- predict(pca, newdata = mm_train)[, 1:2]\nZ_test  <- predict(pca, newdata = mm_test)[, 1:2]\ncolnames(Z_train) <- c(\"PC1\",\"PC2\")\ncolnames(Z_test)  <- c(\"PC1\",\"PC2\")\n\n# 3) Naive Bayes (e1071) en el plano PCA\nnb <- naiveBayes(x = as.data.frame(Z_train), y = y_train, laplace = 0)\n\n# 4) Grid y predicción para pintar la frontera\nh <- 0.02\nx_min <- min(Z_train[,1]) - 1; x_max <- max(Z_train[,1]) + 1\ny_min <- min(Z_train[,2]) - 1; y_max <- max(Z_train[,2]) + 1\ngrid <- expand.grid(PC1 = seq(x_min, x_max, by = h),\n                    PC2 = seq(y_min, y_max, by = h))\ngrid$pred <- predict(nb, newdata = grid)\n\n# 5) Plot fondo + puntos\npal_fill <- c(\"No\" = \"#FFAAAA\", \"Yes\" = \"#b3ffff\")\npal_pts  <- c(\"No\" = \"#FF0000\", \"Yes\" = \"#00ffff\")\n\ndf_train <- data.frame(Z_train, clase = y_train, split = \"Train\")\ndf_test  <- data.frame(Z_test,  clase = y_test,  split = \"Test\")\n\nggplot() +\n  geom_raster(data = grid, aes(PC1, PC2, fill = pred)) +\n  scale_fill_manual(values = pal_fill, name = \"Fondo\") +\n  geom_point(data = df_train, aes(PC1, PC2, color = clase), size = 1.8) +\n  geom_point(data = df_test,  aes(PC1, PC2, color = clase), size = 2.2, shape = 21) +\n  scale_color_manual(values = pal_pts, name = \"Puntos\") +\n  coord_equal(expand = FALSE, xlim = c(x_min, x_max), ylim = c(y_min, y_max)) +\n  labs(title = \"Frontera Naive Bayes (e1071) en plano PCA\", x = \"PC1\", y = \"PC2\") +\n  theme_minimal()\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## R: Packages `caret`\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfusionMatrix(naive_bayes_via_caret2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBootstrapped (25 reps) Confusion Matrix \n\n(entries are percentual average cell counts across resamples)\n \n          Reference\nPrediction   No  Yes\n       No  84.1 14.1\n       Yes  0.9  1.0\n                            \n Accuracy (average) : 0.8509\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(melt(naive_bayes_via_caret2$resample[,-4]), aes(x = variable, y = value, fill=variable)) +\n  geom_boxplot(show.legend=FALSE) +\n  xlab(NULL) + ylab(NULL)\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/unnamed-chunk-7-1.pdf){fig-pos='H'}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nlibrary(ggplot2)\nset.seed(123)\n\n# y como factor\ny_trainC <- factor(y_trainC)\ny_testC  <- factor(y_testC, levels = levels(y_train))\n\n# 1) Preprocesado: centrar, escalar, PCA=2 (ajustado en train)\npreproc <- preProcess(X_trainC, method = c(\"center\", \"scale\", \"pca\"), pcaComp = 2)\nZ_train <- predict(preproc, X_trainC)  # PC1, PC2\nZ_test  <- predict(preproc, X_testC)\n\n# 2) Entrenar Naive Bayes (klaR) en el espacio PCA (dos predictores)\nctrl <- trainControl(method = \"cv\", number = 5, classProbs = TRUE,\n                     summaryFunction = twoClassSummary)\nmodelo_nb <- train(\n  x = Z_train[, c(\"PC1\", \"PC2\")], y = y_trainC,\n  method = \"nb\",                 # klaR::NaiveBayes vía caret\n  trControl = ctrl,\n  metric = \"ROC\",                # mejor que Accuracy si hay desbalance\n  tuneGrid = expand.grid(\n    usekernel = c(TRUE, FALSE),\n    fL = c(0, 1),                # laplace\n    adjust = c(1, 2)\n  )\n)\n\n# 3) Grid en el plano PCA (rango del TRAIN)\nh <- 0.02\nx_min <- min(Z_train$PC1) - 1; x_max <- max(Z_train$PC1) + 1\ny_min <- min(Z_train$PC2) - 1; y_max <- max(Z_train$PC2) + 1\ngrid <- expand.grid(\n  PC1 = seq(x_min, x_max, by = h),\n  PC2 = seq(y_min, y_max, by = h)\n)\n\n# 4) Predicción del modelo en el grid\ngrid$pred <- predict(modelo_nb, newdata = grid)\n\n# 5) Plot fondo + puntos\npal_fill <- c(\"No\" = \"#FFAAAA\", \"Yes\" = \"#b3ffff\")\npal_pts  <- c(\"No\" = \"#FF0000\", \"Yes\" = \"#00ffff\")\n\ndf_train <- data.frame(Z_train, clase = y_trainC, split = \"Train\")\ndf_test  <- data.frame(Z_test,  clase = y_testC,  split = \"Test\")\n\nggplot() +\n  geom_raster(data = grid, aes(PC1, PC2, fill = pred), alpha = 1) +\n  scale_fill_manual(values = pal_fill, name = \"Fondo\") +\n  geom_point(data = df_train, aes(PC1, PC2, color = clase), size = 1.8) +\n  geom_point(data = df_test,  aes(PC1, PC2, color = clase), size = 2.2, shape = 21) +\n  scale_color_manual(values = pal_pts, name = \"Puntos\") +\n  coord_equal(expand = FALSE, xlim = c(x_min, x_max), ylim = c(y_min, y_max)) +\n  labs(title = \"Frontera Naive Bayes (caret::nb) en plano PCA\",\n       x = \"PC1\", y = \"PC2\") +\n  theme_minimal() +\n  theme(legend.position = \"right\")\n```\n:::\n\n\n\n\n\n\n\n\n\n\n\n\n\n## Python\n\n\n\n\n\n\n\n\n\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nfrom sklearn.metrics import classification_report\nprint(classification_report(y_testPy, test_predict))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              precision    recall  f1-score   support\n\n          No       0.90      0.76      0.82       570\n         Yes       0.25      0.47      0.32        95\n\n    accuracy                           0.72       665\n   macro avg       0.57      0.62      0.57       665\nweighted avg       0.80      0.72      0.75       665\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as mpatches\n\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.decomposition import PCA\nfrom sklearn.naive_bayes import GaussianNB  # << cambio clave\n\n# ==== Parámetros ====\nh = 0.02\n\n# ==== 0) Tipos correctos ====\nX_trainPy = np.asarray(X_trainPy, dtype=float)\nX_testPy  = np.asarray(X_testPy,  dtype=float)\ny_trainPy = np.asarray(y_trainPy)\ny_testPy  = np.asarray(y_testPy)\n\n# Codificar etiquetas (para colorear y leyendas)\nle = LabelEncoder()\ny_train_num = le.fit_transform(y_trainPy)\ny_test_num  = le.transform(y_testPy)\n\n# ==== 1) Estandarizar (fit en train) + PCA (fit en train) ====\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_trainPy)\nX_test_scaled  = scaler.transform(X_testPy)\n\npca = PCA(n_components=2, random_state=0)\nZ_train = pca.fit_transform(X_train_scaled).astype(float)\nZ_test  = pca.transform(X_test_scaled).astype(float)\n\n# ==== 2) Entrenar Naive Bayes (Gaussian) en el espacio PCA ====\nclf = GaussianNB()\nclf.fit(Z_train, y_train_num)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nGaussianNB()\n```\n\n\n:::\n\n```{.python .cell-code}\n# ==== 3) Mallado y predicción para el fondo ====\nx_min, x_max = Z_train[:, 0].min() - 1, Z_train[:, 0].max() + 1\ny_min, y_max = Z_train[:, 1].min() - 1, Z_train[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\nZ_grid_pred_num = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\n# ==== 4) Paletas ====\ncmap_light = ListedColormap(['#FFAAAA', '#b3ffff'])\ncmap_bold  = ListedColormap(['#FF0000',  '#00ffff'])\n\n# ==== 5) Plot ====\nplt.figure(figsize=(7,5))\nplt.pcolormesh(xx, yy, Z_grid_pred_num, cmap=cmap_light, shading='auto')\n\nplt.scatter(Z_train[:, 0], Z_train[:, 1], c=y_train_num, cmap=cmap_bold,\n            edgecolor='k', s=25, alpha=0.85, label='Train')\nplt.scatter(Z_test[:, 0],  Z_test[:, 1],  c=y_test_num,  cmap=cmap_bold,\n            edgecolor='k', s=35, marker='o', label='Test')\n\nplt.xlim(xx.min(), xx.max()); plt.ylim(yy.min(), yy.max())\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n(-6.3391686872764605, 7.340831312723248)\n(-4.7438491611385425, 5.696150838861235)\n```\n\n\n:::\n\n```{.python .cell-code}\nplt.xlabel('PC1'); plt.ylabel('PC2')\nplt.title(\"Frontera Naive Bayes (Gaussian) en plano PCA\")\n\n# Leyenda de clases (nombres originales)\nclasses = list(le.classes_)\npalette = ['#FF0000', '#00ffff']\npatches = [mpatches.Patch(color=palette[i % len(palette)], label=str(lbl))\n           for i, lbl in enumerate(classes)]\nlegend_classes = plt.legend(handles=patches, title=\"Clases\",\n                            loc='upper right', bbox_to_anchor=(1.32, 1.0))\nplt.gca().add_artist(legend_classes)\n\nplt.legend(loc='best')  # Train/Test\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output-display}\n![](KnnNB_files/figure-pdf/grafico_clasificacion_python_nb-1.pdf){fig-pos='H'}\n:::\n:::\n\n\n\n\n\n\n\n\n\n\n\n:::\n\n\n\n## Bibliografia\n\n-   https://daviddalpiaz.github.io/r\n-   \n",
    "supporting": [
      "KnnNB_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}