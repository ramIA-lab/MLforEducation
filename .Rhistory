calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(actual    = y_test,
predicted = knn(train = X_train,
test  = X_test,
cl    = y_train,
k     = 5))
calc_class_err(actual    = y_test,
predicted = knn(train = scale(X_train),
test  = scale(X_test),
cl    = y_train,
k     = 5))
set.seed(42)
k_to_try = 1:100
err_k = rep(x = 0, times = length(k_to_try))
for (i in seq_along(k_to_try)) {
pred = knn(train = scale(X_train),
test  = scale(X_test),
cl    = y_train,
k     = k_to_try[i],
prob = T)
err_k[i] = calc_class_err(y_test, pred)
}
# plot error vs choice of k
plot(err_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification error",
main = "(Test) Error Rate vs Neighbors")
# add line for min error seen
abline(h = min(err_k), col = "darkorange", lty = 3)
# add line for minority prevalence in test set
abline(h = mean(y_default_tst == "Yes"), col = "grey", lty = 2)
min(err_k)
which(err_k == min(err_k))
max(which(err_k == min(err_k)))
set.seed(430)
default_idx = createDataPartition(Default$default, p = 0.75, list = FALSE)
default_idx = createDataPartition(datos$Response, p = 0.75, list = FALSE)
set.seed(1994)
default_idx = createDataPartition(datos$Response, p = 0.7, list = FALSE)
train_caret = datos[default_idx, ]
test_caret = datos[-default_idx, ]
modelLookup("knn")
entrenamiento <- train(Response ~ .,
data = train_caret, method = "knn",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2)))
entrenamiento
entrenamiento$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
head(sim_knn_mod$results, 5)
head(entrenamiento$results, 5)
get_best_result(entrenamiento)
plot(entrenamiento)
entrenamiento$finalModel
head(predict(entrenamiento, newdata = test_caret, type = "prob"))
head(predict(entrenamiento, newdata = test_caret, type = "prob"), n = 10)
caret::confusionMatrix(predict(entrenamiento), datos$Response)
caret::confusionMatrix(predict(entrenamiento), test_caret$Response)
caret::confusionMatrix(predict(test_caret), test_caret$Response)
predict(test_caret)
test_caret
test_caret$Response
colnames(Datos)
colnames(datos)
reticulate::repl_python()
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(['ID', "Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(['ID', "Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(['ID', "Response"], axis=1)
y = datos_py['Response']
X.shape
datos_py.columns
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(['Id', "Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1994)
cols = X_train.columns
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
path = "./superstore_data.csv"
datos <- read.csv(path)
# Realizamos el preprocessing necesario
## Eliminamos el ID
datos[, "ID"] <- NULL
datos[, "Edad"] <- 2025 - datos[, "Year_Birth"]
datos[, "Year_Birth"] <- NULL
datos[, "mes_cliente"] <- unlist(strsplit(datos[, "Dt_Customer"], "/"))[c(T, F, F)]
datos[, "Dt_Customer"] <- NULL
datos[, "Response"] <- ifelse(datos[, "Response"], "Yes", "No")
datos[, "Complain"] <- ifelse(datos[, "Complain"], "Yes", "No")
head(datos)
datos[, "Id"] <- NULL
head(datos)
#| label: cargar-dataset
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
path = "./superstore_data.csv"
datos <- read.csv(path)
# Realizamos el preprocessing necesario
## Eliminamos el ID
datos[, "ID"] <- NULL
datos[, "Edad"] <- 2025 - datos[, "Year_Birth"]
datos[, "Year_Birth"] <- NULL
datos[, "mes_cliente"] <- unlist(strsplit(datos[, "Dt_Customer"], "/"))[c(T, F, F)]
datos[, "Dt_Customer"] <- NULL
datos[, "Response"] <- ifelse(datos[, "Response"], "Yes", "No")
datos[, "Complain"] <- ifelse(datos[, "Complain"], "Yes", "No")
datos[, "Id"] <- NULL
# Creamos dummies
library(fastDummies)
datos <- dummy_cols(datos,  select_columns = c("Education", "Marital_Status",
"mes_cliente", "Complain"))
datos[, c("Education", "Marital_Status",
"mes_cliente", "Complain")] <- NULL
col_cliente <- grep("mes_cliente_", colnames(datos), value = T)
for (col in col_cliente) {
datos[, col] <- as.character(datos[, col])
}
naIncome <- which(is.na(datos$Income))
datos <- datos[-naIncome, ]
quien <- sapply(datos, class)
quien <- names(quien)[which(quien == "character")]
for (qu in quien) {
datos[, qu] <- as.factor(datos[, qu])
}
head(datos)
#| label: cargar-dataset
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
path = "./superstore_data.csv"
datos <- read.csv(path)
# Realizamos el preprocessing necesario
## Eliminamos el ID
datos[, "ID"] <- NULL
datos[, "Edad"] <- 2025 - datos[, "Year_Birth"]
datos[, "Year_Birth"] <- NULL
datos[, "mes_cliente"] <- unlist(strsplit(datos[, "Dt_Customer"], "/"))[c(T, F, F)]
datos[, "Dt_Customer"] <- NULL
datos[, "Response"] <- ifelse(datos[, "Response"], "Yes", "No")
datos[, "Complain"] <- ifelse(datos[, "Complain"], "Yes", "No")
datos[, "Id"] <- NULL
# Creamos dummies
library(fastDummies)
datos <- dummy_cols(datos,  select_columns = c("Education", "Marital_Status",
"mes_cliente", "Complain"), remove_first_dummy = TRUE)
datos[, c("Education", "Marital_Status",
"mes_cliente", "Complain")] <- NULL
col_cliente <- grep("mes_cliente_", colnames(datos), value = T)
for (col in col_cliente) {
datos[, col] <- as.character(datos[, col])
}
naIncome <- which(is.na(datos$Income))
datos <- datos[-naIncome, ]
quien <- sapply(datos, class)
quien <- names(quien)[which(quien == "character")]
for (qu in quien) {
datos[, qu] <- as.factor(datos[, qu])
}
head(datos)
reticulate::repl_python()
#| label: cargar-dataset-py
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
datos_py = r.datos
quit
#| label: cargar-librerias-knn-classifier
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
library(class)
library(caret)
head(datos)
colnames(datos)
#| label: crear-datasets_separados
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false
set.seed(1994)
ind_col <- c(16)
default_idx = sample(nrow(datos), nrow(datos)*0.7)
train <- datos[default_idx, ]
X_train <- train[, -ind_col]
y_train <- train[, 16]
test <- datos[-default_idx, ]
X_test <- test[, -ind_col]
y_test <- test[, 16]
X_train <- data.frame(lapply(X_train, as.numeric))
X_test <- data.frame(lapply(X_test, as.numeric))
#| label: entrenamiento_modelo_knn_classifier
#| echo: true
#| eval: true
#| warning: false
#| message: false
#| error: false
prediccion <- knn(train = X_train, test  = X_test,
cl = y_train, k = 3)
head(prediccion)
calc_class_err = function(actual, predicted) {
mean(actual != predicted)
}
calc_class_err(actual    = y_test,
predicted = knn(train = X_train,
test  = X_test,
cl    = y_train,
k     = 5))
calc_class_err(actual    = y_test,
predicted = knn(train = scale(X_train),
test  = scale(X_test),
cl    = y_train,
k     = 5))
set.seed(42)
k_to_try = 1:100
err_k = rep(x = 0, times = length(k_to_try))
for (i in seq_along(k_to_try)) {
pred = knn(train = scale(X_train),
test  = scale(X_test),
cl    = y_train,
k     = k_to_try[i],
prob = T)
err_k[i] = calc_class_err(y_test, pred)
}
# plot error vs choice of k
plot(err_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification error",
main = "(Test) Error Rate vs Neighbors")
# add line for min error seen
abline(h = min(err_k), col = "darkorange", lty = 3)
# add line for minority prevalence in test set
abline(h = mean(y_default_tst == "Yes"), col = "grey", lty = 2)
# plot error vs choice of k
plot(err_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification error",
main = "(Test) Error Rate vs Neighbors")
# add line for min error seen
abline(h = min(err_k), col = "darkorange", lty = 3)
# add line for minority prevalence in test set
abline(h = mean(y_test == "Yes"), col = "grey", lty = 2)
min(err_k)
which(err_k == min(err_k))
max(which(err_k == min(err_k)))
set.seed(1994)
default_idx = createDataPartition(datos$Response, p = 0.7, list = FALSE)
train_caret = datos[default_idx, ]
test_caret = datos[-default_idx, ]
modelLookup("knn")
entrenamiento <- train(Response ~ .,
data = train_caret, method = "knn",
trControl = trainControl(method = "cv", number = 5),
# preProcess = c("center", "scale"),
tuneGrid = expand.grid(k = seq(1, 31, by = 2)))
entrenamiento
entrenamiento$modelType
entrenamiento$modelType
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
head(entrenamiento$results, 5)
get_best_result(entrenamiento)
plot(entrenamiento)
entrenamiento$finalModel
head(predict(entrenamiento, newdata = test_caret, type = "prob"), n = 10)
caret::confusionMatrix(predict(entrenamiento), datos$CLS_PRO_pro13)
predict(X_test)
X_test
predict(entrenamiento, X_test)
predict(entrenamiento, newdata = test_caret)
caret::confusionMatrix(predict(entrenamiento, newdata = test_caret), test_caret$Response)
reticulate::repl_python()
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(["Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1994)
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(["Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1994)
cols = X_train.columns
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
cols = X_train.columns
from sklearn.preprocessing import StandardScaler
import pandas as pd
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
cols
cols = X_train.columns
cols
from sklearn.preprocessing import StandardScaler
import pandas as pd
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
cols = X_train.columns
cols
from sklearn.preprocessing import StandardScaler
import pandas as pd
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
#| label: python_test_train
#| echo: false
#| eval: true
#| warning: false
#| message: false
#| error: false
from sklearn.model_selection import train_test_split
X = datos_py.drop(["Response"], axis=1)
y = datos_py['Response']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 1994)
cols = X_train.columns
cols
from sklearn.preprocessing import StandardScaler
import pandas as pd
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
X_train = pd.DataFrame(X_train, columns=[cols])
X_test = pd.DataFrame(X_test, columns=[cols])
quit
# import KNeighbors ClaSSifier from sklearn
from sklearn.neighbors import KNeighborsClassifier
reticulate::repl_python()
# import KNeighbors ClaSSifier from sklearn
from sklearn.neighbors import KNeighborsClassifier
# instantiate the model
knn = KNeighborsClassifier(n_neighbors=3)
# fit the model to the training set
knn.fit(X_train, y_train)
y_pred = knn.predict(X_test)
y_pred
# probability of getting output as 2 - benign cancer
knn.predict_proba(X_test)[:,0]
knn.predict_proba(X_test)
from sklearn.metrics import accuracy_score
print('Model accuracy score: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))
y_pred_train = knn.predict(X_train)
y_pred_train = knn.predict(X_train)
print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))
quit
# print the scores on training and test set
print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))
reticulate::repl_python()
# print the scores on training and test set
print('Training set score: {:.4f}'.format(knn.score(X_train, y_train)))
print('Test set score: {:.4f}'.format(knn.score(X_test, y_test)))
# instantiate the model with k=5
knn_5 = KNeighborsClassifier(n_neighbors=5)
# fit the model to the training set
knn_5.fit(X_train, y_train)
# predict on the test-set
y_pred_5 = knn_5.predict(X_test)
print('Model accuracy score with k=5 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_5)))
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred_7))
from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
%matplotlib inline
reticulate::repl_python()
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
!pip install seaborn
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_7 = confusion_matrix(y_test, y_pred)
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_7 = confusion_matrix(y_test, y_pred)
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
y_test,
y_pred)
cm_7 = confusion_matrix(y_test, y_pred_test)
cm_7
cm_7 = confusion_matrix(y_test, y_pred_5)
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_7 = confusion_matrix(y_test, y_pred_5)
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'],
cm_matrix
q
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'], index=['Predict Positive:1', 'Predict Negative:0'])
cm_7 = confusion_matrix(y_test, y_pred_5)
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
from sklearn.metrics import confusion_matrix
# visualize confusion matrix with seaborn heatmap
plt.figure(figsize=(6,4))
cm_7 = confusion_matrix(y_test, y_pred_5)
cm_matrix = pd.DataFrame(data=cm_7, columns=['Actual Positive:1', 'Actual Negative:0'], index=['Predict Positive:1', 'Predict Negative:0'])
sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')
import matplotlib.pyplot as plt # for data visualization purposes
import seaborn as sns # for data visualization
from sklearn.metrics import confusion_matrix
%matplotlib inline
