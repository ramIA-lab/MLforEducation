{
  "hash": "2cfc66170453e43cf011b75e4a1d1ee7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Advance Preprocessing\"\nsubtitle: \"Herramientas para el preprocesamiento de los datos\"\nauthor: Dante Conti, Sergi Ramirez, (c) IDEAI\ndate: \"2025-09-30\"\ndate-modified: \"2025-09-30\"\nformat:\n  html:\n    toc: true\n    toc-depth: 3\n    number-sections: true\n    code-fold: show\n    code-tools: true\n    theme: cerulean\n  pdf:\n    toc: true\n    number-sections: true\n    theme: cerulean\nexecute:\n  echo: true\n  eval: false\n  warning: false\n  message: false\neditor: visual\n---\n\n\n\n\n# Descripci√≥n del problema\n\nPara hacer el apartado de preprocessing vamos a utilizar la base de datos [`valentine_dataset.csv`](https://www.kaggle.com/datasets/anyasorc/valentine-dataset).\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n# Limpieza de los datos\n\n## Limpieza de los datos a nivel de variable\n\nLos **errores estructurales** a nivel de variable se centran fundamentalmente en el tipo de dato de las variables. En primer lugar, se visualizan los datos con la funci√≥n `diagnose()` de `dlookr`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dlookr)\ndlookr::diagnose(dades)\n```\n:::\n\n\n\n\n## Eliminaci√≥n de observaciones duplicadas o irrelevantes\n\nLas **observaciones duplicadas** aparecen frecuentemente durante la recogida de datos e integraci√≥n de las bases de datos, por lo que dichas duplicidades deben ser eliminadas en esta fase de limpieza.\n\nA continuaci√≥n, se usa la funci√≥n `overview()` del paquete `dlookr`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(overview(dades), n = 9)\n```\n:::\n\n\n\n\n# Outliers\n\nUn outlier es un valor extremo que se aleja significativamente del resto de observaciones. Detectarlos es importante porque pueden distorsionar las estad√≠sticas, influir en los modelos y generar conclusiones err√≥neas.\n\nExisten diferentes enfoques: desde an√°lisis univariantes (una variable a la vez) hasta multivariantes (considerando la relaci√≥n entre varias variables).\n\nPara detectar los valores at√≠picos podemos hacer uso de la funci√≥n `diagnose_numeric` y `diagnose_category`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiagnose_numeric(dades)\ndiagnose_category(dades)\n```\n:::\n\n\n\n\n## Univariate\n\nEn este caso analizamos variable por variable.\n\n### Max and Min\n\nLa primera estrategia consiste en observar los valores m√≠nimos y m√°ximos de cada variable num√©rica. Esto nos da una primera idea de los rangos de los datos y de si existen valores extra√±os.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmapply(function(x, name) {\n  cat(\"var. \", name, \": \\n\\t min: \", min(x), \"\\n\\t max: \", max(x), \"\\n\")\n  invisible(NULL)  # Evita la salida de valores NULL\n}, dades[, varNum], colnames(dades[, varNum]))\n```\n:::\n\n\n\n\n### IQR\n\nOtra manera de detectar outliers es usando el **rango intercuart√≠lico (IQR)**. Se definen como outliers los puntos que quedan fuera del intervalo:\n\n$$\n[Q1 - 1.5xIQR, Q3 + 1.5xIQR]\n$$\n\ndonde $Q1$ es el primer cuartil, $Q3$ el tercer cuartil e $IQR = Q3 - Q1$.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EnvStats)\n\nIQROutlier <- function(variable, rmnas = TRUE) {\n  IQ <- iqr(variable, na.rm = rmnas)\n  intInf <- quantile(variable, probs = c(0.25, 0.75))[[1]] - 1.5*IQ\n  intSup <- quantile(variable, probs = c(0.25, 0.75))[[2]] + 1.5*IQ\n  posicions <- which(variable >= intSup | variable <= intInf)\n  if (length(posicions) > 0) {\n    cat(\"Existeixen outliers en les posicions:\", paste0(posicions, collapse = \", \"))\n  } else {\n    cat(\"No existeixen outliers\")\n  }\n  return(posicions)\n}\n```\n:::\n\n::: {.cell}\n\n:::\n\n\n\n\n> üëâ Aqu√≠ veremos cu√°ntos valores son considerados extremos seg√∫n este criterio en cada variable num√©rica.\n\n### Boxplot\n\nVisualitzaci√≥ basada en IQR per detectar outliers.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggplot2)\n\nvariable <- \"Age\"\n\nboxplot(dades[, variable])\nboxplot.stats(dades[, variable])$out\n\n# Crear un boxplot\nggplot(dades, aes(y = get(variable))) +\n  geom_boxplot(fill = \"skyblue\", color = \"black\") +\n  labs(title = paste0(\"Boxplot de \", variable)) +\n  theme_minimal()\n```\n:::\n\n\n\n\n### Z-Score\n\nUn outlier es un valor amb \\|z\\| \\> 3 deviaci√≥ est√°ndar\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariable <- \"Age\"\nvalorEscalado <- scale(dades[, variable])\nhist(valorEscalado)\n\nggplot(data.frame(valor = valorEscalado), aes(x = valor)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  # Histograma\n  geom_vline(xintercept = c(3, -3), linetype = \"dashed\", color = \"red\", size = 1) + # L√≠neas horizontales\n  theme_minimal()\n```\n:::\n\n\n\n\n### Hampel Identifier\n\nUtilitza la mediana i la desviaci√≥ absoluta mediana (MAD) en lloc de la mitjana\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariable <- \"Age\"\n\nlower_bound <- median(dades[, variable]) - 3 * mad(dades[, variable], constant = 1)\nupper_bound <- median(dades[, variable]) + 3 * mad(dades[, variable], constant = 1)\noutlier_ind <- which((dades[, variable] < lower_bound) | (dades[, variable] > upper_bound))\noutlier_ind\n```\n:::\n\n\n\n\n### Tests Estad√≠stics\n\n#### Grubbs' Test\n\nDetecta valors extrems en una distribuci√≥ normal\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(outliers)\n\nvariable <- \"Age\"\ntest <- outliers::grubbs.test(dades[, variable], opposite = TRUE)\n# amb el par√†metre opposite controles quina de les dues cues est√°n buscant\ntest\n```\n:::\n\n\n\n\n#### Dixon's Test\n\nNom√©s utilitzar per a bbdd petites (entre 3 - 30) observacions\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvariable <- \"Age\"\ntest <- outliers::dixon.test(dades[, variable], opposite = FALSE)\ntest\n```\n:::\n\n\n\n\n#### Rosner's Test\n\nLa prueba de Rosner para valores at√≠picos tiene las ventajas de que: 1. se utiliza para detectar varios valores at√≠picos a la vez (a diferencia de la prueba de Grubbs y Dixon, que debe realizarse de forma iterativa para detectar m√∫ltiples valores at√≠picos), 2. Est√° dise√±ado para evitar el problema del enmascaramiento, donde un valor at√≠pico cercano en valor a otro valor at√≠pico puede pasar desapercibido.\n\nA diferencia de la prueba de Dixon, tenga en cuenta que la prueba de Rosner es m√°s apropiada cuando el tama√±o de la muestra es grande (n ‚â• 20).\n\nEsta funci√≥n requiere al menos dos argumentos: - los datos - la cantidad de valores at√≠picos sospechosos k (k = 3 como cantidad predeterminada)\n\nAsumeix normalitat de les dades\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(EnvStats)\n\nvariable <- \"Age\"\ntest <- EnvStats::rosnerTest(dades[, variable], k = 1)\ntest\ntest$all.stats\n```\n:::\n\n\n\n\n## Multivariate\n\nHasta ahora hemos visto cada variable por separado. Sin embargo, a veces los outliers aparecen **en combinaci√≥n** de variables.\n\nPara detectarlos se pueden usar m√©todos como la distancia de Mahalanobis o algoritmos m√°s avanzados de detecci√≥n de anomal√≠as.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(scatterplot3d)\nlibrary(readr)\ndades <- readr::read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv\")\ndades <- data.frame(dades[, c(\"DC\", \"temp\", \"RH\")])\nscatterplot3d(dades[,\"DC\"], dades[, \"temp\"],dades[, \"RH\"])\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rgl)\n\n# Plot\nrgl::plot3d(x = dades[, \"DC\"], y = dades[, \"temp\"], z = dades[, \"RH\"], \ncol = \"black\", type = 'p', radius = .1)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(plotly)\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, size = 1) %>% \n       add_markers())\n```\n:::\n\n\n\n\n### Cas general\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mvoutlier)\ndades2 <- dades; Y <- as.matrix(dades2)\ndistances <- dd.plot(Y,quan=1/2, alpha=0.025)\nhead(distances$md.cla)\nhead(distances$md.rob)\nres <- aq.plot(Y,delta=qchisq(0.975,df=ncol(Y)),quan=1/2,alpha=0.05)\nstr(res)\nhead(res$outliers)\ntable(res$outliers)\n#windows()\npar(mfrow=c(1, 1))\nlibrary(MVN)\n# mvnoutliers <- mvn(dades, multivariateOutlierMethod = \"adj\", showOutliers = TRUE, \n#                   showNewData = TRUE)\nmvnoutliers <- mvn(data = dades, mvn_test = \"royston\", \n                   univariate_test = \"AD\", \n              multivariate_outlier_method = \"adj\",\n              show_new_data = TRUE)\n```\n:::\n\n\n\n\nVisualitzem tots els outliers detectats com a true\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(summary(mvnoutliers, select = \"outliers\"))\n```\n:::\n\n\n\n\nVisualitzem les variables originals quines han donat els que no son outliers\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(summary(mvnoutliers, select = \"new_data\"))\n```\n:::\n\n\n\n\nVisualitzem els resultats del test de normalitat univariant\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(summary(mvnoutliers, select = \"mvn\"))\n```\n:::\n\n\n\n\ni multivariant\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(summary(mvnoutliers, select = \"univariate\"))\n```\n:::\n\n\n\n\n### PCA\n\nM√©todes basats en correlacions ens permeten detectar outliers\n\n### Distancia de Mahalanobis\n\nMedeix la distancia de un punt respecte a la mitjana considerant la covarian√ßa\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndistancia_mahalanobis <- mahalanobis(dades, colMeans(dades), cov(dades))\n```\n:::\n\n\n\n\nGrafiquem el plot de la densitat de les distancies\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(density(distancia_mahalanobis))\n```\n:::\n\n\n\n\nEs mostren els valors de la bbdd que queden per sobre de el 99% de la distribuci√≥ chi-cuadrat\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncutoff <- qchisq(p = 0.99, df = ncol(dades))\ndades[distancia_mahalanobis>cutoff, ]\n```\n:::\n\n\n\n\nOrdenamos de forma decreciente, seg√∫n el score de Mahalanobis\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndades <- dades[order(distancia_mahalanobis, decreasing = TRUE),]\n```\n:::\n\n\n\n\nVisualitzem l'histograma de les distancies per veure on tallem els outliers\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow=c(1,1))\nhist(distancia_mahalanobis)\n```\n:::\n\n\n\n\nDescartamos los outliers seg√∫n un umbral\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\numbral <- 8\ndades[, \"outlier\"] <- (distancia_mahalanobis > umbral)\n\ndades[, \"color\"] <- ifelse(dades[, \"outlier\"], \"red\", \"black\")\nscatterplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], \n              color = dades[, \"color\"])\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, \n                       color = ~color, colors = c('#0C4B8E', '#BF382A')) %>% \n                        add_markers())\n\n(quienes <- which(dades[, \"outlier\"] == TRUE))\n```\n:::\n\n\n\n\n#### Mahalanobis Robusto\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(chemometrics)\n\ndis <- chemometrics::Moutlier(dades[, c(\"DC\", \"temp\", \"RH\")], quantile = 0.99, plot = TRUE)\n\npar(mfrow = c(1, 1))\nplot(dis$md, dis$rd, type = \"n\")\ntext(dis$md, dis$rd, labels = rownames(dades))\na <- which(dis$rd > 7)\nprint(a)\n```\n:::\n\n\n\n\n### Regresi√≥ Lineal i residus\n\nUn punt amb un residu gran pot considerar-se un outlier\n\n### Distancia de Cook\n\nIdentifica punts amb gran influ√®ncia en la regresi√≥. Un valor de Cook D_i \\> 1 √©s un outliers.\n\n### K-Nearest Neighbors (KNN) Outlier Score\n\nBasats en la densitat local de les dades\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(adamethods)\n\ndo_knno(dades[, c(\"DC\", \"temp\", \"RH\")], k=1, top_n = 30)\n```\n:::\n\n\n\n\n### Local Outlier Factor (LOF)\n\nCompara la densidat de un punt amb la densidat dels seus ve√Øns. Un valor LOF alt\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(DMwR2)\nlibrary(dplyr)\n\noutlier.scores <- lofactor(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\npar(mfrow=c(1,1))\nplot(density(outlier.scores))\noutlier.scores\noutliers <- order(outlier.scores, decreasing=T)\noutliers <- order(outlier.scores, decreasing=T)[1:5]\n```\n:::\n\n\n\n\nAprofitarem el ACP per poder visualizar els outliers\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn <- nrow(dades[, c(\"DC\", \"temp\", \"RH\")]); labels <- 1:n; labels[-outliers] <- \".\"\nbiplot(prcomp(dades[, c(\"DC\", \"temp\", \"RH\")]), cex = .8, xlabs = labels)\n```\n:::\n\n\n\n\nGrafiquem les correlacions per veure els gr√°fics\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npch <- rep(\".\", n)\npch[outliers] <- \"+\"\ncol <- rep(\"black\", n)\ncol[outliers] <- \"red\"\npairs(dades[, c(\"DC\", \"temp\", \"RH\")], pch = pch, col = col)\n```\n:::\n\n\n\n\nHo visualitzem en 3D\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], type = \"s\", col = col, size = 1)\n```\n:::\n\n\n\n\n#### Nueva versi√≥n de LOF\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Rlof)\noutliers.scores <- Rlof::lof(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\nplot(density(outliers.scores))\n#outlier.scores <- lof(dades[, c(\"DC\", \"temp\", \"RH\")], k=c(5:10))\n```\n:::\n\n\n\n\n### Isolation Forest\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Cargamos las librerias necesarias\nlibrary(R.matlab)   # Lectura de archivos .mat\nlibrary(solitude)   # Modelo isolation forest\nlibrary(tidyverse)  # Preparaci√≥n de datos y gr√°ficos\nlibrary(MLmetrics)\n\n# Carreguem les dades\ncardio_mat  <- readMat(\"https://www.dropbox.com/s/galg3ihvxklf0qi/cardio.mat?dl=1\")\ndf_cardio   <- as.data.frame(cardio_mat$X)\ndf_cardio$y <- as.character(cardio_mat$y)\ndatos <- df_cardio\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nisoforest <- isolationForest$new(\n  sample_size = as.integer(nrow(datos)/2),\n  num_trees   = 500, \n  replace     = TRUE,\n  seed        = 123\n)\nisoforest$fit(dataset = datos %>% select(-y))\n```\n:::\n\n\n\n\nAra anem a realitzar les prediccions.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredicciones <- isoforest$predict(\n  data = datos %>% select(-y)\n)\nhead(predicciones)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data = predicciones, aes(x = average_depth)) +\n  geom_histogram(color = \"gray40\") +\n  geom_vline(\n    xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),\n    color      = \"red\",\n    linetype   = \"dashed\") +\n  labs(\n    title = \"Distribuci√≥n de las distancias medias del Isolation Forest\",\n    subtitle = \"Cuantiles marcados en rojo\"  ) +\n  theme_bw() +\n  theme(plot.title = element_text(size = 11))\n\ncuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))\ncuantiles\n```\n:::\n\n\n\n\n### TIPS: Detecci√≥n de anomal√≠as\n\nUna vez que la distancia de separaci√≥n ha sido calculado, se puede emplear como criterio para identificar anomal√≠as. Asumiendo que las observaciones con valores at√≠picos en una o m√°s de sus variables se separan del resto con mayor facilidad, aquellas observaciones con menor distancia promedio deber√≠an ser las m√°s at√≠picas.\n\nEn la pr√°ctica, si se est√° empleando esta estrategia de detecci√≥n es porque no se dispone de datos etiquetados, es decir, no se conoce qu√© observaciones son realmente anomal√≠as. Sin embargo, como en este ejemplo se dispone de la clasificaci√≥n real, se puede verificar si realmente los datos an√≥malos tienen menores distancias.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndatos <- datos %>%\n  bind_cols(predicciones)\n\nggplot(data = datos,\n       aes(x = y, y = average_depth)) +\n  geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) + \n  geom_violin(alpha = 0) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +\n  stat_summary(fun = \"mean\", colour = \"orangered2\", size = 3, geom = \"point\") +\n  labs(title = \"Distancia promedio en el modelo Isolation Forest\",\n       x = \"clasificaci√≥n (0 = normal, 1 = anomal√≠a)\",\n       y = \"Distancia promedio\") +\n  theme_bw() + \n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 11)\n  )\n```\n:::\n\n\n\n\nLa distancia promedio en el grupo de las anomal√≠as (1) es claramente inferior. Sin embargo, al existir solapamiento, si se clasifican las n observaciones con menor distancia como anomal√≠as, se incurrir√≠a en errores de falsos positivos.\n\nAcorde a la documentaci√≥n, el set de datos Cardiotocogrpahy contiene 176 anomal√≠as. V√©ase la matriz de confusi√≥n resultante si se clasifican como anomal√≠as las 176 observaciones con menor distancia predicha.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresultados <- datos %>%\n  select(y, average_depth) %>%\n  arrange(average_depth) %>%\n  mutate(clasificacion = if_else(average_depth <= 8.5, \"1\", \"0\"))\n\nmat_confusion <- MLmetrics::ConfusionMatrix(\n  y_pred = resultados$clasificacion,\n  y_true = resultados$y)\n\nmat_confusion\n```\n:::\n\n\n\n\n# Missing values (valores faltantes)\n\nLos **valores faltantes** aparecen cuando una observaci√≥n no tiene registrado el valor en cierta variable.\n\nManejar correctamente los NA es esencial: eliminarlos puede reducir mucho el dataset, mientras que imputarlos incorrectamente puede introducir sesgos.\n\nExisten varias t√©cnicas:\n\n-   **Eliminaci√≥n de filas/columnas** con demasiados NA.\n-   **Imputaci√≥n simple**, por ejemplo reemplazando con la media o moda.\n-   **Imputaci√≥n avanzada**, como KNN o modelos predictivos.\n\n> üëâ La elecci√≥n depende de la importancia de la variable, la cantidad de NA y el contexto del problema.\n\n## Generate data with NA's\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolSums(is.na(iris))\niris.mis <- missForest::prodNA(iris, noNA = 0.1)\ncolSums((is.na(iris.mis)))\n```\n:::\n\n\n\n\nOtra forma de crear missings en el dataframe\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.mis <- mi::create.missing(iris, pct.mis = 10)\n```\n:::\n\n\n\n\n## Little Test\n\nEs un test que nos permite detectar con que tipo de NA's estamos enfrente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnaniar::mcar_test(iris.mis)\n```\n:::\n\n\n\n\nSi el valor p de la prova √©s inferior a 0 aix√≤ vol dir que les dades amb NAs s'han generat aleat√≤riament.\n\n## Patrons descriptius de NA en una base de dades\n\n### Explorar les relacions de NA's\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(visdat)\nlibrary(ggplot2)\nlibrary(naniar)\n\nvis_dat(airquality);\nvis_dat(iris.mis)\nvis_miss(airquality);\nvis_miss(iris.mis)\n\nggplot(airquality, aes(x = Solar.R,y = Ozone)) + \n  geom_point()\nggplot(airquality, aes(x = Solar.R,  y = Ozone)) + \n  geom_miss_point()\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month)\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month) + \n  theme_dark()\n```\n:::\n\n\n\n\n### Visualitzaci√≥ dels NA's per variables\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngg_miss_var(airquality) + labs(y = \"Look at all the missing ones\")\n```\n:::\n\n\n\n\n### Detecci√≥ de NA's en la base de dades\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naq_shadow <- bind_shadow(airquality)\n```\n:::\n\n\n\n\nImprimeix el gr√†fic amb difer√®ncia a les NA i no a les NA,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nairquality %>%\n  bind_shadow() %>%\n  group_by(Ozone_NA) %>%\n  summarise_at(.vars = \"Solar.R\",\n               .funs = c(\"mean\", \"sd\", \"var\", \"min\", \"max\"),\n               na.rm = TRUE)\n\nggplot(aq_shadow,\n       aes(x = Temp,\n           colour = Ozone_NA)) + \n  geom_density()\n```\n:::\n\n\n\n\n### Extreu estad√≠stiques amb NAs de la base de dades\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprop_miss_case(airquality)\npct_miss_case(airquality)\nmiss_case_summary(airquality)\nmiss_case_table(airquality)\nprop_miss_var(airquality)\npct_miss_var(airquality)\nmiss_var_summary(airquality)\nmiss_var_table(airquality)\n```\n:::\n\n\n\n\n## Imputaci√≥ b√†sica\n\n### Imputar con la media\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.mis[, \"imputed_Sepal.Length\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, mean))\n```\n:::\n\n\n\n\n### Imputar con la mediana\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npre_median <- preProcess(dades, method = \"medianImpute\")\nimputed_median <- predict(pre_median, dades)\ndiagnose(imputed_median)\n```\n:::\n\n\n\n\n### Imputar con un valor aleatorio\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.mis[, \"imputed_Sepal.Length2\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, 'random'))\n```\n:::\n\n\n\n\nDe manera similar podeu utilitzar la mediana min, max, per imputar el valor que manca.\n\n### Representa la distribuci√≥ a variables reals i d'imputaci√≥ a trav√©s del gr√°fico de densidad con ggplot2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_long <- iris.mis %>%\n  select(Sepal.Length, imputed_Sepal.Length, imputed_Sepal.Length2) %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\", \"green\"))\n\niris.mis[, c(\"imputed_Sepal.Length\", \"imputed_Sepal.Length2\")] <- NULL\n```\n:::\n\n\n\n\nOtra forma es usando el paquete `argImpute`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(impute_arg <- Hmisc::aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +\n                           Species, data = iris.mis, n.impute = 5))\n```\n:::\n\n\n\n\nRevisamos la variable `Sepal.Length` con la imputaci√≥n realizada en cada una de las rondas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimpute_arg$imputed$Sepal.Length\n```\n:::\n\n\n\n\nCalculamos la media para las 5 simulaciones.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputed_Sepal.Length <- rowMeans(impute_arg$imputed$Sepal.Length)\nnew_var_imputed <- iris$Sepal.Length\nnew_var_imputed[as.numeric(names(imputed_Sepal.Length))] <- imputed_Sepal.Length\n```\n:::\n\n\n\n\nRevisamos la diferencia entre las dos imputaciones.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = new_var_imputed)\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n:::\n\n\n\n\n## Multiple Iterative Regression Imputation (MI method)\n\nImputamos los valores NA's con mi\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmi_data <- mi::mi(iris.mis, seed = 335)\n```\n:::\n\n\n\n\nRevisamos la informaci√≥n de las imputaciones.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mi_data)\nplot(mi_data)\npar(ask = FALSE)\n```\n:::\n\n\n\n\nRevisamos las interaciones de la base de datos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmi_data@data\n```\n:::\n\n\n\n\n## Media con una variable target\n\nDefinimos la variable target\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntarget = \"Species\"\n```\n:::\n\n\n\n\nDefinimos la base de datos con NA's\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata <- subset(iris, select = -c(get(target)))\ndata <- missForest::prodNA(data, noNA = 0.1)\ndata$Species <- iris[, target]\n```\n:::\n\n\n\n\nDefinir variables a imputar (excluyendo la variable target)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvarImp <- colnames(data)[which(!colnames(data) %in% target)]\n```\n:::\n\n\n\n\nCalcular las medias por grupo\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmeans <- aggregate(data[, varImp], list(data[, target]), mean, na.rm = TRUE)\n```\n:::\n\n\n\n\nImputar valores faltantes\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfor (c in varImp) {\n  for (g in means[, \"Group.1\"]) {\n    cond <- data[, target] == g  # Condici√≥n booleana en vez de which()\n    na_index <- is.na(data[, c]) & cond  # Seleccionar NA dentro del grupo\n    \n    # Asignar valores imputados\n    data[na_index, c] <- means[means[, \"Group.1\"] == g, c]\n  }\n}\nsummary(data)\n```\n:::\n\n\n\n\nVisualizamos la diferencia entre las imputaciones\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris[, \"Tipo\"] <- \"original\"\ndata[, \"Tipo\"] <- \"imputed\"\n```\n:::\n\n\n\n\nUnimos en un mismo dataframe\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata_long <- bind_rows(iris, data)\ncols_numeric <- names(data_long)[sapply(data_long, is.numeric) & names(data_long) != \"Tipo\"]\n\n# Convert a large data\ndata_long <- data_long %>%\n  pivot_longer(cols = all_of(cols_numeric), names_to = \"Variable\", values_to = \"Valor\")\n```\n:::\n\n\n\n\nCreamos el gr√°fico con ggplot\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(data_long, aes(x = Valor, fill = Tipo)) +\n  geom_density(alpha = 0.3) +  # Transparencia para comparaci√≥n\n  facet_wrap(~Variable, scales = \"free\") +  # Un gr√°fico por variable\n  labs(title = \"Comparaci√≥n de Distribuciones: Original vs Imputado\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n:::\n\n\n\n\nRemovemos la tipologia de variable\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.mis[, \"Tipo\"] <- NULL\n```\n:::\n\n\n\n\n## Multiple Imputation by Chained Equations (MICE)\n\nEliminamos las variables categoricas\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquiCat <- which(lapply(iris.mis, class) %in% c(\"character\", \"factor\"))\ncategories <- names(iris.mis)[quiCat]\niris.mis2 <- subset(iris.mis, select = -c(get(categories)))\nsummary(iris.mis2)\n```\n:::\n\n\n\n\nVisualizamos los patrones de NA's de la base de datos\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npar(mfrow = c(1, 1))\nmice::md.pattern(iris.mis2, rotate.names = TRUE)\n```\n:::\n\n\n\n\nTambi√©n lo podemos visualizar con el paquete VIM\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmice_plot <- VIM::aggr(iris.mis2, col=c('navyblue','yellow'),\n                  numbers=TRUE, sortVars=TRUE,\n                  labels=names(iris.mis), cex.axis=.7,\n                  gap=3, ylab=c(\"Missing data\",\"Pattern\"))\n```\n:::\n\n\n\n\nA continuaci√≥n realizamos la imputaci√≥n de los valores faltanes de manera multivariada\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nimputed_Data <- mice::mice(iris.mis2, m=5, maxit = 50, method = 'pmm', seed = 500)\nsummary(imputed_Data)\n```\n:::\n\n\n\n\nInspeccionamos la calidad de las imputaciones\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmice::stripplot(imputed_Data, Sepal.Width, pch = 19, xlab = \"Imputation number\")\nimputed_Data$imp$Sepal.Width\n```\n:::\n\n\n\n\nAl final seleccionamos una de las iteracciones y la dejamos como imputaci√≥n de los valores faltantes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncompleteData <- mice::complete(imputed_Data, action = \"long\")\n```\n:::\n\n\n\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n## KNN\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntipos <- sapply(iris.mis, class)\nvarNum <- names(tipos)[which(tipos %in% c(\"numeric\", \"integer\"))]\ndata_knn_imputation <- multiUS::KNNimp(iris.mis[, varNum], k = 1)\nsummary(data_knn_imputation)\n```\n:::\n\n\n\n\nVisualizamos la diferencia entre las dos imputaciones.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = data_knn_imputation[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n:::\n\n\n\n\nOtra forma de hacerlo en R seria la siguiente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#| label: graficamos_mi_iteration\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(\"caret\")\npre_knn <- preProcess(dades, method = \"knnImpute\", k = 2)\nimputed_knn <- predict(pre_knn, dades)\ndiagnose(imputed_knn)\n```\n:::\n\n\n\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare the imputation and not imputation with all numeric vars in dataframe\n\n## missForest\n\nImputamos los missings usando todos los parametros con los valores por defectos.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(missForest)\niris.imp <- missForest(iris.mis, variablewise = T, verbose = T) \n```\n:::\n\n\n\n\nVisualizamos los valores imputados\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.imp$ximp\n```\n:::\n\n\n\n\nVisualizamos el error cometido en las imputaciones.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\niris.imp$OOBerror\n```\n:::\n\n\n\n\nNRMSE √©s un error normalitzat mitj√† al quadrat. S'utilitza per representar l'error derivat d'imputar valors continus. El PFC (proporci√≥ de falsament classificada) s'utilitza per representar l'error derivat d'imputar valors categ√≤rics.\n\nComparamos el accuracy actual,\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(iris.err <- mixError(iris.imp$ximp, iris.mis, iris))\n```\n:::\n\n\n\n\nMiramos la diferencia entre las dos imputaciones\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed =  iris.imp$ximp[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n:::\n\n\n\n\n### Exercises:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n### Extra\n\nQuan es tracta de valors que manquen, √©s possible que vulgueu reempla√ßar valors per valors que manquen (NA). Aix√≤ √©s √∫til en els casos en qu√® es coneix l'origen de les dades i es pot estar segur de quins valors han de faltar. Per exemple, podr√≠eu saber que tots els valors de ¬´N/A¬ª, ¬´N A¬ª i ¬´No disponible¬ª, o -99 o -1 se suposa que falten.\n\nnaniar proporciona funcions per treballar espec√≠ficament en aquest tipus de problemes utilitzant la funci√≥ replace.with.na. Aquesta funci√≥ √©s el compliment a tidyr::replace els NA's, que reempla√ßa un valor NA per un valor especificat, mentre que naniar::replace,with_na reempla√ßa un valor per un NA:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidyr::replace_na: Missing values turns into a value (NA ‚Äì> -99)\nnaniar::replace_with_na: Value becomes a missing value (-99 ‚Äì> NA)\n```\n:::\n\n\n\n\n## MIMMI\n\nPuedes descargar el fichero de MIMMI pinchando [aqu√≠](03_02_MIMMI.R)\n\n# Features Selection\n\nLa selecci√≥n de variables involucra un conjunto de t√©cnicas cuyo objetivo es seleccionar el subconjunto de variables predictoras m√°s relevante para las fases de modelizaci√≥n. Esto es importante porque:\n\n-   Variables predictoras redundantes pueden distraer o enga√±ar a los algoritmos de aprendizaje, lo que posiblemente se traduzca en un menor rendimiento, no solo predictivo (exactitud y precisi√≥n), sino tambi√©n en t√©rminos de tiempo de computaci√≥n.\n\n-   Igualmente, la inclusi√≥n de variables irrelevantes aumenta el coste computacional y dificulta la interpretabilidad.\n\nUna adecuada selecci√≥n de variables tiene ventajas importantes:\n\n1.  Elimina las variables con informaci√≥n redundante\n2.  Reduce el grado de complejidad de los modelos\n3.  Evita o reduce el sobreajuste\n4.  Incrementa de la precisi√≥n de las predicciones\n5.  Reduce la carga computacional\n\nDebe comprobarse la magnitud de la varianza de las variables candidatas a ser seleccionadas y de sus correlaciones dos a dos, as√≠ como si existen combinaciones lineales entre ellas (multicolinealidad).\n\nLos m√©todos de selecci√≥n de variables se pueden resumir en 2 grandes grupos:\n\n1.  Los que utilizan variables objetivo (supervisados)\n2.  Los que no (no supervisados)\n\nNos centraremos en los que utilizan variable objetivo (supervisados). Estos se pueden dividir en los siguientes grupos:\n\n1.  **M√©todos tipo filtro** *(Filter)*: puntua de mayor a menor cada variable predictora en base a su capacidad predictiva y selecciona un subconjunto de variables dependiendo de dicha puntuaci√≥n.\n2.  **M√©todos tipo envoltura** *(wrapper)*: Elige un subconjunto de vaiables que dan como resultado el modelo con mayores prestaciones en cuanto a calidad de resultados y eficiencia.\n3.  **M√©todos tipo intr√≠nsecos** *(embedded)*: Seleccionan las variables autom√°ticamente como parte del ajuste del modelo durante el entrenamiento.\n\n## Preselecci√≥n de variables\n\n### Varianza nula\n\nUno de los aspectos fundamentales en la selecci√≥n de variables es comprobar si su varianza es cero o cercana a cero porque, si es as√≠, sus valores son iguales o similares, respectivamente, y, por tanto, esas variables estar√°n perfectamente o cuasiperfectamente correlacionadas con el t√©rmino independiente del modelo, con lo cual, en el mejor de los casos, solo a√±adir√°n ruido al modelo. Este tipo de efecto acaba afectando en la divisi√≥n de los conjuntos de entrenamiento y validaci√≥n de los datos.\n\nPara visualizarlo en R, podemos hacer lo siguiente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret)\nlibrary(idealista18)\nlibrary(tidyverse)\n\nMadrid_Sale <- as.data.frame(Madrid_Sale)\nnumeric_cols <- sapply(Madrid_Sale, is.numeric)\nMadrid_Sale_num <- Madrid_Sale[, numeric_cols]\n\nvarianza <- nearZeroVar(Madrid_Sale_num, saveMetrics = T)\nhead(varianza, 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       freqRatio percentUnique zeroVar   nzv\nPERIOD  2.019617   0.004218742   FALSE FALSE\nPRICE   1.076923   2.911986500   FALSE FALSE\n```\n\n\n:::\n:::\n\n\n\n\n### Correlaci√≥n entre variables\n\nUna de las cuestiones a tener en cuenta en el proceso de selecci√≥n de variables es la magnitud de las **correlaciones entre variables** ya que esto puede afectar a la fiabilidad de las predicciones al tener variables muy correlacionadas. En el caso extreno el modelo tendr√° problemas de colinealidad o multicolinealidad.\n\nPara detectar las variables con muy elevada correlaci√≥n entre ellas, se le pasa la funci√≥n `findCorrelation()` de `caret`, con valor 0,9, a la matriz de correlaciones lineales entre las variables susceptibles de ser seleccionadas.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmadrid_cor <- cor(Madrid_Sale_num[, 1:20])\n(alta_corr <- findCorrelation(madrid_cor, cutoff = .9))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 11\n```\n\n\n:::\n:::\n\n\n\n\nPara visualizar, podemos ver el `corrplot`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"corrplot\")\n\nmatriz_corr <- cor(Madrid_Sale_num[, 1:8])\ncorrplot(matriz_corr, method = \"circle\")\n```\n\n::: {.cell-output-display}\n![](AdvancedPreprocessing_files/figure-html/grafico_correlaciones-1.png){width=672}\n:::\n:::\n\n\n\n\n### Combinaciones lineales\n\nEn la mayor√≠a de los casos las variables que se utilizan como predictoras no son ortogonales, sino que tienen cierto grado de dependencia lineal entre ellas. Si dicho grado es moderado, las consecuencias de la no ortogonalidad en la predicci√≥n no son graves, pero en los casos de dependencia lineal cuasiperfecta las inferencias resultantes del modelo estimado distan mucho de la realidad. Dichas consecuencias son a√∫n m√°s graves en el caso de que las combinaciones lineales sean perfectas. Por ello, la existencia de colinealidad o combinaciones lineales entre las variables seleccionables tambi√©n es una circunstancia a evitar.\n\nLas principales fuentes de multicolinealidad son:\n\n-   El m√©todo utilizado en la recogida de datos (subespacios)\n-   Restricciones en el modelo o en la poblaci√≥n (existencia de variables correlacionadas)\n-   Especificaci√≥n del modelo (polinomios)\n-   M√°s variables que observaciones\n\nLos efectos de la multicolinealidad en los modelos son los siguientes:\n\n-   Los estimadores tendr√°n grandes varianzas y covarianzas\n-   Las estimaciones de los coeficientes del modelo ser√°n demasiado grandes\n-   Los signos de los coeficientes estimados suelen ser distintos a los esperados\n-   Peque√±as variaciones en los datos, o en las especificaciones del modelo, provocar√°n grandes cambios en los coeficientes\n\nUtilizando la funci√≥n `findLinearCombos()` del paquete `caret` permite encontrar combinaciones lineales de las variables predictoras.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nMadrid_Sale_num_na <- tidyr::drop_na(Madrid_Sale_num) # Es necesario eliminar los NA.\n(combos <- findLinearCombos(Madrid_Sale_num_na))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$linearCombos\n$linearCombos[[1]]\n[1] 12 11\n\n$linearCombos[[2]]\n[1] 33\n\n\n$remove\n[1] 12 33\n```\n\n\n:::\n:::\n\n\n\n\nEn caso de encontrarse con problemas de multicolinealidad se deberia de realizar:\n\n-   Eliminaci√≥n de variables predictoras que se encuentren altamente relacionadas con otras que permanecen en el modelo\n\n-   Sustituir las variables predictoras por componentes principales\n\n-   Incluir informaci√≥n externa a los datos originales. Esta alternativa implica utilizar estimadores contra√≠dos (de Stein o ridge) o bayesianos.\n\nSi quisieramos eliminar variables que son combinaciones lineales deberiamos de hacer lo siguiente:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(Madrid_Sale_num_na[, -combos$remove])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  PERIOD   PRICE UNITPRICE CONSTRUCTEDAREA ROOMNUMBER BATHNUMBER HASTERRACE\n1 201803  126000  2680.851              47          1          1          0\n2 201803  228000  4560.000              50          0          1          0\n3 201803  425000  6071.429              70          1          1          0\n4 201803 2349000  4333.948             542          1          1          0\n5 201803  236000  4720.000              50          2          1          0\n6 201803 1131000  5463.768             207          5          3          0\n  HASLIFT HASAIRCONDITIONING AMENITYID HASPARKINGSPACE PARKINGSPACEPRICE\n1       1                  1         3               0                 1\n2       0                  0         3               0                 1\n3       1                  0         1               1                 1\n4       1                  1         3               0                 1\n5       0                  0         3               0                 1\n6       1                  0         3               1                 1\n  HASNORTHORIENTATION HASSOUTHORIENTATION HASEASTORIENTATION HASWESTORIENTATION\n1                   0                   0                  0                  0\n2                   0                   0                  0                  0\n3                   0                   0                  0                  1\n4                   0                   0                  0                  0\n5                   0                   0                  1                  0\n6                   0                   1                  1                  0\n  HASBOXROOM HASWARDROBE HASSWIMMINGPOOL HASDOORMAN HASGARDEN ISDUPLEX ISSTUDIO\n1          1           1               1          1         1        0        0\n2          0           0               0          0         0        0        1\n3          0           0               0          0         0        0        0\n4          0           0               0          0         0        0        0\n5          0           0               0          0         0        0        0\n6          1           0               0          1         0        0        0\n  ISINTOPFLOOR CONSTRUCTIONYEAR FLOORCLEAN FLATLOCATIONID CADCONSTRUCTIONYEAR\n1            0             2005          1              1                2005\n2            0             1930          0              1                1930\n3            0             1900          2              1                1900\n4            0             1890          1              1                1890\n5            0             1900          3              1                1900\n6            0             1940          0              1                1940\n  CADMAXBUILDINGFLOOR CADDWELLINGCOUNT CADASTRALQUALITYID BUILTTYPEID_2\n1                   7              319                  3             1\n2                   5               19                  7             0\n3                   5               16                  1             0\n4                   4               11                  2             1\n5                   5                6                  6             1\n6                   5               29                  4             1\n  BUILTTYPEID_3 DISTANCE_TO_CITY_CENTER DISTANCE_TO_METRO\n1             0               8.0584293         0.8720746\n2             1               1.2502313         0.3370982\n3             1               0.7535746         0.4371906\n4             0               0.6227413         0.1622422\n5             0               1.0341080         0.3147058\n6             0               0.6328356         0.1954949\n  DISTANCE_TO_CASTELLANA LONGITUDE LATITUDE\n1               6.868677 -3.766933 40.36248\n2               1.794136 -3.714340 40.40874\n3               1.548310 -3.712390 40.41487\n4               1.453994 -3.711072 40.41734\n5               1.622230 -3.712053 40.40976\n6               1.400989 -3.709651 40.42011\n```\n\n\n:::\n:::\n\n\n\n\n## M√©todos de selecci√≥n de variables\n\nEn el *subset* de variables que sobrevivien al proceso anterior, es necesario detectar cuales de ellas han de entrar en el modelo. Esta fase se realiza porque:\n\n-   Queremos simplificar los modelos para hacerlos m√°s interpretables\n-   Mejorar la precisi√≥n del modelo\n-   Reducir el tiempo de computaci√≥n. Entrenar algoritmos con mayor velocidad\n-   Evitar la maldici√≥n de la dimensionalidad (efecto Huges), que se refiere a las consecuencias no deseadas que tiene lugar cuando la dimensionalidad de un problema es muy elevada.\n-   Reducir la probabilidad de sobreajuste\n\n### *Filters*\n\nLos **m√©todos de selecci√≥n de variables tipo filtro** usan t√©cnicas estad√≠sticas para evaluar la relaci√≥n entre cada variable predictora y la variable objetivo. Generalmente, consideran la influencia de cada variable predictora sobre la variable objetivo por separado. Las puntuaciones obtenidas se utilizan como base para clasificar y elegir las variables predictoras que se utilizar√°n en el modelo.\n\nSi la variable predictora es num√©rica, entonces se usa el coeficiente de correlaci√≥n de Pearson o el de Spearman (si es o no lineal). Si las variables fueran todas categ√≥ricas se podria usar medidas de asociaci√≥n para tablas de contingencia. Por lo contrario si la entregada es categorica y la salida es num√©rica se podrian usar t√©cnicas de ANOVA para analizar que variables son influeyentes.\n\nPodemos usar diferentes paquetes como `FSelector`, `caret` para implementar dicha t√©cnica. En este caso, usaremos el paquete `FSinR`. A continuaci√≥n se muestra un ejemplo para variables predictoras num√©ricas. Para ello, se toma una muestra del conjunto de datos. Una vez en disposici√≥n de la muestra, primeramente se transforma la variable objetivo en categ√≥rica, siendo las categor√≠as (intervalos) cuatro cortes de la distribuci√≥n de sus valores; dicha categorizaci√≥n se lleva a cabo mediante **binning** Tambi√©n se eliminan los registros con datos faltantes.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"rsample\")\n\n# Se toma una muestra con el paquete rsample\nset.seed(7)\nMadrid_Sale_num_sample <- sample(1:nrow(Madrid_Sale_num), size = 5000, replace = FALSE)\nMadrid_Sale_num_sample <- Madrid_Sale_num[Madrid_Sale_num_sample, ]\n# Se realiza binning con cuatro bins\nMadrid_Sale_num_sample_bin <- Madrid_Sale_num_sample |>\n  mutate(price_bin = cut(PRICE, breaks = c(0, 250000, 500000, 750000, 10000000), labels = c(\"primerQ\", \"segundoQ\", \"tercerQ\", \"c\"), include.lowest = TRUE)) |>\n  select(price_bin, CONSTRUCTEDAREA, ROOMNUMBER, BATHNUMBER, HASTERRACE, HASLIFT)\n# Se eliminan los registros con valores missing\nMadrid_Sale_sample_na <- drop_na(Madrid_Sale_num_sample_bin)\n```\n:::\n\n\n\n\nUna vez discretizada la variable objetivo, se selecciona el conjunto de variables predictoras de la variable objetivo `price_bin`, que es la variable `PRICE` transformada mediante *binning*. Como m√©todo tipo filtro se utiliza minimum description length (MDLM), que es un m√©todo de selecci√≥n de variables que se basa en una medida de la complejidad del modelo denominada ‚Äúlongitud m√≠nima de la descripci√≥n‚Äù (de ah√≠ el nombre del modelo), por lo que su objetivo es encontrar el modelo m√°s sencillo que proporcione una explicaci√≥n aceptable de los datos. Como algoritmo de b√∫squeda se utiliza sequential forward selection.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"FSinR\")\n\n# M√©todo tipo filtro MDLC (Minimum-Description_Length-Criterion)\nevaluador <- filterEvaluator(\"MDLC\")\n\n# Se genera el algoritmo de b√∫squeda\nbuscador <- searchAlgorithm(\"sequentialForwardSelection\")\n\n# Se implementa el proceso, pasando a la funci√≥n los dos par√°metros anteriores\nresultados <- featureSelection(Madrid_Sale_sample_na, \"price_bin\", buscador, evaluador)\n\n# Se muestran los resultados\nresultados$bestFeatures\nresultados$bestValue\n```\n:::\n\n\n\n\n### *Wrappers*\n\nEste enfoque realiza una b√∫squeda a trav√©s de diferentes combinaciones o subconjuntos de variables predictoras/clasificadoras para comprobar el efecto que tienen en la precisi√≥n del modelo.\n\nLos m√©todos wrapper son de gran eficacia a la hora de eliminar variables irrelevantes y/o redundantes (cosa que no ocurre en los de tipo filtro porque se centran en el poder predictor de cada variable de forma aislada).\n\ntienen en cuenta la circunstancia de que dos o m√°s variables, aparentemente irrelevantes en cuanto a su capacidad predictiva o clasificatoria cuando se consideran una por una, pueden ser relevantes cuando se consideran conjuntamente. Sin embargo, son muy lentos, ya que tienen que aplicar much√≠simas veces el algoritmo de b√∫squeda, cambiando cada vez el n√∫mero de variables, siguiendo cada vez alg√∫n criterio tanto de b√∫squeda como de paro.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Se fijan los par√°metros\nevaluador <- wrapperEvaluator(\"rpart1SE\")\nbuscador <- searchAlgorithm(\"sequentialForwardSelection\")\n# Se eval√∫an sobre Madrid_Sale_sample_na\nresults <- featureSelection(Madrid_Sale_sample_na, \"price_bin\", buscador, evaluador)\nresultados$bestFeatures\nresultados$bestValue\n```\n:::\n\n\n\n\n### *Embeddings*\n\nHay algunos algoritmos de aprendizaje autom√°tico que realizan la selecci√≥n autom√°tica de variables como parte del aprendizaje del modelo. Estos son los m√©todos de selecci√≥n de tipo intr√≠nseco, que aglutinan las ventajas de los m√©todos de filtro y envoltura.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"randomForest\")\n\n# Usar random forest para la selecci√≥n de variables\nrf_modelo <- randomForest(price_bin ~ ., data = Madrid_Sale_num_sample_bin)\n\n# Listar las variables m√°s importantes\nvarImp(rf_modelo)\n```\n:::\n\n\n\n\n# Features Enginineering\n\nLa ingenier√≠a de variables consiste en el proceso de conseguir, a partir de la informaci√≥n disponible, las variables id√≥neas (y en el n√∫mero apropiado) para que los modelos o clasificadores proporcionen los mejores resultados posibles, dados los datos disponibles y el modelo a ejecutar.\n\nUna de las herramientas m√°s populares es el **One-hot encoding**. El **One-hot encoding** consiste en asignar a cada etiqueta un n√∫mero entero o valor √∫nico seg√∫n el orden alfab√©tico. Es la codificaci√≥n m√°s popular y ampliamente utilizada.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndummies <- dummyVars(\"  ~ .\", data = Madrid_Sale_num_sample_bin)\nhead(predict(dummies, newdata = Madrid_Sale_num_sample_bin))\n```\n:::\n\n\n\n\n# Validaci√≥n y control de calidad\n\nAl final del proceso de limpieza de datos, estos deber√≠an ser consistentes y seguir las reglas apropiadas para su campo de negocio. De no ser as√≠, los modelos que se estimen en base a ellos no representar√°n convenientemente la realidad objeto de estudio y las conclusiones que se obtengan de dichos modelos no ser√°n de utilidad para dicha realidad.\n\nLa verificaci√≥n de si los datos son o no consistentes y si siguen o no las reglas del campo de negocio del cual proceden se puede llevar a cabo con el paquete `tidyverse`, que permite hacer selecciones, filtrados o tablas de frecuencias, entre otras acciones.\n\nUna opci√≥n m√°s sofisticada es el paquete `validate`, donde se pueden introducir las reglas de negocio dentro del propio c√≥digo o bien desde un fichero externo. A continuaci√≥n, se realiza un ejemplo con las reglas incrustadas en el propio c√≥digo. Estas reglas pueden ser avisos o normas que indican error en esos datos. En este ejemplo, se han definido siete reglas: por ejemplo, `PRICE` ‚â• 0, o que la suma de las variables `HASNORTHORIENTATION`, `HASSOUTHORIENTATION`, `HASEASTORIENTATION` y `HASWESTORIENTATION` sea la unidad. La salida que se obtiene se presenta a continuaci√≥n.\n\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"validate\")\n\nMadrid_Sale_int |>\n  check_that(\n    HASLIFT >= 0,\n    PRICE >= 0,\n    HASNORTHORIENTATION + HASSOUTHORIENTATION + HASEASTORIENTATION + HASWESTORIENTATION == 1,\n    is.numeric(PRICE),\n    UNITPRICE * CONSTRUCTEDAREA == PRICE,\n    if (ROOMNUMBER > 3) PRICE > 100000,\n    nrow(.) >= 20000\n  ) |>\n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  name items passes fails nNA error warning\n1   V1 94815  94815     0   0 FALSE   FALSE\n2   V2 94815  94815     0   0 FALSE   FALSE\n3   V3 94815  28080 66735   0 FALSE   FALSE\n4   V4     1      1     0   0 FALSE   FALSE\n5   V5 94815  20111 74704   0 FALSE   FALSE\n6   V6 94815  94786    29   0 FALSE   FALSE\n7   V7     1      1     0   0 FALSE   FALSE\n                                                                                             expression\n1                                                                                 HASLIFT - 0 >= -1e-08\n2                                                                                   PRICE - 0 >= -1e-08\n3 abs(HASNORTHORIENTATION + HASSOUTHORIENTATION + HASEASTORIENTATION + HASWESTORIENTATION - 1) <= 1e-08\n4                                                                                     is.numeric(PRICE)\n5                                                                  UNITPRICE * CONSTRUCTEDAREA == PRICE\n6                                                                     ROOMNUMBER <= 3 | (PRICE > 1e+05)\n7                                                                                      nrow(.) >= 20000\n```\n\n\n:::\n:::\n\n\n\n\nEn un esquema tradicional de validaci√≥n, adem√°s de las reglas de validaci√≥n aportadas por los expertos en el tema del que se trate, debe incluirse tambi√©n un listado de reglas de correcci√≥n (igualmente aportado por los expertos en la materia) que indique c√≥mo hay que corregir un registro cuando no cumple con una determinada regla de validaci√≥n. Este modo de proceder, adem√°s de suponer un doble esfuerzo, puede conducir a inconsistencias o validaciones c√≠clicas.\n\nEl **M√©todo de Fellegi y Holt (MFH)** da una soluci√≥n a este problema, evitando dichas inconsistencias, proporcionando un procedimiento que genera un conjunto completo de reglas de validaci√≥n, incorporando reglas impl√≠citas a las formuladas por los expertos de manera expl√≠cita.\n\nDicho m√©todo asegura el cumplimiento de las siguientes tres premisas:\n\n-   Minimizar el n√∫mero de campos a corregir en un registro para hacerlo pasar todas las validaciones.\n-   Mantener, en la medida de lo posible, la distribuci√≥n conjunta original del conjunto de datos.\n-   Derivar las reglas de correcci√≥n, directamente y de forma impl√≠cita, de las reglas de validaci√≥n. Por tanto, dichas reglas de correcci√≥n no son propuestas por el experto o, en su caso, por el validador.\n\nEl **MFH** no est√° exento de limitaciones. La primera es el incremento del coste computacional, que puede llegar a constituir un problema en caso de que el n√∫mero de reglas impl√≠citas sea muy elevado, lo cual es muy frecuente. De hecho, hay casos en los que hay m√°s reglas impl√≠citas que registros. Para solucionar este problema, denominado *‚Äúproblema de localizaci√≥n del error‚Äù*, que consiste, b√°sicamente, en determinar el conjunto m√≠nimo de variables a corregir para cada validaci√≥n, se han propuesto varias alternativas, que incluyen m√©todos de investigaci√≥n de operaciones, √°rboles binarios y metaheur√≠sticas como algoritmos gen√©ticos y similares.\n\nA efectos pr√°cticos, el MFH se puede aplicar con la funci√≥n `locate_errors()` del paquete `errorlocate`, determin√°ndose as√≠ cu√°les son las variables a corregir para solventar los errores en las reglas de negocio establecidas (objeto rules).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"errorlocate\")\n\nMadrid_Sale_red2 <- mutate(Madrid_Sale_int, price_bin = Hmisc::cut2(PRICE, g=4))\n\nrules <- validator(if (ROOMNUMBER >= 10) price_bin == \"[502000,7138000]\")\n(el <- locate_errors(Madrid_Sale_red2, rules) |>\n  summary(el))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nVariable:\n                            name errors missing\n42                     price_bin     45       0\n6                     ROOMNUMBER     35       0\n1                        ASSETID      0       0\n2                         PERIOD      0       0\n3                          PRICE      0       0\n4                      UNITPRICE      0       0\n5                CONSTRUCTEDAREA      0       0\n7                     BATHNUMBER      0       0\n8                     HASTERRACE      0       0\n9                        HASLIFT      0       0\n10            HASAIRCONDITIONING      0       0\n11                     AMENITYID      0       0\n12               HASPARKINGSPACE      0       0\n13 ISPARKINGSPACEINCLUDEDINPRICE      0       0\n14             PARKINGSPACEPRICE      0       0\n15           HASNORTHORIENTATION      0       0\n16           HASSOUTHORIENTATION      0       0\n17            HASEASTORIENTATION      0       0\n18            HASWESTORIENTATION      0       0\n19                    HASBOXROOM      0       0\n20                   HASWARDROBE      0       0\n21               HASSWIMMINGPOOL      0       0\n22                    HASDOORMAN      0       0\n23                     HASGARDEN      0       0\n24                      ISDUPLEX      0       0\n25                      ISSTUDIO      0       0\n26                  ISINTOPFLOOR      0       0\n27              CONSTRUCTIONYEAR      0   55873\n28                    FLOORCLEAN      0    3846\n29                FLATLOCATIONID      0    6387\n30           CADCONSTRUCTIONYEAR      0       0\n31           CADMAXBUILDINGFLOOR      0       0\n32              CADDWELLINGCOUNT      0       0\n33            CADASTRALQUALITYID      0       1\n34                 BUILTTYPEID_1      0       0\n35                 BUILTTYPEID_2      0       0\n36                 BUILTTYPEID_3      0       0\n37       DISTANCE_TO_CITY_CENTER      0       0\n38             DISTANCE_TO_METRO      0       0\n39        DISTANCE_TO_CASTELLANA      0       0\n40                     LONGITUDE      0       0\n41                      LATITUDE      0       0\nErrors per record:\n  errors records\n1      0   94735\n2      1      80\n```\n\n\n:::\n:::\n\n\n\n\n¬øY qu√© se debe hacer con los registros que no cumplen las normas de validaci√≥n? La respuesta es, como norma, ‚Äúsiempre que se disponga de informaci√≥n de negocio, esta debe preponderar sobre cualquier tipo de imputaci√≥n‚Äù. A partir de este punto se puede proceder a realizar imputaciones determin√≠sticas para solucionar los problemas detectados.\n\nEn el ejemplo anterior, se propone imputar el valor `ROOMNUMBER=5` a los casos de los tres primeros cuartiles (todos menos el m√°s caro) que tengan m√°s de 10 habitaciones. Para ello, se utiliza la funci√≥n `modify_so()` del paquete `dcmodify`. Para comprobar que la imputaci√≥n se ha llevado a cabo con √©xito, se pueden comparar los conjuntos de datos antes y despu√©s de la imputaci√≥n con la funci√≥n `compare()`, comprob√°ndose que tal imputaci√≥n se ha realizado exitosamente en los 2 registros que presentaban problemas con la regla `ROOMNUMBER >= 10`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(\"dcmodify\")\nout <- Madrid_Sale_red2 |>\n  modify_so(if (ROOMNUMBER >= 10 & price_bin != \"[502000,7138000]\") ROOMNUMBER <- 5)\nrules <- validator(if (ROOMNUMBER >= 10) price_bin == \"[502000,7138000]\")\ncompare(rules, raw = Madrid_Sale_red2, modified = out)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nObject of class validatorComparison:\n\n   compare(x = rules, raw = Madrid_Sale_red2, modified = out)\n\n                    Version\nStatus                 raw modified\n  validations        94815    94815\n  verifiable         94815    94815\n  unverifiable           0        0\n  still_unverifiable     0        0\n  new_unverifiable       0        0\n  satisfied          94735    94815\n  still_satisfied    94735    94735\n  new_satisfied          0       80\n  violated              80        0\n  still_violated        80        0\n  new_violated           0        0\n```\n\n\n:::\n:::\n\n\n\n\n# Bibliograf√≠a\n\n## Outliers\n\n-   https://statsandr.com/blog/outliers-detection-in-r/#z-scores\n-   https://m-mburu.github.io/datacamp/anomaly_detection_R/anomaly_detection.html\n-   https://github.com/pridiltal/ctv-AnomalyDetection\n\n## Imputaci√≥n\n\n-   http://naniar.njtierney.com/articles/replace-with-na.html\n-   https://cran.r-project.org/web/packages/visdat/vignettes/using_visdat.html\n-   https://cran.r-project.org/web/packages/DMwR2/DMwR2.pdf\n-   https://ltorgo.github.io/DMwR2/RintroDM.html#data_pre-processing\n-   https://www.rdocumentation.org/packages/DMwR/versions/0.4.1/topics/knnImputation\n-   https://amices.org/mice/\n",
    "supporting": [
      "AdvancedPreprocessing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}