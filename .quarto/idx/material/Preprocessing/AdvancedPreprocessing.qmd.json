{"title":"Advance Preprocessing","markdown":{"yaml":{"title":"Advance Preprocessing","author":"Dante Conti, Sergi Ramirez, (c) IDEAI","date":"`r Sys.Date()`","date-modified":"`r Sys.Date()`","toc":true,"number-sections":true,"format":{"html":{"theme":"cerulean"}},"editor":"visual"},"headingText":"Descripci√≥n del problema","containsRefs":false,"markdown":"\n\n\nPara hacer el apartado de preprocessing vamos a utilizar la base de datos [`valentine_dataset.csv`](https://www.kaggle.com/datasets/anyasorc/valentine-dataset).\n\n```{r}\n#| label: lectura-datos\n#| echo: false\n#| warning: false\n#| message: false\n#| error: false\n\n# Lectura de los datos\ndades <- read.csv(\"E:/PROYECTOS/ramIA-lab_repositorio/MLforEducation/MLforEducation/material/Preprocessing/valentine_dataset.csv\")\n\ntipus <- sapply(dades, class)\nvarNum <- names(tipus)[which(tipus %in% c(\"integer\", \"numeric\"))]\nvarNum <- varNum[which(!varNum %in% c(\"Valentine_Date\"))]\nvarCat <- names(tipus)[which(tipus %in% c(\"factor\", \"character\"))]\n```\n\n# Outliers\n\nUn outlier es un valor extremo que se aleja significativamente del resto de observaciones. Detectarlos es importante porque pueden distorsionar las estad√≠sticas, influir en los modelos y generar conclusiones err√≥neas.\n\nExisten diferentes enfoques: desde an√°lisis univariantes (una variable a la vez) hasta multivariantes (considerando la relaci√≥n entre varias variables).\n\n## Univariate\n\nEn este caso analizamos variable por variable.\n\n### Max and Min\n\nLa primera estrategia consiste en observar los valores m√≠nimos y m√°ximos de cada variable num√©rica. Esto nos da una primera idea de los rangos de los datos y de si existen valores extra√±os.\n\n```{r}\n#| label: min_max\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nmapply(function(x, name) {\n  cat(\"var. \", name, \": \\n\\t min: \", min(x), \"\\n\\t max: \", max(x), \"\\n\")\n  invisible(NULL)  # Evita la salida de valores NULL\n}, dades[, varNum], colnames(dades[, varNum]))\n```\n\n### IQR\n\nOtra manera de detectar outliers es usando el **rango intercuart√≠lico (IQR)**.\nSe definen como outliers los puntos que quedan fuera del intervalo:\n\n$$\n[Q1 - 1.5xIQR, Q3 + 1.5xIQR]\n$$\n\ndonde $Q1$ es el primer cuartil, $Q3$ el tercer cuartil e $IQR = Q3 - Q1$.\n\n```{r}\n#| label: iqr\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(EnvStats)\n\nIQROutlier <- function(variable, rmnas = TRUE) {\n  IQ <- iqr(variable, na.rm = rmnas)\n  intInf <- quantile(variable, probs = c(0.25, 0.75))[[1]] - 1.5*IQ\n  intSup <- quantile(variable, probs = c(0.25, 0.75))[[2]] + 1.5*IQ\n  posicions <- which(variable >= intSup | variable <= intInf)\n  if (length(posicions) > 0) {\n    cat(\"Existeixen outliers en les posicions:\", paste0(posicions, collapse = \", \"))\n  } else {\n    cat(\"No existeixen outliers\")\n  }\n  return(posicions)\n}\n```\n\n```{r}\n#| label: iqr_valor\n#| echo: false\n#| warning: false\n#| message: false\n#| error: false\n\nIQROutlier(dades[, \"Confidence_Score\"])\n```\n\n> üëâ Aqu√≠ veremos cu√°ntos valores son considerados extremos seg√∫n este criterio en cada variable num√©rica.\n\n### Boxplot\n\nVisualitzaci√≥ basada en IQR per detectar outliers.\n\n```{r}\n#| label: boxplot\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(ggplot2)\n\nvariable <- \"Age\"\n\nboxplot(dades[, variable])\nboxplot.stats(dades[, variable])$out\n\n# Crear un boxplot\nggplot(dades, aes(y = get(variable))) +\n  geom_boxplot(fill = \"skyblue\", color = \"black\") +\n  labs(title = paste0(\"Boxplot de \", variable)) +\n  theme_minimal()\n```\n\n### Z-Score\n\nUn outlier es un valor amb \\|z\\| \\> 3 deviaci√≥ est√°ndar\n\n```{r}\n#| label: z_score\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\nvalorEscalado <- scale(dades[, variable])\nhist(valorEscalado)\n\nggplot(data.frame(valor = valorEscalado), aes(x = valor)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  # Histograma\n  geom_vline(xintercept = c(3, -3), linetype = \"dashed\", color = \"red\", size = 1) + # L√≠neas horizontales\n  theme_minimal()\n```\n\n### Hampel Identifier\n\nUtilitza la mediana i la desviaci√≥ absoluta mediana (MAD) en lloc de la mitjana\n\n```{r}\n#| label: hampel\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\n\nlower_bound <- median(dades[, variable]) - 3 * mad(dades[, variable], constant = 1)\nupper_bound <- median(dades[, variable]) + 3 * mad(dades[, variable], constant = 1)\noutlier_ind <- which((dades[, variable] < lower_bound) | (dades[, variable] > upper_bound))\noutlier_ind\n```\n\n### Tests Estad√≠stics\n\n#### Grubbs' Test\n\nDetecta valors extrems en una distribuci√≥ normal\n\n```{r}\n#| label: grubbs_test\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(outliers)\n\nvariable <- \"Age\"\ntest <- outliers::grubbs.test(dades[, variable], opposite = TRUE)\n# amb el par√†metre opposite controles quina de les dues cues est√°n buscant\ntest\n\n```\n\n#### Dixon's Test\n\nNom√©s utilitzar per a bbdd petites (entre 3 - 30) observacions\n\n```{r}\n#| label: dixon-test\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\ntest <- outliers::dixon.test(dades[, variable], opposite = FALSE)\ntest\n```\n\n#### Rosner's Test\n\nLa prueba de Rosner para valores at√≠picos tiene las ventajas de que: 1. se utiliza para detectar varios valores at√≠picos a la vez (a diferencia de la prueba de Grubbs y Dixon, que debe realizarse de forma iterativa para detectar m√∫ltiples valores at√≠picos), 2. Est√° dise√±ado para evitar el problema del enmascaramiento, donde un valor at√≠pico cercano en valor a otro valor at√≠pico puede pasar desapercibido.\n\nA diferencia de la prueba de Dixon, tenga en cuenta que la prueba de Rosner es m√°s apropiada cuando el tama√±o de la muestra es grande (n ‚â• 20).\n\nEsta funci√≥n requiere al menos dos argumentos: - los datos - la cantidad de valores at√≠picos sospechosos k (k = 3 como cantidad predeterminada)\n\nAsumeix normalitat de les dades\n\n```{r}\n#| label: rosner\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(EnvStats)\n\nvariable <- \"Age\"\ntest <- EnvStats::rosnerTest(dades[, variable], k = 1)\ntest\ntest$all.stats\n```\n\n## Multivariate\n\nHasta ahora hemos visto cada variable por separado. Sin embargo, a veces los outliers aparecen **en combinaci√≥n** de variables.\n\nPara detectarlos se pueden usar m√©todos como la distancia de Mahalanobis o algoritmos m√°s avanzados de detecci√≥n de anomal√≠as.\n\n```{r}\n#| label: plot_multivariate\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(scatterplot3d)\nlibrary(readr)\ndades <- readr::read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv\")\ndades <- data.frame(dades[, c(\"DC\", \"temp\", \"RH\")])\nscatterplot3d(dades[,\"DC\"], dades[, \"temp\"],dades[, \"RH\"])\n```\n\n```{r}\n#| label: 3d_scatterplot\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(rgl)\n\n# Plot\nrgl::plot3d(x = dades[, \"DC\"], y = dades[, \"temp\"], z = dades[, \"RH\"], \ncol = \"black\", type = 'p', radius = .1)\n```\n\n```{r}\n#| label: scatterplot_plotly\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(plotly)\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, size = 1) %>% \n       add_markers())\n```\n\n### Cas general\n\n```{r}\n#| label: deteccio_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(mvoutlier)\ndades2 <- dades; Y <- as.matrix(dades2)\ndistances <- dd.plot(Y,quan=1/2, alpha=0.025)\nhead(distances$md.cla)\nhead(distances$md.rob)\nres <- aq.plot(Y,delta=qchisq(0.975,df=ncol(Y)),quan=1/2,alpha=0.05)\nstr(res)\nhead(res$outliers)\ntable(res$outliers)\n#windows()\npar(mfrow=c(1, 1))\nlibrary(MVN)\n# mvnoutliers <- mvn(dades, multivariateOutlierMethod = \"adj\", showOutliers = TRUE, \n#                   showNewData = TRUE)\nmvnoutliers <- mvn(data = dades, mvn_test = \"royston\", \n                   univariate_test = \"AD\", \n              multivariate_outlier_method = \"adj\",\n              show_new_data = TRUE)\n```\n\nVisualitzem tots els outliers detectats com a true\n\n```{r}\n#| label: visualizacion_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"outliers\"))\n```\n\nVisualitzem les variables originals quines han donat els que no son outliers\n\n```{r}\n#| label: datos_sin_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"new_data\"))\n```\n\nVisualitzem els resultats del test de normalitat univariant\n\n```{r}\n#| label: test_normalidad_lof\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"mvn\"))\n```\n\ni multivariant\n\n```{r}\n#| label: test_normalidad_multi_lof\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n#| \nhead(summary(mvnoutliers, select = \"univariate\"))\n```\n\n### PCA\n\nM√©todes basats en correlacions ens permeten detectar outliers\n\n### Distancia de Mahalanobis\n\nMedeix la distancia de un punt respecte a la mitjana considerant la covarian√ßa\n\n```{r}\n#| label: dist_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n \ndistancia_mahalanobis <- mahalanobis(dades, colMeans(dades), cov(dades))\n```\n\nGrafiquem el plot de la densitat de les distancies\n\n```{r}\n#| label: plot_density_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nplot(density(distancia_mahalanobis))\n```\n\nEs mostren els valors de la bbdd que queden per sobre de el 99% de la distribuci√≥ chi-cuadrat\n\n```{r}\n#| label: cuttoff_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ncutoff <- qchisq(p = 0.99, df = ncol(dades))\ndades[distancia_mahalanobis>cutoff, ]\n```\n\nOrdenamos de forma decreciente, seg√∫n el score de Mahalanobis\n\n```{r}\n#| label: segmentar_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndades <- dades[order(distancia_mahalanobis, decreasing = TRUE),]\n```\n\nVisualitzem l'histograma de les distancies per veure on tallem els outliers\n\n```{r}\n#| label: plot_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\npar(mfrow=c(1,1))\nhist(distancia_mahalanobis)\n```\n\nDescartamos los outliers seg√∫n un umbral\n\n```{r}\n#| label: umbral_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\numbral <- 8\ndades[, \"outlier\"] <- (distancia_mahalanobis > umbral)\n\ndades[, \"color\"] <- ifelse(dades[, \"outlier\"], \"red\", \"black\")\nscatterplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], \n              color = dades[, \"color\"])\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, \n                       color = ~color, colors = c('#0C4B8E', '#BF382A')) %>% \n                        add_markers())\n\n(quienes <- which(dades[, \"outlier\"] == TRUE))\n```\n\n#### Mahalanobis Robusto\n\n```{r}\n#| label: mahalanobis_robusto\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(chemometrics)\n\ndis <- chemometrics::Moutlier(dades[, c(\"DC\", \"temp\", \"RH\")], quantile = 0.99, plot = TRUE)\n\npar(mfrow = c(1, 1))\nplot(dis$md, dis$rd, type = \"n\")\ntext(dis$md, dis$rd, labels = rownames(dades))\na <- which(dis$rd > 7)\nprint(a)\n```\n\n### Regresi√≥ Lineal i residus\n\nUn punt amb un residu gran pot considerar-se un outlier\n\n### Distancia de Cook\n\nIdentifica punts amb gran influ√®ncia en la regresi√≥. Un valor de Cook D_i \\> 1 √©s un outliers.\n\n### K-Nearest Neighbors (KNN) Outlier Score\n\nBasats en la densitat local de les dades\n\n```{r}\n#| label: knn-outlier\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(adamethods)\n\ndo_knno(dades[, c(\"DC\", \"temp\", \"RH\")], k=1, top_n = 30)\n\n```\n\n### Local Outlier Factor (LOF)\n\nCompara la densidat de un punt amb la densidat dels seus ve√Øns. Un valor LOF alt\n\n```{r}\n#| label: lof1\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(DMwR2)\nlibrary(dplyr)\n\noutlier.scores <- lofactor(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\npar(mfrow=c(1,1))\nplot(density(outlier.scores))\noutlier.scores\noutliers <- order(outlier.scores, decreasing=T)\noutliers <- order(outlier.scores, decreasing=T)[1:5]\n```\n\nAprofitarem el ACP per poder visualizar els outliers\n\n```{r}\n#| label: acp_lof\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nn <- nrow(dades[, c(\"DC\", \"temp\", \"RH\")]); labels <- 1:n; labels[-outliers] <- \".\"\nbiplot(prcomp(dades[, c(\"DC\", \"temp\", \"RH\")]), cex = .8, xlabs = labels)\n```\n\nGrafiquem les correlacions per veure els gr√°fics\n\n```{r}\n#| label: corrplot_lof\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\n\npch <- rep(\".\", n)\npch[outliers] <- \"+\"\ncol <- rep(\"black\", n)\ncol[outliers] <- \"red\"\npairs(dades[, c(\"DC\", \"temp\", \"RH\")], pch = pch, col = col)\n```\n\nHo visualitzem en 3D\n\n```{r}\n#| label: pca_3d_outliers\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], type = \"s\", col = col, size = 1)\n```\n\n#### Nueva versi√≥n de LOF\n\n```{r}\n#| label: lof2\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(Rlof)\noutliers.scores <- Rlof::lof(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\nplot(density(outliers.scores))\n#outlier.scores <- lof(dades[, c(\"DC\", \"temp\", \"RH\")], k=c(5:10))\n```\n\n### Isolation Forest\n\n```{r}\n#| label: isolation_forest_ddbb\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\n### Cargamos las librerias necesarias\nlibrary(R.matlab)   # Lectura de archivos .mat\nlibrary(solitude)   # Modelo isolation forest\nlibrary(tidyverse)  # Preparaci√≥n de datos y gr√°ficos\nlibrary(MLmetrics)\n\n# Carreguem les dades\ncardio_mat  <- readMat(\"https://www.dropbox.com/s/galg3ihvxklf0qi/cardio.mat?dl=1\")\ndf_cardio   <- as.data.frame(cardio_mat$X)\ndf_cardio$y <- as.character(cardio_mat$y)\ndatos <- df_cardio\n```\n\n```{r}\n#| label: aplicar_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nisoforest <- isolationForest$new(\n  sample_size = as.integer(nrow(datos)/2),\n  num_trees   = 500, \n  replace     = TRUE,\n  seed        = 123\n)\nisoforest$fit(dataset = datos %>% select(-y))\n```\n\nAra anem a realitzar les prediccions.\n\n```{r}\n#| label: predicciones_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\npredicciones <- isoforest$predict(\n  data = datos %>% select(-y)\n)\nhead(predicciones)\n```\n\n```{r}\n#| label: plot_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nggplot(data = predicciones, aes(x = average_depth)) +\n  geom_histogram(color = \"gray40\") +\n  geom_vline(\n    xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),\n    color      = \"red\",\n    linetype   = \"dashed\") +\n  labs(\n    title = \"Distribuci√≥n de las distancias medias del Isolation Forest\",\n    subtitle = \"Cuantiles marcados en rojo\"  ) +\n  theme_bw() +\n  theme(plot.title = element_text(size = 11))\n\ncuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))\ncuantiles\n```\n\n### TIPS: Detecci√≥n de anomal√≠as\n\nUna vez que la distancia de separaci√≥n ha sido calculado, se puede emplear como criterio para identificar anomal√≠as. Asumiendo que las observaciones con valores at√≠picos en una o m√°s de sus variables se separan del resto con mayor facilidad, aquellas observaciones con menor distancia promedio deber√≠an ser las m√°s at√≠picas.\n\nEn la pr√°ctica, si se est√° empleando esta estrategia de detecci√≥n es porque no se dispone de datos etiquetados, es decir, no se conoce qu√© observaciones son realmente anomal√≠as. Sin embargo, como en este ejemplo se dispone de la clasificaci√≥n real, se puede verificar si realmente los datos an√≥malos tienen menores distancias.\n\n```{r}\n#| label: plot_deteccionAnomalias\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndatos <- datos %>%\n  bind_cols(predicciones)\n\nggplot(data = datos,\n       aes(x = y, y = average_depth)) +\n  geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) + \n  geom_violin(alpha = 0) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +\n  stat_summary(fun = \"mean\", colour = \"orangered2\", size = 3, geom = \"point\") +\n  labs(title = \"Distancia promedio en el modelo Isolation Forest\",\n       x = \"clasificaci√≥n (0 = normal, 1 = anomal√≠a)\",\n       y = \"Distancia promedio\") +\n  theme_bw() + \n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 11)\n  )\n\n```\n\nLa distancia promedio en el grupo de las anomal√≠as (1) es claramente inferior. Sin embargo, al existir solapamiento, si se clasifican las n observaciones con menor distancia como anomal√≠as, se incurrir√≠a en errores de falsos positivos.\n\nAcorde a la documentaci√≥n, el set de datos Cardiotocogrpahy contiene 176 anomal√≠as. V√©ase la matriz de confusi√≥n resultante si se clasifican como anomal√≠as las 176 observaciones con menor distancia predicha.\n\n```{r}\n#| label: matriz_confusion\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nresultados <- datos %>%\n  select(y, average_depth) %>%\n  arrange(average_depth) %>%\n  mutate(clasificacion = if_else(average_depth <= 8.5, \"1\", \"0\"))\n\nmat_confusion <- MLmetrics::ConfusionMatrix(\n  y_pred = resultados$clasificacion,\n  y_true = resultados$y)\n\nmat_confusion\n```\n\n# Missing values (valores faltantes)\n\nLos **valores faltantes** aparecen cuando una observaci√≥n no tiene registrado el valor en cierta variable.\n\nManejar correctamente los NA es esencial: eliminarlos puede reducir mucho el dataset, mientras que imputarlos incorrectamente puede introducir sesgos.\n\nExisten varias t√©cnicas:\n\n* **Eliminaci√≥n de filas/columnas** con demasiados NA.\n* **Imputaci√≥n simple**, por ejemplo reemplazando con la media o moda.\n* **Imputaci√≥n avanzada**, como KNN o modelos predictivos.\n\n> üëâ La elecci√≥n depende de la importancia de la variable, la cantidad de NA y el contexto del problema.\n\n## Generate data with NA's\n\n```{r}\n#| label: generar_missings\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ncolSums(is.na(iris))\niris.mis <- missForest::prodNA(iris, noNA = 0.1)\ncolSums((is.na(iris.mis)))\n```\n\nOtra forma de crear missings en el dataframe\n\n```{r}\n#| label: generar_missings2\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis <- mi::create.missing(iris, pct.mis = 10)\n```\n\n## Little Test\n\nEs un test que nos permite detectar con que tipo de NA's estamos enfrente:\n\n```{r}\n#| label: test_little\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nnaniar::mcar_test(iris.mis)\n```\n\nSi el valor p de la prova √©s inferior a 0 aix√≤ vol dir que les dades amb NAs s'han generat aleat√≤riament.\n\n## Patrons descriptius de NA en una base de dades\n\n### Explorar les relacions de NA's\n\n```{r}\n#| label: vis_na_total\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(visdat)\nlibrary(ggplot2)\nlibrary(naniar)\n\nvis_dat(airquality);\nvis_dat(iris.mis)\nvis_miss(airquality);\nvis_miss(iris.mis)\n\nggplot(airquality, aes(x = Solar.R,y = Ozone)) + \n  geom_point()\nggplot(airquality, aes(x = Solar.R,  y = Ozone)) + \n  geom_miss_point()\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month)\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month) + \n  theme_dark()\n```\n\n### Visualitzaci√≥ dels NA's per variables\n\n```{r}\n#| label: vis_na_variables\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ngg_miss_var(airquality) + labs(y = \"Look at all the missing ones\")\n```\n\n### Detecci√≥ de NA's en la base de dades\n\n```{r}\n#| label: deteccio_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\naq_shadow <- bind_shadow(airquality)\n```\n\nImprimeix el gr√†fic amb difer√®ncia a les NA i no a les NA,\n\n```{r}\n#| label: grafico_detec_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nairquality %>%\n  bind_shadow() %>%\n  group_by(Ozone_NA) %>%\n  summarise_at(.vars = \"Solar.R\",\n               .funs = c(\"mean\", \"sd\", \"var\", \"min\", \"max\"),\n               na.rm = TRUE)\n\nggplot(aq_shadow,\n       aes(x = Temp,\n           colour = Ozone_NA)) + \n  geom_density()\n```\n\n### Extreu estad√≠stiques amb NAs de la base de dades\n\n```{r}\n#| label: estadistiques_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nprop_miss_case(airquality)\npct_miss_case(airquality)\nmiss_case_summary(airquality)\nmiss_case_table(airquality)\nprop_miss_var(airquality)\npct_miss_var(airquality)\nmiss_var_summary(airquality)\nmiss_var_table(airquality)\n```\n\n## Imputaci√≥ b√†sica\n\n### Imputar amb valor mitj√†\n\n```{r}\n#| label: NA_valor_mitja\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis[, \"imputed_Sepal.Length\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, mean))\n```\n\n# Imputar amb valor aleatori\n\n```{r}\n#| label: NA_valor_aleatori\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis[, \"imputed_Sepal.Length2\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, 'random'))\n```\n\nDe manera similar podeu utilitzar la mediana min, max, per imputar el valor que manca.\n\n### Representa la distribuci√≥ a variables reals i d'imputaci√≥ a trav√©s del gr√°fico de densidad con ggplot2\n\n```{r}\n#| label: grafico_imputacion\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndf_long <- iris.mis %>%\n  select(Sepal.Length, imputed_Sepal.Length, imputed_Sepal.Length2) %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\", \"green\"))\n\niris.mis[, c(\"imputed_Sepal.Length\", \"imputed_Sepal.Length2\")] <- NULL\n```\n\nOtra forma es usando el paquete `argImpute`.\n\n```{r}\n#| label: argImpute\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\n(impute_arg <- Hmisc::aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +\n                           Species, data = iris.mis, n.impute = 5))\n```\n\nRevisamos la variable `Sepal.Length` con la imputaci√≥n realizada en cada una de las rondas.\n\n```{r}\n#| label: imputacion_SL\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nimpute_arg$imputed$Sepal.Length\n```\n\nCalculamos la media para las 5 simulaciones.\n\n```{r}\n#| label: media_simulaciones\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nimputed_Sepal.Length <- rowMeans(impute_arg$imputed$Sepal.Length)\nnew_var_imputed <- iris$Sepal.Length\nnew_var_imputed[as.numeric(names(imputed_Sepal.Length))] <- imputed_Sepal.Length\n```\n\nRevisamos la diferencia entre las dos imputaciones.\n\n```{r}\n#| label: grafico_media_simulaciones\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = new_var_imputed)\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n## Multiple Iterative Regression Imputation (MI method)\n\nImputamos los valores NA's con mi\n\n```{r}\n#| label: mi_imputation\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nmi_data <- mi::mi(iris.mis, seed = 335)\n```\n\nRevisamos la informaci√≥n de las imputaciones.\n\n```{r}\n#| label: grafico_mi_imputation\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nsummary(mi_data)\nplot(mi_data)\npar(ask = FALSE)\n```\n\nRevisamos las interaciones de la base de datos\n\n```{r}\n#| label: graficamos_mi_iteration\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nmi_data@data\n```\n\n## Media con una variable target\n\nDefinimos la variable target\n\n```{r}\ntarget = \"Species\"\n```\n\nDefinimos la base de datos con NA's\n\n```{r}\n\ndata <- subset(iris, select = -c(get(target)))\ndata <- missForest::prodNA(data, noNA = 0.1)\ndata$Species <- iris[, target]\n```\n\nDefinir variables a imputar (excluyendo la variable target)\n\n```{r}\n\nvarImp <- colnames(data)[which(!colnames(data) %in% target)]\n```\n\nCalcular las medias por grupo\n\n```{r}\n\nmeans <- aggregate(data[, varImp], list(data[, target]), mean, na.rm = TRUE)\n```\n\nImputar valores faltantes\n\n```{r}\nfor (c in varImp) {\n  for (g in means[, \"Group.1\"]) {\n    cond <- data[, target] == g  # Condici√≥n booleana en vez de which()\n    na_index <- is.na(data[, c]) & cond  # Seleccionar NA dentro del grupo\n    \n    # Asignar valores imputados\n    data[na_index, c] <- means[means[, \"Group.1\"] == g, c]\n  }\n}\nsummary(data)\n```\n\nVisualizamos la diferencia entre las imputaciones\n\n```{r}\n\niris[, \"Tipo\"] <- \"original\"\ndata[, \"Tipo\"] <- \"imputed\"\n```\n\nUnimos en un mismo dataframe\n\n```{r}\n\ndata_long <- bind_rows(iris, data)\ncols_numeric <- names(data_long)[sapply(data_long, is.numeric) & names(data_long) != \"Tipo\"]\n\n# Convert a large data\ndata_long <- data_long %>%\n  pivot_longer(cols = all_of(cols_numeric), names_to = \"Variable\", values_to = \"Valor\")\n\n```\n\nCreamos el gr√°fico con ggplot\n\n```{r}\n\nggplot(data_long, aes(x = Valor, fill = Tipo)) +\n  geom_density(alpha = 0.3) +  # Transparencia para comparaci√≥n\n  facet_wrap(~Variable, scales = \"free\") +  # Un gr√°fico por variable\n  labs(title = \"Comparaci√≥n de Distribuciones: Original vs Imputado\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\nRemovemos la tipologia de variable\n\n```{r}\n\niris.mis[, \"Tipo\"] <- NULL\n```\n\n## Multiple Imputation by Chained Equations (MICE)\n\nEliminamos las variables categoricas\n\n```{r}\n\nquiCat <- which(lapply(iris.mis, class) %in% c(\"character\", \"factor\"))\ncategories <- names(iris.mis)[quiCat]\niris.mis2 <- subset(iris.mis, select = -c(get(categories)))\nsummary(iris.mis2)\n```\n\nVisualizamos los patrones de NA's de la base de datos\n\n```{r}\n\npar(mfrow = c(1, 1))\nmice::md.pattern(iris.mis2, rotate.names = TRUE)\n```\n\nTambi√©n lo podemos visualizar con el paquete VIM\n\n```{r}\n\nmice_plot <- VIM::aggr(iris.mis2, col=c('navyblue','yellow'),\n                  numbers=TRUE, sortVars=TRUE,\n                  labels=names(iris.mis), cex.axis=.7,\n                  gap=3, ylab=c(\"Missing data\",\"Pattern\"))\n```\n\nA continuaci√≥n realizamos la imputaci√≥n de los valores faltanes de manera multivariada\n\n```{r}\n\nimputed_Data <- mice::mice(iris.mis2, m=5, maxit = 50, method = 'pmm', seed = 500)\nsummary(imputed_Data)\n```\n\nInspeccionamos la calidad de las imputaciones\n\n```{r}\nmice::stripplot(imputed_Data, Sepal.Width, pch = 19, xlab = \"Imputation number\")\nimputed_Data$imp$Sepal.Width\n```\n\nAl final seleccionamos una de las iteracciones y la dejamos como imputaci√≥n de los valores faltantes.\n\n```{r}\ncompleteData <- mice::complete(imputed_Data, action = \"long\")\n```\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n## KNN\n\n```{r}\ntipos <- sapply(iris.mis, class)\nvarNum <- names(tipos)[which(tipos %in% c(\"numeric\", \"integer\"))]\ndata_knn_imputation <- multiUS::KNNimp(iris.mis[, varNum], k = 1)\nsummary(data_knn_imputation)\n```\n\nVisualizamos la diferencia entre las dos imputaciones.\n\n```{r}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = data_knn_imputation[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare the imputation and not imputation with all numeric vars in dataframe\n\n## missForest\n\nImputamos los missings usando todos los parametros con los valores por defectos.\n\n```{r}\nlibrary(missForest)\niris.imp <- missForest(iris.mis, variablewise = T, verbose = T) \n```\n\nVisualizamos los valores imputados\n\n```{r}\n\niris.imp$ximp\n```\n\nVisualizamos el error cometido en las imputaciones.\n\n```{r}\n\niris.imp$OOBerror\n```\n\nNRMSE √©s un error normalitzat mitj√† al quadrat. S'utilitza per representar l'error derivat d'imputar valors continus. El PFC (proporci√≥ de falsament classificada) s'utilitza per representar l'error derivat d'imputar valors categ√≤rics.\n\nComparamos el accuracy actual,\n\n```{r}\n\n(iris.err <- mixError(iris.imp$ximp, iris.mis, iris))\n```\n\nMiramos la diferencia entre las dos imputaciones\n\n```{r}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed =  iris.imp$ximp[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n### Exercises:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n### Extra:\n\nQuan es tracta de valors que manquen, √©s possible que vulgueu reempla√ßar valors per valors que manquen (NA). Aix√≤ √©s √∫til en els casos en qu√® es coneix l'origen de les dades i es pot estar segur de quins valors han de faltar. Per exemple, podr√≠eu saber que tots els valors de ¬´N/A¬ª, ¬´N A¬ª i ¬´No disponible¬ª, o -99 o -1 se suposa que falten.\n\nnaniar proporciona funcions per treballar espec√≠ficament en aquest tipus de problemes utilitzant la funci√≥ replace.with.na. Aquesta funci√≥ √©s el compliment a tidyr::replace els NA's, que reempla√ßa un valor NA per un valor especificat, mentre que naniar::replace,with_na reempla√ßa un valor per un NA:\n\n```{r}\n#| label: code_ejemplo\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\ntidyr::replace_na: Missing values turns into a value (NA ‚Äì> -99)\nnaniar::replace_with_na: Value becomes a missing value (-99 ‚Äì> NA)\n```\n\n## MIMMI\n\nPuedes descargar el fichero de MIMMI pinchando [aqu√≠](03_02_MIMMI.R)\n\n# Bibliograf√≠a\n\n## Outliers\n\n-   https://statsandr.com/blog/outliers-detection-in-r/#z-scores\n-   https://m-mburu.github.io/datacamp/anomaly_detection_R/anomaly_detection.html\n-   https://github.com/pridiltal/ctv-AnomalyDetection\n\n## Imputaci√≥n\n\n-   http://naniar.njtierney.com/articles/replace-with-na.html\n-   https://cran.r-project.org/web/packages/visdat/vignettes/using_visdat.html\n-   https://cran.r-project.org/web/packages/DMwR2/DMwR2.pdf\n-   https://ltorgo.github.io/DMwR2/RintroDM.html#data_pre-processing\n-   https://www.rdocumentation.org/packages/DMwR/versions/0.4.1/topics/knnImputation\n-   https://amices.org/mice/\n","srcMarkdownNoYaml":"\n\n# Descripci√≥n del problema\n\nPara hacer el apartado de preprocessing vamos a utilizar la base de datos [`valentine_dataset.csv`](https://www.kaggle.com/datasets/anyasorc/valentine-dataset).\n\n```{r}\n#| label: lectura-datos\n#| echo: false\n#| warning: false\n#| message: false\n#| error: false\n\n# Lectura de los datos\ndades <- read.csv(\"E:/PROYECTOS/ramIA-lab_repositorio/MLforEducation/MLforEducation/material/Preprocessing/valentine_dataset.csv\")\n\ntipus <- sapply(dades, class)\nvarNum <- names(tipus)[which(tipus %in% c(\"integer\", \"numeric\"))]\nvarNum <- varNum[which(!varNum %in% c(\"Valentine_Date\"))]\nvarCat <- names(tipus)[which(tipus %in% c(\"factor\", \"character\"))]\n```\n\n# Outliers\n\nUn outlier es un valor extremo que se aleja significativamente del resto de observaciones. Detectarlos es importante porque pueden distorsionar las estad√≠sticas, influir en los modelos y generar conclusiones err√≥neas.\n\nExisten diferentes enfoques: desde an√°lisis univariantes (una variable a la vez) hasta multivariantes (considerando la relaci√≥n entre varias variables).\n\n## Univariate\n\nEn este caso analizamos variable por variable.\n\n### Max and Min\n\nLa primera estrategia consiste en observar los valores m√≠nimos y m√°ximos de cada variable num√©rica. Esto nos da una primera idea de los rangos de los datos y de si existen valores extra√±os.\n\n```{r}\n#| label: min_max\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nmapply(function(x, name) {\n  cat(\"var. \", name, \": \\n\\t min: \", min(x), \"\\n\\t max: \", max(x), \"\\n\")\n  invisible(NULL)  # Evita la salida de valores NULL\n}, dades[, varNum], colnames(dades[, varNum]))\n```\n\n### IQR\n\nOtra manera de detectar outliers es usando el **rango intercuart√≠lico (IQR)**.\nSe definen como outliers los puntos que quedan fuera del intervalo:\n\n$$\n[Q1 - 1.5xIQR, Q3 + 1.5xIQR]\n$$\n\ndonde $Q1$ es el primer cuartil, $Q3$ el tercer cuartil e $IQR = Q3 - Q1$.\n\n```{r}\n#| label: iqr\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(EnvStats)\n\nIQROutlier <- function(variable, rmnas = TRUE) {\n  IQ <- iqr(variable, na.rm = rmnas)\n  intInf <- quantile(variable, probs = c(0.25, 0.75))[[1]] - 1.5*IQ\n  intSup <- quantile(variable, probs = c(0.25, 0.75))[[2]] + 1.5*IQ\n  posicions <- which(variable >= intSup | variable <= intInf)\n  if (length(posicions) > 0) {\n    cat(\"Existeixen outliers en les posicions:\", paste0(posicions, collapse = \", \"))\n  } else {\n    cat(\"No existeixen outliers\")\n  }\n  return(posicions)\n}\n```\n\n```{r}\n#| label: iqr_valor\n#| echo: false\n#| warning: false\n#| message: false\n#| error: false\n\nIQROutlier(dades[, \"Confidence_Score\"])\n```\n\n> üëâ Aqu√≠ veremos cu√°ntos valores son considerados extremos seg√∫n este criterio en cada variable num√©rica.\n\n### Boxplot\n\nVisualitzaci√≥ basada en IQR per detectar outliers.\n\n```{r}\n#| label: boxplot\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(ggplot2)\n\nvariable <- \"Age\"\n\nboxplot(dades[, variable])\nboxplot.stats(dades[, variable])$out\n\n# Crear un boxplot\nggplot(dades, aes(y = get(variable))) +\n  geom_boxplot(fill = \"skyblue\", color = \"black\") +\n  labs(title = paste0(\"Boxplot de \", variable)) +\n  theme_minimal()\n```\n\n### Z-Score\n\nUn outlier es un valor amb \\|z\\| \\> 3 deviaci√≥ est√°ndar\n\n```{r}\n#| label: z_score\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\nvalorEscalado <- scale(dades[, variable])\nhist(valorEscalado)\n\nggplot(data.frame(valor = valorEscalado), aes(x = valor)) +\n  geom_histogram(binwidth = 0.5, fill = \"skyblue\", color = \"black\") +  # Histograma\n  geom_vline(xintercept = c(3, -3), linetype = \"dashed\", color = \"red\", size = 1) + # L√≠neas horizontales\n  theme_minimal()\n```\n\n### Hampel Identifier\n\nUtilitza la mediana i la desviaci√≥ absoluta mediana (MAD) en lloc de la mitjana\n\n```{r}\n#| label: hampel\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\n\nlower_bound <- median(dades[, variable]) - 3 * mad(dades[, variable], constant = 1)\nupper_bound <- median(dades[, variable]) + 3 * mad(dades[, variable], constant = 1)\noutlier_ind <- which((dades[, variable] < lower_bound) | (dades[, variable] > upper_bound))\noutlier_ind\n```\n\n### Tests Estad√≠stics\n\n#### Grubbs' Test\n\nDetecta valors extrems en una distribuci√≥ normal\n\n```{r}\n#| label: grubbs_test\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(outliers)\n\nvariable <- \"Age\"\ntest <- outliers::grubbs.test(dades[, variable], opposite = TRUE)\n# amb el par√†metre opposite controles quina de les dues cues est√°n buscant\ntest\n\n```\n\n#### Dixon's Test\n\nNom√©s utilitzar per a bbdd petites (entre 3 - 30) observacions\n\n```{r}\n#| label: dixon-test\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nvariable <- \"Age\"\ntest <- outliers::dixon.test(dades[, variable], opposite = FALSE)\ntest\n```\n\n#### Rosner's Test\n\nLa prueba de Rosner para valores at√≠picos tiene las ventajas de que: 1. se utiliza para detectar varios valores at√≠picos a la vez (a diferencia de la prueba de Grubbs y Dixon, que debe realizarse de forma iterativa para detectar m√∫ltiples valores at√≠picos), 2. Est√° dise√±ado para evitar el problema del enmascaramiento, donde un valor at√≠pico cercano en valor a otro valor at√≠pico puede pasar desapercibido.\n\nA diferencia de la prueba de Dixon, tenga en cuenta que la prueba de Rosner es m√°s apropiada cuando el tama√±o de la muestra es grande (n ‚â• 20).\n\nEsta funci√≥n requiere al menos dos argumentos: - los datos - la cantidad de valores at√≠picos sospechosos k (k = 3 como cantidad predeterminada)\n\nAsumeix normalitat de les dades\n\n```{r}\n#| label: rosner\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(EnvStats)\n\nvariable <- \"Age\"\ntest <- EnvStats::rosnerTest(dades[, variable], k = 1)\ntest\ntest$all.stats\n```\n\n## Multivariate\n\nHasta ahora hemos visto cada variable por separado. Sin embargo, a veces los outliers aparecen **en combinaci√≥n** de variables.\n\nPara detectarlos se pueden usar m√©todos como la distancia de Mahalanobis o algoritmos m√°s avanzados de detecci√≥n de anomal√≠as.\n\n```{r}\n#| label: plot_multivariate\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(scatterplot3d)\nlibrary(readr)\ndades <- readr::read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv\")\ndades <- data.frame(dades[, c(\"DC\", \"temp\", \"RH\")])\nscatterplot3d(dades[,\"DC\"], dades[, \"temp\"],dades[, \"RH\"])\n```\n\n```{r}\n#| label: 3d_scatterplot\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(rgl)\n\n# Plot\nrgl::plot3d(x = dades[, \"DC\"], y = dades[, \"temp\"], z = dades[, \"RH\"], \ncol = \"black\", type = 'p', radius = .1)\n```\n\n```{r}\n#| label: scatterplot_plotly\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(plotly)\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, size = 1) %>% \n       add_markers())\n```\n\n### Cas general\n\n```{r}\n#| label: deteccio_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(mvoutlier)\ndades2 <- dades; Y <- as.matrix(dades2)\ndistances <- dd.plot(Y,quan=1/2, alpha=0.025)\nhead(distances$md.cla)\nhead(distances$md.rob)\nres <- aq.plot(Y,delta=qchisq(0.975,df=ncol(Y)),quan=1/2,alpha=0.05)\nstr(res)\nhead(res$outliers)\ntable(res$outliers)\n#windows()\npar(mfrow=c(1, 1))\nlibrary(MVN)\n# mvnoutliers <- mvn(dades, multivariateOutlierMethod = \"adj\", showOutliers = TRUE, \n#                   showNewData = TRUE)\nmvnoutliers <- mvn(data = dades, mvn_test = \"royston\", \n                   univariate_test = \"AD\", \n              multivariate_outlier_method = \"adj\",\n              show_new_data = TRUE)\n```\n\nVisualitzem tots els outliers detectats com a true\n\n```{r}\n#| label: visualizacion_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"outliers\"))\n```\n\nVisualitzem les variables originals quines han donat els que no son outliers\n\n```{r}\n#| label: datos_sin_outliers\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"new_data\"))\n```\n\nVisualitzem els resultats del test de normalitat univariant\n\n```{r}\n#| label: test_normalidad_lof\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nhead(summary(mvnoutliers, select = \"mvn\"))\n```\n\ni multivariant\n\n```{r}\n#| label: test_normalidad_multi_lof\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n#| \nhead(summary(mvnoutliers, select = \"univariate\"))\n```\n\n### PCA\n\nM√©todes basats en correlacions ens permeten detectar outliers\n\n### Distancia de Mahalanobis\n\nMedeix la distancia de un punt respecte a la mitjana considerant la covarian√ßa\n\n```{r}\n#| label: dist_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n \ndistancia_mahalanobis <- mahalanobis(dades, colMeans(dades), cov(dades))\n```\n\nGrafiquem el plot de la densitat de les distancies\n\n```{r}\n#| label: plot_density_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nplot(density(distancia_mahalanobis))\n```\n\nEs mostren els valors de la bbdd que queden per sobre de el 99% de la distribuci√≥ chi-cuadrat\n\n```{r}\n#| label: cuttoff_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ncutoff <- qchisq(p = 0.99, df = ncol(dades))\ndades[distancia_mahalanobis>cutoff, ]\n```\n\nOrdenamos de forma decreciente, seg√∫n el score de Mahalanobis\n\n```{r}\n#| label: segmentar_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndades <- dades[order(distancia_mahalanobis, decreasing = TRUE),]\n```\n\nVisualitzem l'histograma de les distancies per veure on tallem els outliers\n\n```{r}\n#| label: plot_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\npar(mfrow=c(1,1))\nhist(distancia_mahalanobis)\n```\n\nDescartamos los outliers seg√∫n un umbral\n\n```{r}\n#| label: umbral_mahalanobis\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\numbral <- 8\ndades[, \"outlier\"] <- (distancia_mahalanobis > umbral)\n\ndades[, \"color\"] <- ifelse(dades[, \"outlier\"], \"red\", \"black\")\nscatterplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], \n              color = dades[, \"color\"])\n\n(fig <- plotly::plot_ly(dades, x = ~DC, y = ~temp, z = ~RH, \n                       color = ~color, colors = c('#0C4B8E', '#BF382A')) %>% \n                        add_markers())\n\n(quienes <- which(dades[, \"outlier\"] == TRUE))\n```\n\n#### Mahalanobis Robusto\n\n```{r}\n#| label: mahalanobis_robusto\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(chemometrics)\n\ndis <- chemometrics::Moutlier(dades[, c(\"DC\", \"temp\", \"RH\")], quantile = 0.99, plot = TRUE)\n\npar(mfrow = c(1, 1))\nplot(dis$md, dis$rd, type = \"n\")\ntext(dis$md, dis$rd, labels = rownames(dades))\na <- which(dis$rd > 7)\nprint(a)\n```\n\n### Regresi√≥ Lineal i residus\n\nUn punt amb un residu gran pot considerar-se un outlier\n\n### Distancia de Cook\n\nIdentifica punts amb gran influ√®ncia en la regresi√≥. Un valor de Cook D_i \\> 1 √©s un outliers.\n\n### K-Nearest Neighbors (KNN) Outlier Score\n\nBasats en la densitat local de les dades\n\n```{r}\n#| label: knn-outlier\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(adamethods)\n\ndo_knno(dades[, c(\"DC\", \"temp\", \"RH\")], k=1, top_n = 30)\n\n```\n\n### Local Outlier Factor (LOF)\n\nCompara la densidat de un punt amb la densidat dels seus ve√Øns. Un valor LOF alt\n\n```{r}\n#| label: lof1\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(DMwR2)\nlibrary(dplyr)\n\noutlier.scores <- lofactor(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\npar(mfrow=c(1,1))\nplot(density(outlier.scores))\noutlier.scores\noutliers <- order(outlier.scores, decreasing=T)\noutliers <- order(outlier.scores, decreasing=T)[1:5]\n```\n\nAprofitarem el ACP per poder visualizar els outliers\n\n```{r}\n#| label: acp_lof\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nn <- nrow(dades[, c(\"DC\", \"temp\", \"RH\")]); labels <- 1:n; labels[-outliers] <- \".\"\nbiplot(prcomp(dades[, c(\"DC\", \"temp\", \"RH\")]), cex = .8, xlabs = labels)\n```\n\nGrafiquem les correlacions per veure els gr√°fics\n\n```{r}\n#| label: corrplot_lof\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\n\npch <- rep(\".\", n)\npch[outliers] <- \"+\"\ncol <- rep(\"black\", n)\ncol[outliers] <- \"red\"\npairs(dades[, c(\"DC\", \"temp\", \"RH\")], pch = pch, col = col)\n```\n\nHo visualitzem en 3D\n\n```{r}\n#| label: pca_3d_outliers\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nplot3d(dades[, \"DC\"], dades[, \"temp\"], dades[, \"RH\"], type = \"s\", col = col, size = 1)\n```\n\n#### Nueva versi√≥n de LOF\n\n```{r}\n#| label: lof2\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(Rlof)\noutliers.scores <- Rlof::lof(dades[, c(\"DC\", \"temp\", \"RH\")], k = 5)\nplot(density(outliers.scores))\n#outlier.scores <- lof(dades[, c(\"DC\", \"temp\", \"RH\")], k=c(5:10))\n```\n\n### Isolation Forest\n\n```{r}\n#| label: isolation_forest_ddbb\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\n### Cargamos las librerias necesarias\nlibrary(R.matlab)   # Lectura de archivos .mat\nlibrary(solitude)   # Modelo isolation forest\nlibrary(tidyverse)  # Preparaci√≥n de datos y gr√°ficos\nlibrary(MLmetrics)\n\n# Carreguem les dades\ncardio_mat  <- readMat(\"https://www.dropbox.com/s/galg3ihvxklf0qi/cardio.mat?dl=1\")\ndf_cardio   <- as.data.frame(cardio_mat$X)\ndf_cardio$y <- as.character(cardio_mat$y)\ndatos <- df_cardio\n```\n\n```{r}\n#| label: aplicar_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nisoforest <- isolationForest$new(\n  sample_size = as.integer(nrow(datos)/2),\n  num_trees   = 500, \n  replace     = TRUE,\n  seed        = 123\n)\nisoforest$fit(dataset = datos %>% select(-y))\n```\n\nAra anem a realitzar les prediccions.\n\n```{r}\n#| label: predicciones_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\npredicciones <- isoforest$predict(\n  data = datos %>% select(-y)\n)\nhead(predicciones)\n```\n\n```{r}\n#| label: plot_isolationForest\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nggplot(data = predicciones, aes(x = average_depth)) +\n  geom_histogram(color = \"gray40\") +\n  geom_vline(\n    xintercept = quantile(predicciones$average_depth, seq(0, 1, 0.1)),\n    color      = \"red\",\n    linetype   = \"dashed\") +\n  labs(\n    title = \"Distribuci√≥n de las distancias medias del Isolation Forest\",\n    subtitle = \"Cuantiles marcados en rojo\"  ) +\n  theme_bw() +\n  theme(plot.title = element_text(size = 11))\n\ncuantiles <- quantile(x = predicciones$average_depth, probs = seq(0, 1, 0.05))\ncuantiles\n```\n\n### TIPS: Detecci√≥n de anomal√≠as\n\nUna vez que la distancia de separaci√≥n ha sido calculado, se puede emplear como criterio para identificar anomal√≠as. Asumiendo que las observaciones con valores at√≠picos en una o m√°s de sus variables se separan del resto con mayor facilidad, aquellas observaciones con menor distancia promedio deber√≠an ser las m√°s at√≠picas.\n\nEn la pr√°ctica, si se est√° empleando esta estrategia de detecci√≥n es porque no se dispone de datos etiquetados, es decir, no se conoce qu√© observaciones son realmente anomal√≠as. Sin embargo, como en este ejemplo se dispone de la clasificaci√≥n real, se puede verificar si realmente los datos an√≥malos tienen menores distancias.\n\n```{r}\n#| label: plot_deteccionAnomalias\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndatos <- datos %>%\n  bind_cols(predicciones)\n\nggplot(data = datos,\n       aes(x = y, y = average_depth)) +\n  geom_jitter(aes(color = y), width = 0.03, alpha = 0.3) + \n  geom_violin(alpha = 0) +\n  geom_boxplot(width = 0.2, outlier.shape = NA, alpha = 0) +\n  stat_summary(fun = \"mean\", colour = \"orangered2\", size = 3, geom = \"point\") +\n  labs(title = \"Distancia promedio en el modelo Isolation Forest\",\n       x = \"clasificaci√≥n (0 = normal, 1 = anomal√≠a)\",\n       y = \"Distancia promedio\") +\n  theme_bw() + \n  theme(legend.position = \"none\",\n        plot.title = element_text(size = 11)\n  )\n\n```\n\nLa distancia promedio en el grupo de las anomal√≠as (1) es claramente inferior. Sin embargo, al existir solapamiento, si se clasifican las n observaciones con menor distancia como anomal√≠as, se incurrir√≠a en errores de falsos positivos.\n\nAcorde a la documentaci√≥n, el set de datos Cardiotocogrpahy contiene 176 anomal√≠as. V√©ase la matriz de confusi√≥n resultante si se clasifican como anomal√≠as las 176 observaciones con menor distancia predicha.\n\n```{r}\n#| label: matriz_confusion\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nresultados <- datos %>%\n  select(y, average_depth) %>%\n  arrange(average_depth) %>%\n  mutate(clasificacion = if_else(average_depth <= 8.5, \"1\", \"0\"))\n\nmat_confusion <- MLmetrics::ConfusionMatrix(\n  y_pred = resultados$clasificacion,\n  y_true = resultados$y)\n\nmat_confusion\n```\n\n# Missing values (valores faltantes)\n\nLos **valores faltantes** aparecen cuando una observaci√≥n no tiene registrado el valor en cierta variable.\n\nManejar correctamente los NA es esencial: eliminarlos puede reducir mucho el dataset, mientras que imputarlos incorrectamente puede introducir sesgos.\n\nExisten varias t√©cnicas:\n\n* **Eliminaci√≥n de filas/columnas** con demasiados NA.\n* **Imputaci√≥n simple**, por ejemplo reemplazando con la media o moda.\n* **Imputaci√≥n avanzada**, como KNN o modelos predictivos.\n\n> üëâ La elecci√≥n depende de la importancia de la variable, la cantidad de NA y el contexto del problema.\n\n## Generate data with NA's\n\n```{r}\n#| label: generar_missings\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ncolSums(is.na(iris))\niris.mis <- missForest::prodNA(iris, noNA = 0.1)\ncolSums((is.na(iris.mis)))\n```\n\nOtra forma de crear missings en el dataframe\n\n```{r}\n#| label: generar_missings2\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis <- mi::create.missing(iris, pct.mis = 10)\n```\n\n## Little Test\n\nEs un test que nos permite detectar con que tipo de NA's estamos enfrente:\n\n```{r}\n#| label: test_little\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nnaniar::mcar_test(iris.mis)\n```\n\nSi el valor p de la prova √©s inferior a 0 aix√≤ vol dir que les dades amb NAs s'han generat aleat√≤riament.\n\n## Patrons descriptius de NA en una base de dades\n\n### Explorar les relacions de NA's\n\n```{r}\n#| label: vis_na_total\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nlibrary(visdat)\nlibrary(ggplot2)\nlibrary(naniar)\n\nvis_dat(airquality);\nvis_dat(iris.mis)\nvis_miss(airquality);\nvis_miss(iris.mis)\n\nggplot(airquality, aes(x = Solar.R,y = Ozone)) + \n  geom_point()\nggplot(airquality, aes(x = Solar.R,  y = Ozone)) + \n  geom_miss_point()\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month)\n\nggplot(airquality, aes(x = Solar.R, y = Ozone)) + \n  geom_miss_point() + \n  facet_wrap(~Month) + \n  theme_dark()\n```\n\n### Visualitzaci√≥ dels NA's per variables\n\n```{r}\n#| label: vis_na_variables\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ngg_miss_var(airquality) + labs(y = \"Look at all the missing ones\")\n```\n\n### Detecci√≥ de NA's en la base de dades\n\n```{r}\n#| label: deteccio_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\naq_shadow <- bind_shadow(airquality)\n```\n\nImprimeix el gr√†fic amb difer√®ncia a les NA i no a les NA,\n\n```{r}\n#| label: grafico_detec_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nairquality %>%\n  bind_shadow() %>%\n  group_by(Ozone_NA) %>%\n  summarise_at(.vars = \"Solar.R\",\n               .funs = c(\"mean\", \"sd\", \"var\", \"min\", \"max\"),\n               na.rm = TRUE)\n\nggplot(aq_shadow,\n       aes(x = Temp,\n           colour = Ozone_NA)) + \n  geom_density()\n```\n\n### Extreu estad√≠stiques amb NAs de la base de dades\n\n```{r}\n#| label: estadistiques_na\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nprop_miss_case(airquality)\npct_miss_case(airquality)\nmiss_case_summary(airquality)\nmiss_case_table(airquality)\nprop_miss_var(airquality)\npct_miss_var(airquality)\nmiss_var_summary(airquality)\nmiss_var_table(airquality)\n```\n\n## Imputaci√≥ b√†sica\n\n### Imputar amb valor mitj√†\n\n```{r}\n#| label: NA_valor_mitja\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis[, \"imputed_Sepal.Length\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, mean))\n```\n\n# Imputar amb valor aleatori\n\n```{r}\n#| label: NA_valor_aleatori\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\niris.mis[, \"imputed_Sepal.Length2\"] <- with(iris.mis, Hmisc::impute(Sepal.Length, 'random'))\n```\n\nDe manera similar podeu utilitzar la mediana min, max, per imputar el valor que manca.\n\n### Representa la distribuci√≥ a variables reals i d'imputaci√≥ a trav√©s del gr√°fico de densidad con ggplot2\n\n```{r}\n#| label: grafico_imputacion\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\ndf_long <- iris.mis %>%\n  select(Sepal.Length, imputed_Sepal.Length, imputed_Sepal.Length2) %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\", \"green\"))\n\niris.mis[, c(\"imputed_Sepal.Length\", \"imputed_Sepal.Length2\")] <- NULL\n```\n\nOtra forma es usando el paquete `argImpute`.\n\n```{r}\n#| label: argImpute\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\n(impute_arg <- Hmisc::aregImpute(~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width +\n                           Species, data = iris.mis, n.impute = 5))\n```\n\nRevisamos la variable `Sepal.Length` con la imputaci√≥n realizada en cada una de las rondas.\n\n```{r}\n#| label: imputacion_SL\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nimpute_arg$imputed$Sepal.Length\n```\n\nCalculamos la media para las 5 simulaciones.\n\n```{r}\n#| label: media_simulaciones\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nimputed_Sepal.Length <- rowMeans(impute_arg$imputed$Sepal.Length)\nnew_var_imputed <- iris$Sepal.Length\nnew_var_imputed[as.numeric(names(imputed_Sepal.Length))] <- imputed_Sepal.Length\n```\n\nRevisamos la diferencia entre las dos imputaciones.\n\n```{r}\n#| label: grafico_media_simulaciones\n#| echo: true\n#| warning: false\n#| message: false\n#| error: false\n\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = new_var_imputed)\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n## Multiple Iterative Regression Imputation (MI method)\n\nImputamos los valores NA's con mi\n\n```{r}\n#| label: mi_imputation\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nmi_data <- mi::mi(iris.mis, seed = 335)\n```\n\nRevisamos la informaci√≥n de las imputaciones.\n\n```{r}\n#| label: grafico_mi_imputation\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nsummary(mi_data)\nplot(mi_data)\npar(ask = FALSE)\n```\n\nRevisamos las interaciones de la base de datos\n\n```{r}\n#| label: graficamos_mi_iteration\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\nmi_data@data\n```\n\n## Media con una variable target\n\nDefinimos la variable target\n\n```{r}\ntarget = \"Species\"\n```\n\nDefinimos la base de datos con NA's\n\n```{r}\n\ndata <- subset(iris, select = -c(get(target)))\ndata <- missForest::prodNA(data, noNA = 0.1)\ndata$Species <- iris[, target]\n```\n\nDefinir variables a imputar (excluyendo la variable target)\n\n```{r}\n\nvarImp <- colnames(data)[which(!colnames(data) %in% target)]\n```\n\nCalcular las medias por grupo\n\n```{r}\n\nmeans <- aggregate(data[, varImp], list(data[, target]), mean, na.rm = TRUE)\n```\n\nImputar valores faltantes\n\n```{r}\nfor (c in varImp) {\n  for (g in means[, \"Group.1\"]) {\n    cond <- data[, target] == g  # Condici√≥n booleana en vez de which()\n    na_index <- is.na(data[, c]) & cond  # Seleccionar NA dentro del grupo\n    \n    # Asignar valores imputados\n    data[na_index, c] <- means[means[, \"Group.1\"] == g, c]\n  }\n}\nsummary(data)\n```\n\nVisualizamos la diferencia entre las imputaciones\n\n```{r}\n\niris[, \"Tipo\"] <- \"original\"\ndata[, \"Tipo\"] <- \"imputed\"\n```\n\nUnimos en un mismo dataframe\n\n```{r}\n\ndata_long <- bind_rows(iris, data)\ncols_numeric <- names(data_long)[sapply(data_long, is.numeric) & names(data_long) != \"Tipo\"]\n\n# Convert a large data\ndata_long <- data_long %>%\n  pivot_longer(cols = all_of(cols_numeric), names_to = \"Variable\", values_to = \"Valor\")\n\n```\n\nCreamos el gr√°fico con ggplot\n\n```{r}\n\nggplot(data_long, aes(x = Valor, fill = Tipo)) +\n  geom_density(alpha = 0.3) +  # Transparencia para comparaci√≥n\n  facet_wrap(~Variable, scales = \"free\") +  # Un gr√°fico por variable\n  labs(title = \"Comparaci√≥n de Distribuciones: Original vs Imputado\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\nRemovemos la tipologia de variable\n\n```{r}\n\niris.mis[, \"Tipo\"] <- NULL\n```\n\n## Multiple Imputation by Chained Equations (MICE)\n\nEliminamos las variables categoricas\n\n```{r}\n\nquiCat <- which(lapply(iris.mis, class) %in% c(\"character\", \"factor\"))\ncategories <- names(iris.mis)[quiCat]\niris.mis2 <- subset(iris.mis, select = -c(get(categories)))\nsummary(iris.mis2)\n```\n\nVisualizamos los patrones de NA's de la base de datos\n\n```{r}\n\npar(mfrow = c(1, 1))\nmice::md.pattern(iris.mis2, rotate.names = TRUE)\n```\n\nTambi√©n lo podemos visualizar con el paquete VIM\n\n```{r}\n\nmice_plot <- VIM::aggr(iris.mis2, col=c('navyblue','yellow'),\n                  numbers=TRUE, sortVars=TRUE,\n                  labels=names(iris.mis), cex.axis=.7,\n                  gap=3, ylab=c(\"Missing data\",\"Pattern\"))\n```\n\nA continuaci√≥n realizamos la imputaci√≥n de los valores faltanes de manera multivariada\n\n```{r}\n\nimputed_Data <- mice::mice(iris.mis2, m=5, maxit = 50, method = 'pmm', seed = 500)\nsummary(imputed_Data)\n```\n\nInspeccionamos la calidad de las imputaciones\n\n```{r}\nmice::stripplot(imputed_Data, Sepal.Width, pch = 19, xlab = \"Imputation number\")\nimputed_Data$imp$Sepal.Width\n```\n\nAl final seleccionamos una de las iteracciones y la dejamos como imputaci√≥n de los valores faltantes.\n\n```{r}\ncompleteData <- mice::complete(imputed_Data, action = \"long\")\n```\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n## KNN\n\n```{r}\ntipos <- sapply(iris.mis, class)\nvarNum <- names(tipos)[which(tipos %in% c(\"numeric\", \"integer\"))]\ndata_knn_imputation <- multiUS::KNNimp(iris.mis[, varNum], k = 1)\nsummary(data_knn_imputation)\n```\n\nVisualizamos la diferencia entre las dos imputaciones.\n\n```{r}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed = data_knn_imputation[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n### Exercices:\n\n1.  Deploy the multiple plot to compare the imputation and not imputation with all numeric vars in dataframe\n\n## missForest\n\nImputamos los missings usando todos los parametros con los valores por defectos.\n\n```{r}\nlibrary(missForest)\niris.imp <- missForest(iris.mis, variablewise = T, verbose = T) \n```\n\nVisualizamos los valores imputados\n\n```{r}\n\niris.imp$ximp\n```\n\nVisualizamos el error cometido en las imputaciones.\n\n```{r}\n\niris.imp$OOBerror\n```\n\nNRMSE √©s un error normalitzat mitj√† al quadrat. S'utilitza per representar l'error derivat d'imputar valors continus. El PFC (proporci√≥ de falsament classificada) s'utilitza per representar l'error derivat d'imputar valors categ√≤rics.\n\nComparamos el accuracy actual,\n\n```{r}\n\n(iris.err <- mixError(iris.imp$ximp, iris.mis, iris))\n```\n\nMiramos la diferencia entre las dos imputaciones\n\n```{r}\nnewBD <- data.frame(real = iris[, \"Sepal.Length\"], imputed =  iris.imp$ximp[, \"Sepal.Length\"])\ndf_long <- newBD %>%\n  pivot_longer(cols = everything(), names_to = \"Variable\", values_to = \"Valor\")\n\nggplot(df_long, aes(x = Valor, fill = Variable)) +\n  geom_density(alpha = 0.3) +  # Transparencia para mejor visualizaci√≥n\n  labs(title = \"Densidad de las tres variables\",\n       x = \"Valor\",\n       y = \"Densidad\") +\n  theme_minimal() +\n  scale_fill_manual(values = c(\"blue\", \"red\"))\n```\n\n### Exercises:\n\n1.  Deploy the multiple plot to compare te imputation and not imputation with all numeric vars in dataframe\n\n### Extra:\n\nQuan es tracta de valors que manquen, √©s possible que vulgueu reempla√ßar valors per valors que manquen (NA). Aix√≤ √©s √∫til en els casos en qu√® es coneix l'origen de les dades i es pot estar segur de quins valors han de faltar. Per exemple, podr√≠eu saber que tots els valors de ¬´N/A¬ª, ¬´N A¬ª i ¬´No disponible¬ª, o -99 o -1 se suposa que falten.\n\nnaniar proporciona funcions per treballar espec√≠ficament en aquest tipus de problemes utilitzant la funci√≥ replace.with.na. Aquesta funci√≥ √©s el compliment a tidyr::replace els NA's, que reempla√ßa un valor NA per un valor especificat, mentre que naniar::replace,with_na reempla√ßa un valor per un NA:\n\n```{r}\n#| label: code_ejemplo\n#| echo: true\n#| eval: false\n#| warning: false\n#| message: false\n#| error: false\n\ntidyr::replace_na: Missing values turns into a value (NA ‚Äì> -99)\nnaniar::replace_with_na: Value becomes a missing value (-99 ‚Äì> NA)\n```\n\n## MIMMI\n\nPuedes descargar el fichero de MIMMI pinchando [aqu√≠](03_02_MIMMI.R)\n\n# Bibliograf√≠a\n\n## Outliers\n\n-   https://statsandr.com/blog/outliers-detection-in-r/#z-scores\n-   https://m-mburu.github.io/datacamp/anomaly_detection_R/anomaly_detection.html\n-   https://github.com/pridiltal/ctv-AnomalyDetection\n\n## Imputaci√≥n\n\n-   http://naniar.njtierney.com/articles/replace-with-na.html\n-   https://cran.r-project.org/web/packages/visdat/vignettes/using_visdat.html\n-   https://cran.r-project.org/web/packages/DMwR2/DMwR2.pdf\n-   https://ltorgo.github.io/DMwR2/RintroDM.html#data_pre-processing\n-   https://www.rdocumentation.org/packages/DMwR/versions/0.4.1/topics/knnImputation\n-   https://amices.org/mice/\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../styles.css"],"toc":true,"number-sections":true,"output-file":"AdvancedPreprocessing.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.37","theme":"cerulean","title":"Advance Preprocessing","author":"Dante Conti, Sergi Ramirez, (c) IDEAI","date":"`r Sys.Date()`","date-modified":"`r Sys.Date()`","editor":"visual"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}