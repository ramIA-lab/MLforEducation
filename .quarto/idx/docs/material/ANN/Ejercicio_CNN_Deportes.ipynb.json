{"title":"Convolutional Neural Networks","markdown":{"yaml":{"title":"Convolutional Neural Networks"},"headingText":"Importar Librerías","containsRefs":false,"markdown":"\n\n\n\n\n\n\n\nVamos a emparejar el notebook de python con el google drive\n\n## **Imagenes y píxeles**\n\nLa red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a  784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-01.png)\n\n### Cargar set de Imágenes\n\n# Creamos las etiquetas\n\n# Creamos Sets de Entrenamiento y Test\n\n# Preprocesamos las imagenes\n\nAntes de alimentar la red, recuerda que como entrada nos conviene normalizar los valores. Los colores de los pixeles tienen valores que van de 0 a 255, haremos una transformación de cada pixel: “valor/255” y nos quedará siempre un valor entre 0 y 1.\n\n![imagen2](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-02.png)\n\n## Hacemos el One-hot Encoding para la red\n\n# Creamos el Set de Entrenamiento y Validación\n\n# **Creamos el modelo de CNN**\n\nAhora comienza el *procesado distintivo* de las CNN. Es decir, haremos las llamadas *convoluciones*:\n\nEstas consisten en tomar *grupos de pixeles cercanos* de la imagen de entrada e ir operando matemáticamente (producto escalar) contra una pequeña matriz que se llama kernel. Ese kernel supongamos de tamaño 3×3 pixels “recorre” todas las neuronas de entrada (de izquierda-derecha, de arriba-abajo) y genera una nueva matriz de salida, que en definitiva será nuestra nueva capa de neuronas ocultas. NOTA: si la imagen fuera a color, el kernel realmente sería de 3x3x3 es decir: un filtro con 3 kernels de 3×3; luego  esos 3 filtros se suman (y se le suma una unidad bias) y conformarán 1 salida (cómo si fuera 1 solo canal).\n\n![images](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-03.png)\n\n# **Filtros:**\n## Conjunto de Kernels\n\nCuando generamos nuestra matriz agregada, en realidad, no aplicaremos 1 sólo kernel, si no que tendremos muchos kernel (en su conjunto se llama filtros). Por ejemplo en esta primer convolución podríamos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como *feature mapping*), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra **PRIMER CAPA OCULTA** de neuronas.\n\n\\\n![imagenes](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn_kernel.gif)\n\nA medida que vamos desplazando el kernel y vamos obteniendo una *nueva imagen* filtrada por el *kernel*. En esta primer convolución y siguiendo con el ejemplo anterior, es como si obtuviéramos 32 *imágenes filtradas nuevas*. Estas imágenes nuevas lo que están “dibujando” son ciertas características de la imagen original. Esto ayudará en el futuro a poder distinguir un objeto de otro.\n\n![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-04.png)\n\n# **La función de activación**\n\nLa función de activación más utilizada para este tipo de redes neuronales es la llamada **ReLu** por *Rectifier Linear Unit* y consiste en f(x) = max(0,x).\n\n# **Subsampling**\n\nAhora viene un paso en el que reduciremos la cantidad de neuronas antes de hacer una nueva convolución. Estp es debido porque a partir de nuestra imagen blanco y negro de 28x28px tenemos una primer capa de entrada de 784 neuronas y luego de la primer convolución obtenemos una capa oculta de 25.088 neuronas -que realmente son nuestros 32 mapas de características de 28×28-\n\nSi hiciéramos una nueva convolución a partir de esta capa, el número de neuronas de la próxima capa se iría por las nubes (y ello implica mayor procesamiento)! Para reducir el tamaño de la próxima capa de neuronas haremos un proceso de subsampling en el que reduciremos el tamaño de nuestras imágenes filtradas pero en donde deberán prevalecer las características más importantes que detectó cada filtro. Hay diversos tipos de subsampling, a continuación veremos el **más usado**: *Max-Pooling*\n\n## **Max-Pooling**\n\nVamos a intentar explicarlo con un ejemplo: supongamos que haremos *Max-pooling* de tamaño 2×2. Esto quiere decir que recorreremos cada una de nuestras 32 imágenes de características obtenidas anteriormente de 28x28px de izquierda-derecha, arriba-abajo PERO en vez de tomar de a 1 pixel, tomaremos de “2×2” (2 de alto por 2 de ancho = 4 pixeles) e iremos preservando el valor “más alto” de entre esos 4 pixeles (por eso lo de “Max”). En este caso, usando 2×2, la imagen resultante es reducida “a la mitad”y quedará de 14×14 pixeles. Luego de este proceso de subsamplig nos quedarán  32 imágenes de 14×14, pasando de haber tenido 25.088 neuronas a  6.272, son bastantes menos y -en teoría- siguen almacenando la información más importante para detectar características deseadas.\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-05.png)\n\nMuy bien, pues esa ha sido una primer convolución: consiste de una entrada, un conjunto de filtros, generamos un mapa de características y hacemos un subsampling. Con lo cual, en el ejemplo de imágenes de 1 sólo color tendremos:\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-06.png)\n\n\nLa **primer convolución** es capaz de detectar características primitivas como lineas ó curvas. A medida que hagamos más capas con las convoluciones, los mapas de características serán capaces de reconocer formas más complejas, y el conjunto total de capas de convoluciones podrá *ver*.\n\nPues ahora deberemos hacer una Segunda convolución que será:\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-07.png)\n\nLa **3er convolución** comenzará en tamaño 7×7 pixels y luego del *max-pooling* quedará en 3×3 con lo cual podríamos hacer sólo 1 convolución más. En este ejemplo empezamos con una imagen de 28x28px e hicimos 3 convoluciones. Si la imagen inicial hubiese sido mayor (de 224x224px) aún hubiéramos podido seguir haciendo convoluciones.\n\nLlegamos a la última convolución y nos queda el desenlace…\n\nPara terminar, tomaremos la última capa oculta a la que hicimos *subsampling*, que se dice que es *tridimensional* por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la *aplanamos*, esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas *tradicionales*, de las que ya conocíamos. Por ejemplo, podríamos aplanar (y conectar) a una nueva capa oculta de 100 neuronas feedforward.\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-08.png)\n\nEntonces, a esta nueva capa oculta *tradicional*, le aplicamos una función llamada **Softmax** que conecta contra la capa de salida final que tendrá la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, serán 2 neuronas. Si es el dataset Mnist numérico serán 10 neuronas de salida. Si clasificamos coches, aviones ó barcos serán 3, etc.\n\nLas salidas al momento del entrenamiento tendrán el formato conocido como **one-hot-encoding** en el que para perros y gatos sera: [1,0] y [0,1], para coches, aviones ó barcos será [1,0,0]; [0,1,0];[0,0,1].\n\nY la función de *Softmax* se encarga de pasar a probabilidad (entre 0 y 1) a las neuronas de salida. Por ejemplo una salida [0,2 0,8] nos indica 20% probabilidades de que sea perro y 80% de que sea gato.\n\n## **Backpropagation**\n\nEl proceso es similar al de las redes tradicionales en las que tenemos una entrada y una salida esperada (por eso aprendizaje supervisado) y mediante el *backpropagation* mejoramos el valor de los pesos de las interconexiones entre capas de neuronas y a medida que iteramos esos pesos se ajustan hasta ser óptimos.\n\nEn el caso de la CNN, deberemos ajustar el valor de los pesos de los distintos kernels. Esto es una gran ventaja al momento del aprendizaje pues como vimos cada kernel es de un tamaño reducido, en nuestro ejemplo en la primer convolución es de tamaño de 3×3, eso son sólo 9 parámetros que debemos ajustar en 32 filtros dan un total de 288 parámetros. En comparación con los pesos entre dos capas de neuronas “tradicionales”: una de 748 y otra de 6272 en donde están TODAS interconectarlas con TODAS y eso equivaldría a tener que entrenar y ajustar más de 4,5 millones de pesos (repito: sólo para 1 capa).\n\n## **Arquitectura básica**\n\nResumiendo: podemos decir que los elementos que usamos para crear CNNs son:\n\n- **Entrada:** Serán los pixeles de la imagen. Serán alto, ancho y profundidad será 1 sólo color o 3 para Red,Green,Blue.\n\n- **Capa De Convolución:** procesará la salida de neuronas que están conectadas en “regiones locales” de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una pequeña región a la que están conectados en el volumen de entrada. Aquí usaremos por ejemplo 32 filtros o la cantidad que decidamos y ese será el volumen de salida.\n\n- **“CAPA RELU”** aplicará la función de activación en los elementos de la matriz.\n\n- **POOL ó SUBSAMPLING:** Hará una reducción en las dimensiones alto y ancho, pero se mantiene la profundidad.\n\n- **CAPA “TRADICIONAL”** red de neuronas feedforward que conectará con la última capa de subsampling y finalizará con la cantidad de neuronas que queremos clasificar.\n\n## Declaración de parámetros\n\n## Construcción del modelo\n\n# Entrenamos el modelo: Aprende a clasificar imágenes\n\n# Evaluamos la red\n\n# Aprendamos de los errores: Qué mejorar\n\n# Prediccion de una nueva imagen\n\n## **TENSORFLOW**\n","srcMarkdownNoYaml":"\n\n\n\n\n\n\n# Importar Librerías\n\nVamos a emparejar el notebook de python con el google drive\n\n## **Imagenes y píxeles**\n\nLa red toma como entrada los pixeles de una imagen. Si tenemos una imagen con apenas 28×28 pixeles de alto y ancho, eso equivale a  784 neuronas. Y eso es si sólo tenemos 1 color (escala de grises). Si tuviéramos una imagen a color, necesitaríamos 3 canales (red, green, blue) y entonces usaríamos 28x28x3 = 2352 neuronas de entrada. Esa es nuestra capa de entrada.\n\n![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-01.png)\n\n### Cargar set de Imágenes\n\n# Creamos las etiquetas\n\n# Creamos Sets de Entrenamiento y Test\n\n# Preprocesamos las imagenes\n\nAntes de alimentar la red, recuerda que como entrada nos conviene normalizar los valores. Los colores de los pixeles tienen valores que van de 0 a 255, haremos una transformación de cada pixel: “valor/255” y nos quedará siempre un valor entre 0 y 1.\n\n![imagen2](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-02.png)\n\n## Hacemos el One-hot Encoding para la red\n\n# Creamos el Set de Entrenamiento y Validación\n\n# **Creamos el modelo de CNN**\n\nAhora comienza el *procesado distintivo* de las CNN. Es decir, haremos las llamadas *convoluciones*:\n\nEstas consisten en tomar *grupos de pixeles cercanos* de la imagen de entrada e ir operando matemáticamente (producto escalar) contra una pequeña matriz que se llama kernel. Ese kernel supongamos de tamaño 3×3 pixels “recorre” todas las neuronas de entrada (de izquierda-derecha, de arriba-abajo) y genera una nueva matriz de salida, que en definitiva será nuestra nueva capa de neuronas ocultas. NOTA: si la imagen fuera a color, el kernel realmente sería de 3x3x3 es decir: un filtro con 3 kernels de 3×3; luego  esos 3 filtros se suman (y se le suma una unidad bias) y conformarán 1 salida (cómo si fuera 1 solo canal).\n\n![images](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-03.png)\n\n# **Filtros:**\n## Conjunto de Kernels\n\nCuando generamos nuestra matriz agregada, en realidad, no aplicaremos 1 sólo kernel, si no que tendremos muchos kernel (en su conjunto se llama filtros). Por ejemplo en esta primer convolución podríamos tener 32 filtros, con lo cual realmente obtendremos 32 matrices de salida (este conjunto se conoce como *feature mapping*), cada una de 28x28x1 dando un total del 25.088 neuronas para nuestra **PRIMER CAPA OCULTA** de neuronas.\n\n\\\n![imagenes](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn_kernel.gif)\n\nA medida que vamos desplazando el kernel y vamos obteniendo una *nueva imagen* filtrada por el *kernel*. En esta primer convolución y siguiendo con el ejemplo anterior, es como si obtuviéramos 32 *imágenes filtradas nuevas*. Estas imágenes nuevas lo que están “dibujando” son ciertas características de la imagen original. Esto ayudará en el futuro a poder distinguir un objeto de otro.\n\n![imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-04.png)\n\n# **La función de activación**\n\nLa función de activación más utilizada para este tipo de redes neuronales es la llamada **ReLu** por *Rectifier Linear Unit* y consiste en f(x) = max(0,x).\n\n# **Subsampling**\n\nAhora viene un paso en el que reduciremos la cantidad de neuronas antes de hacer una nueva convolución. Estp es debido porque a partir de nuestra imagen blanco y negro de 28x28px tenemos una primer capa de entrada de 784 neuronas y luego de la primer convolución obtenemos una capa oculta de 25.088 neuronas -que realmente son nuestros 32 mapas de características de 28×28-\n\nSi hiciéramos una nueva convolución a partir de esta capa, el número de neuronas de la próxima capa se iría por las nubes (y ello implica mayor procesamiento)! Para reducir el tamaño de la próxima capa de neuronas haremos un proceso de subsampling en el que reduciremos el tamaño de nuestras imágenes filtradas pero en donde deberán prevalecer las características más importantes que detectó cada filtro. Hay diversos tipos de subsampling, a continuación veremos el **más usado**: *Max-Pooling*\n\n## **Max-Pooling**\n\nVamos a intentar explicarlo con un ejemplo: supongamos que haremos *Max-pooling* de tamaño 2×2. Esto quiere decir que recorreremos cada una de nuestras 32 imágenes de características obtenidas anteriormente de 28x28px de izquierda-derecha, arriba-abajo PERO en vez de tomar de a 1 pixel, tomaremos de “2×2” (2 de alto por 2 de ancho = 4 pixeles) e iremos preservando el valor “más alto” de entre esos 4 pixeles (por eso lo de “Max”). En este caso, usando 2×2, la imagen resultante es reducida “a la mitad”y quedará de 14×14 pixeles. Luego de este proceso de subsamplig nos quedarán  32 imágenes de 14×14, pasando de haber tenido 25.088 neuronas a  6.272, son bastantes menos y -en teoría- siguen almacenando la información más importante para detectar características deseadas.\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-05.png)\n\nMuy bien, pues esa ha sido una primer convolución: consiste de una entrada, un conjunto de filtros, generamos un mapa de características y hacemos un subsampling. Con lo cual, en el ejemplo de imágenes de 1 sólo color tendremos:\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-06.png)\n\n\nLa **primer convolución** es capaz de detectar características primitivas como lineas ó curvas. A medida que hagamos más capas con las convoluciones, los mapas de características serán capaces de reconocer formas más complejas, y el conjunto total de capas de convoluciones podrá *ver*.\n\nPues ahora deberemos hacer una Segunda convolución que será:\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/cnn-07.png)\n\nLa **3er convolución** comenzará en tamaño 7×7 pixels y luego del *max-pooling* quedará en 3×3 con lo cual podríamos hacer sólo 1 convolución más. En este ejemplo empezamos con una imagen de 28x28px e hicimos 3 convoluciones. Si la imagen inicial hubiese sido mayor (de 224x224px) aún hubiéramos podido seguir haciendo convoluciones.\n\nLlegamos a la última convolución y nos queda el desenlace…\n\nPara terminar, tomaremos la última capa oculta a la que hicimos *subsampling*, que se dice que es *tridimensional* por tomar la forma -en nuestro ejemplo- 3x3x128 (alto,ancho,mapas) y la *aplanamos*, esto es que deja de ser tridimensional, y pasa a ser una capa de neuronas *tradicionales*, de las que ya conocíamos. Por ejemplo, podríamos aplanar (y conectar) a una nueva capa oculta de 100 neuronas feedforward.\n\n![Imagen](https://www.aprendemachinelearning.com/wp-content/uploads/2018/11/CNN-08.png)\n\nEntonces, a esta nueva capa oculta *tradicional*, le aplicamos una función llamada **Softmax** que conecta contra la capa de salida final que tendrá la cantidad de neuronas correspondientes con las clases que estamos clasificando. Si clasificamos perros y gatos, serán 2 neuronas. Si es el dataset Mnist numérico serán 10 neuronas de salida. Si clasificamos coches, aviones ó barcos serán 3, etc.\n\nLas salidas al momento del entrenamiento tendrán el formato conocido como **one-hot-encoding** en el que para perros y gatos sera: [1,0] y [0,1], para coches, aviones ó barcos será [1,0,0]; [0,1,0];[0,0,1].\n\nY la función de *Softmax* se encarga de pasar a probabilidad (entre 0 y 1) a las neuronas de salida. Por ejemplo una salida [0,2 0,8] nos indica 20% probabilidades de que sea perro y 80% de que sea gato.\n\n## **Backpropagation**\n\nEl proceso es similar al de las redes tradicionales en las que tenemos una entrada y una salida esperada (por eso aprendizaje supervisado) y mediante el *backpropagation* mejoramos el valor de los pesos de las interconexiones entre capas de neuronas y a medida que iteramos esos pesos se ajustan hasta ser óptimos.\n\nEn el caso de la CNN, deberemos ajustar el valor de los pesos de los distintos kernels. Esto es una gran ventaja al momento del aprendizaje pues como vimos cada kernel es de un tamaño reducido, en nuestro ejemplo en la primer convolución es de tamaño de 3×3, eso son sólo 9 parámetros que debemos ajustar en 32 filtros dan un total de 288 parámetros. En comparación con los pesos entre dos capas de neuronas “tradicionales”: una de 748 y otra de 6272 en donde están TODAS interconectarlas con TODAS y eso equivaldría a tener que entrenar y ajustar más de 4,5 millones de pesos (repito: sólo para 1 capa).\n\n## **Arquitectura básica**\n\nResumiendo: podemos decir que los elementos que usamos para crear CNNs son:\n\n- **Entrada:** Serán los pixeles de la imagen. Serán alto, ancho y profundidad será 1 sólo color o 3 para Red,Green,Blue.\n\n- **Capa De Convolución:** procesará la salida de neuronas que están conectadas en “regiones locales” de entrada (es decir pixeles cercanos), calculando el producto escalar entre sus pesos (valor de pixel) y una pequeña región a la que están conectados en el volumen de entrada. Aquí usaremos por ejemplo 32 filtros o la cantidad que decidamos y ese será el volumen de salida.\n\n- **“CAPA RELU”** aplicará la función de activación en los elementos de la matriz.\n\n- **POOL ó SUBSAMPLING:** Hará una reducción en las dimensiones alto y ancho, pero se mantiene la profundidad.\n\n- **CAPA “TRADICIONAL”** red de neuronas feedforward que conectará con la última capa de subsampling y finalizará con la cantidad de neuronas que queremos clasificar.\n\n## Declaración de parámetros\n\n## Construcción del modelo\n\n# Entrenamos el modelo: Aprende a clasificar imágenes\n\n# Evaluamos la red\n\n# Aprendamos de los errores: Qué mejorar\n\n# Prediccion de una nueva imagen\n\n## **TENSORFLOW**\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"Ejercicio_CNN_Deportes.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.37","resources":"../../../material/ANN/","theme":{"light":"cosmo","dark":"darkly"},"title":"Convolutional Neural Networks"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}