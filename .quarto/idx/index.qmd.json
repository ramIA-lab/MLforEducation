{"title":"Métodos Estadísticos para la mineria de datos","markdown":{"yaml":{"title":"Métodos Estadísticos para la mineria de datos","toc":false,"number-sections":true},"headingText":"Introducción a la mineria de datos","containsRefs":false,"markdown":"\n\nLa filosofía de la minería de datos trata de la conversión de datos en conocimiento para la toma de decisiones, y como tal constituye la fase central del proceso de extracción de conocimiento a partir de bases de datos. La minería de datos es un punto de encuentro de diferentes disciplinas: \n\n-  la estadística, \n-  el aprendizaje automático (*machine learning*)\n-  las técnicas de bases de datos \n-  los sistemas para la toma de decisiones. \n\nJuntas permiten afrontar muchos problemas actuales en cuanto al tratamiento de la información.\n\nLa asignatura introduce las técnicas más usuales para la resolución de tres tipos de problemas fundamentales: el análisis de datos binarios (*transacciones*), el análisis de datos científicos (por ejemplo, de genómica) y el análisis de datos de empresas; los cuales configuran buena parte de los problemas actuales que trata la minería de datos.\n\nComo objetivo paralelo hay utilizar la R, un potente en torno a programación libre.\n\n\nLa minería de datos es el proceso de extraer patrones, tendencias y conocimientos útiles a partir de grandes volúmenes de datos. Combina estadística, aprendizaje automático y bases de datos para ayudar a resolver problemas en diversas áreas, como negocios, ciencia y tecnología.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Clustering \n\nEl clustering agrupa datos similares en clústeres basados en características compartidas. Es útil para descubrir patrones ocultos y segmentar conjuntos de datos, comúnmente aplicado en marketing, biología y análisis de redes.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Visualización de datos\n\nLa visualización de datos convierte información compleja en gráficos y representaciones visuales claras, facilitando la interpretación y comunicación de resultados. Herramientas como gráficos de dispersión, histogramas y mapas de calor son fundamentales.\n\n### Analisis de componentes principales (ACP)\n\nEl ACP reduce la dimensionalidad de los datos al identificar las combinaciones lineales más relevantes de las variables originales, conservando la mayor parte de la variación. Se usa para simplificar datos y facilitar su interpretación.\n\n[Teoria]()\n\n[Laboratorio]()\n\n### Analisis de correspondiencias múltiples (ACM)\n\nEl ACM analiza tablas de datos categóricos para identificar relaciones entre categorías, visualizando patrones en mapas bidimensionales que facilitan la interpretación.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Reglas de asociación\n\nEste método identifica relaciones significativas entre variables en grandes bases de datos. Es clave en aplicaciones como los sistemas de recomendación y análisis de cestas de mercado.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Reglas de clasificación\n\nLos modelos de clasificación asignan datos a categorías predefinidas basándose en patrones aprendidos. Es ampliamente usado en diagnóstico médico, detección de fraudes y análisis de texto.\n\n### Lineal Discriminant Analysis (LDA) y Quadratic Discriminant Analysis (QDA)\n\nAmbos métodos buscan separar categorías utilizando fronteras de decisión basadas en estadísticas. LDA asume varianzas iguales entre clases, mientras que QDA permite varianzas diferentes.\n\n[Teoria]()\n\n[Laboratorio]()\n\n### Naives Bayes\n\nUn clasificador basado en probabilidad que asume independencia entre las características. Es eficiente y se aplica en problemas como clasificación de texto y detección de spam.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Métodos particionales \n\nDividen datos en subconjuntos o particiones, a menudo mediante árboles de decisión y técnicas relacionadas.\n\n### Decisions Tree\n\nModelo gráfico que toma decisiones en base a condiciones secuenciales. Es intuitivo y útil en clasificación y regresión.\n\n### Random Forest\n\nCombina múltiples árboles de decisión para mejorar precisión y reducir sobreajuste. Es robusto y adecuado para tareas de clasificación y regresión.\n\n### Bagging & Boosting\n\nMétodos de ensamblado que mejoran el rendimiento combinando múltiples modelos. Bagging reduce la variabilidad, mientras que Boosting optimiza errores iterativamente.\n\n[Teoria]()\n\n[Laboratorio](material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.qmd)\n\n## Métodos flexibles de discriminación \n\n### Support Vectors Machines (SVM)\n\nSeparan clases usando hiperplanos óptimos en un espacio de alta dimensionalidad. Son efectivas en problemas no lineales y clasificación compleja.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Deep Learning \n\nEl aprendizaje profundo utiliza redes neuronales para modelar datos complejos. Es ampliamente aplicado en reconocimiento de imágenes, procesamiento de lenguaje natural y más.\n\n### Redes neuronales: Discriminación pel perceptrón multicapa\n\nLas redes multicapa, basadas en múltiples capas de neuronas interconectadas, resuelven problemas no lineales con alta precisión.\n\n### Redes neuronales convolucionales\n\nEspecializadas en procesar datos con estructura espacial, como imágenes. Extraen automáticamente características relevantes para tareas como clasificación de imágenes y visión por computadora.\n\n[Teoria](material/ANN/ANN.pdf)\n\n[Datos de deportes]()\n\n```{r}\n#| eval: false\n#| echo: false\n[dades deportes](material/ANN/img_deportes.zip)\n[Detección de imagenes](material/ANN/Ejercicio_CNN_Deportes.ipynb)\n```\n\n```{r}\n#| eval: false\n#| echo: false\n[DreamBooth (parte 1)](material/ANN/01_DreamBooth_parte1.ipynb){download=true}\n```\n\n[DreamBooth (parte 1)](material/ANN/01_DreamBooth_parte1.zip)\n\n**Importante:** Para poder hacer uso de este script es necesario que tengas: \n\n- Entre 2 y 3 fotos de cuerpo entero\n\n- Entre 3 y 5 fotos de medio cuerpo\n\n- Entorno a 10 fotos de cara\n\n```{r}\n#| eval: false\n#| echo: false\n[DreamBooth (parte 2)](material/ANN/01_DreamBooth_parte2.ipynb)\n```\n\n[DreamBooth (parte 2)]()\n","srcMarkdownNoYaml":"\n\nLa filosofía de la minería de datos trata de la conversión de datos en conocimiento para la toma de decisiones, y como tal constituye la fase central del proceso de extracción de conocimiento a partir de bases de datos. La minería de datos es un punto de encuentro de diferentes disciplinas: \n\n-  la estadística, \n-  el aprendizaje automático (*machine learning*)\n-  las técnicas de bases de datos \n-  los sistemas para la toma de decisiones. \n\nJuntas permiten afrontar muchos problemas actuales en cuanto al tratamiento de la información.\n\nLa asignatura introduce las técnicas más usuales para la resolución de tres tipos de problemas fundamentales: el análisis de datos binarios (*transacciones*), el análisis de datos científicos (por ejemplo, de genómica) y el análisis de datos de empresas; los cuales configuran buena parte de los problemas actuales que trata la minería de datos.\n\nComo objetivo paralelo hay utilizar la R, un potente en torno a programación libre.\n\n## Introducción a la mineria de datos\n\nLa minería de datos es el proceso de extraer patrones, tendencias y conocimientos útiles a partir de grandes volúmenes de datos. Combina estadística, aprendizaje automático y bases de datos para ayudar a resolver problemas en diversas áreas, como negocios, ciencia y tecnología.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Clustering \n\nEl clustering agrupa datos similares en clústeres basados en características compartidas. Es útil para descubrir patrones ocultos y segmentar conjuntos de datos, comúnmente aplicado en marketing, biología y análisis de redes.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Visualización de datos\n\nLa visualización de datos convierte información compleja en gráficos y representaciones visuales claras, facilitando la interpretación y comunicación de resultados. Herramientas como gráficos de dispersión, histogramas y mapas de calor son fundamentales.\n\n### Analisis de componentes principales (ACP)\n\nEl ACP reduce la dimensionalidad de los datos al identificar las combinaciones lineales más relevantes de las variables originales, conservando la mayor parte de la variación. Se usa para simplificar datos y facilitar su interpretación.\n\n[Teoria]()\n\n[Laboratorio]()\n\n### Analisis de correspondiencias múltiples (ACM)\n\nEl ACM analiza tablas de datos categóricos para identificar relaciones entre categorías, visualizando patrones en mapas bidimensionales que facilitan la interpretación.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Reglas de asociación\n\nEste método identifica relaciones significativas entre variables en grandes bases de datos. Es clave en aplicaciones como los sistemas de recomendación y análisis de cestas de mercado.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Reglas de clasificación\n\nLos modelos de clasificación asignan datos a categorías predefinidas basándose en patrones aprendidos. Es ampliamente usado en diagnóstico médico, detección de fraudes y análisis de texto.\n\n### Lineal Discriminant Analysis (LDA) y Quadratic Discriminant Analysis (QDA)\n\nAmbos métodos buscan separar categorías utilizando fronteras de decisión basadas en estadísticas. LDA asume varianzas iguales entre clases, mientras que QDA permite varianzas diferentes.\n\n[Teoria]()\n\n[Laboratorio]()\n\n### Naives Bayes\n\nUn clasificador basado en probabilidad que asume independencia entre las características. Es eficiente y se aplica en problemas como clasificación de texto y detección de spam.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Métodos particionales \n\nDividen datos en subconjuntos o particiones, a menudo mediante árboles de decisión y técnicas relacionadas.\n\n### Decisions Tree\n\nModelo gráfico que toma decisiones en base a condiciones secuenciales. Es intuitivo y útil en clasificación y regresión.\n\n### Random Forest\n\nCombina múltiples árboles de decisión para mejorar precisión y reducir sobreajuste. Es robusto y adecuado para tareas de clasificación y regresión.\n\n### Bagging & Boosting\n\nMétodos de ensamblado que mejoran el rendimiento combinando múltiples modelos. Bagging reduce la variabilidad, mientras que Boosting optimiza errores iterativamente.\n\n[Teoria]()\n\n[Laboratorio](material/trees_ensambleMethods/DecisionsTree_RandomForest_XGBoost.qmd)\n\n## Métodos flexibles de discriminación \n\n### Support Vectors Machines (SVM)\n\nSeparan clases usando hiperplanos óptimos en un espacio de alta dimensionalidad. Son efectivas en problemas no lineales y clasificación compleja.\n\n[Teoria]()\n\n[Laboratorio]()\n\n## Deep Learning \n\nEl aprendizaje profundo utiliza redes neuronales para modelar datos complejos. Es ampliamente aplicado en reconocimiento de imágenes, procesamiento de lenguaje natural y más.\n\n### Redes neuronales: Discriminación pel perceptrón multicapa\n\nLas redes multicapa, basadas en múltiples capas de neuronas interconectadas, resuelven problemas no lineales con alta precisión.\n\n### Redes neuronales convolucionales\n\nEspecializadas en procesar datos con estructura espacial, como imágenes. Extraen automáticamente características relevantes para tareas como clasificación de imágenes y visión por computadora.\n\n[Teoria](material/ANN/ANN.pdf)\n\n[Datos de deportes]()\n\n```{r}\n#| eval: false\n#| echo: false\n[dades deportes](material/ANN/img_deportes.zip)\n[Detección de imagenes](material/ANN/Ejercicio_CNN_Deportes.ipynb)\n```\n\n```{r}\n#| eval: false\n#| echo: false\n[DreamBooth (parte 1)](material/ANN/01_DreamBooth_parte1.ipynb){download=true}\n```\n\n[DreamBooth (parte 1)](material/ANN/01_DreamBooth_parte1.zip)\n\n**Importante:** Para poder hacer uso de este script es necesario que tengas: \n\n- Entre 2 y 3 fotos de cuerpo entero\n\n- Entre 3 y 5 fotos de medio cuerpo\n\n- Entorno a 10 fotos de cara\n\n```{r}\n#| eval: false\n#| echo: false\n[DreamBooth (parte 2)](material/ANN/01_DreamBooth_parte2.ipynb)\n```\n\n[DreamBooth (parte 2)]()\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":false,"number-sections":true,"output-file":"index.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.37","theme":{"light":"cosmo","dark":"darkly"},"title":"Métodos Estadísticos para la mineria de datos"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}